{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import io\n",
    "from scipy import misc\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(fileName):\n",
    "    finalData = pd.read_csv(fileName)\n",
    "    finalData.count()\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "\n",
    "    for column in finalData.columns:\n",
    "        if finalData[column].dtype == type(object):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            finalData[column] = le.fit_transform(finalData[column])\n",
    "            \n",
    "    return finalData.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupData(finalData, fraction):\n",
    "    data, test = train_test_split(finalData, test_size = 0.2)\n",
    "    data = data.sample(frac = fraction)\n",
    "    features = [\"Sex\", \"Age\", \"Height\", \"Weight\", \"Team\", \"Sport\", \"Event\"]\n",
    "\n",
    "    X_data = data[features]\n",
    "    y_data = data['Medal']\n",
    "\n",
    "    X_test = test[features]\n",
    "    y_test = test[\"Medal\"]\n",
    "    return (X_data, y_data, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(data, fileName):\n",
    "    print(data)\n",
    "    numbers, scores, trainTimes, testTimes, trainAcc = [i[0] for i in data], [i[1] for i in data], [i[2] for i in data], [i[3] for i in data], [i[4] for i in data]\n",
    "    \n",
    "    plotData = [('numbers', numbers), ('scores', scores), ('train times', trainTimes), ('testTimes', testTimes), ('train accuracy', trainAcc)]\n",
    "    \n",
    "    df = pd.DataFrame.from_items(plotData)\n",
    "    df.to_csv(fileName)\n",
    "    \n",
    "    \n",
    "    #leanring curve\n",
    "    plt.plot(numbers, scores, 'bo')\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"% Accuracy\")\n",
    "    plt.show()\n",
    "    #train curve time\n",
    "    plt.plot(numbers, trainTimes, 'ro')\n",
    "    plt.title(\"Train Timing Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"Time (Seconds)\")\n",
    "    plt.show()\n",
    "    #test curve time\n",
    "    plt.plot(numbers, testTimes, 'ro')\n",
    "    plt.title(\"Test Timing Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"Time (Seconds)\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeHyperParameters(accuracies, fileName):\n",
    "    df = pd.DataFrame(list(accuracies.items()), columns = ['Hyper Parameter', 'Accuracy'])\n",
    "    df.to_csv(fileName)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestDecisionTree(data, bestSplit):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_data, y_data, X_test, y_test = data\n",
    "    \n",
    "    if bestSplit is None:\n",
    "        n = 5\n",
    "        kf = KFold(n_splits = n)\n",
    "        kf.get_n_splits(X_data)\n",
    "        hyperParameters = [x*2 for x in range(1, 100)]\n",
    "        accuracies = {}\n",
    "\n",
    "        for hyperParameter in hyperParameters:\n",
    "            averageAccuracy = 0\n",
    "            for train_index, validate_index in kf.split(X_data):\n",
    "                c = DecisionTreeClassifier(min_samples_split = hyperParameter)\n",
    "                X_train, X_validate = X_data.iloc[train_index], X_data.iloc[validate_index]\n",
    "                y_train, y_validate = y_data.iloc[train_index], y_data.iloc[validate_index]\n",
    "                dt = c.fit(X_train, y_train)\n",
    "                y_pred = c.predict(X_validate)\n",
    "                score = accuracy_score(y_validate, y_pred) *100\n",
    "                averageAccuracy += score\n",
    "            averageAccuracy = averageAccuracy/n\n",
    "            print(\"for the hyperParameter %d, the accuracy is %f\" % (hyperParameter, averageAccuracy))\n",
    "            accuracies[hyperParameter] = averageAccuracy\n",
    "\n",
    "        print(\"finished \\n\")\n",
    "        bestSplit = max(accuracies, key=accuracies.get)\n",
    "        storeHyperParameters(accuracies, 'decisionTreeHyperParameters.csv');\n",
    "        \n",
    "        print(\"best hyper parameter: %d\" % (max(accuracies, key=accuracies.get)))\n",
    "\n",
    "    print(\"Training Final Decision Tree Learner\")\n",
    "    c = DecisionTreeClassifier(min_samples_split = bestSplit)\n",
    "    \n",
    "    start = time.time()\n",
    "    dt = c.fit(X_data, y_data)\n",
    "    end = time.time()\n",
    "    trainTime = end - start\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = c.predict(X_test)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred) *100\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    y_train_pred = c.predict(X_data)\n",
    "    trainAcc = accuracy_score(y_data, y_train_pred) *100\n",
    "    \n",
    "    return (score, trainTime, testTime, bestSplit, trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/40.0) for i in range(1, 40)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "outputData = []\n",
    "\n",
    "bestHyperParameter = None;\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupData(finalData, i)\n",
    "    testValues = trainandTestDecisionTree(data, bestHyperParameter)\n",
    "    bestHyperParameter = testValues[3]\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'decisionTreeOutput.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestKNN(data, besthyperParameter):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_data, y_data, X_test, y_test = data\n",
    "    \n",
    "    n = 5\n",
    "    kf = KFold(n_splits = n)\n",
    "    kf.get_n_splits(X_data)\n",
    "    hyperParameterK = [x for x in range(1, 25)]\n",
    "    hyperParameterP = range(1, 5)\n",
    "    hyperParameters = list(itertools.product(hyperParameterK, hyperParameterP))\n",
    "    #hyperParameters = random.sample(hyperParameters, 50)\n",
    "    accuracies = {}\n",
    "\n",
    "    if besthyperParameter is None:\n",
    "        for hyperParameter in hyperParameters:\n",
    "            averageAccuracy = 0\n",
    "            for train_index, validate_index in kf.split(X_data):\n",
    "                c = KNeighborsClassifier(n_neighbors = hyperParameter[0], p = hyperParameter[1])\n",
    "                X_train, X_validate = X_data.iloc[train_index], X_data.iloc[validate_index]\n",
    "                y_train, y_validate = y_data.iloc[train_index], y_data.iloc[validate_index]\n",
    "                dt = c.fit(X_train, y_train)\n",
    "                y_pred = c.predict(X_validate)\n",
    "                score = accuracy_score(y_validate, y_pred) *100\n",
    "                averageAccuracy += score\n",
    "            averageAccuracy = averageAccuracy/n\n",
    "            print(\"for the hyperParameter %d, %d, the accuracy is %f\" % (hyperParameter[0], hyperParameter[1], averageAccuracy))\n",
    "            accuracies[hyperParameter] = averageAccuracy\n",
    "            storeHyperParameters(accuracies, 'KNNHyperParameters.csv')\n",
    "\n",
    "        print(\"finished \\n\")\n",
    "        besthyperParameter = max(accuracies, key=accuracies.get)\n",
    "        print(\"best hyper parameter: %d, %d\" % (besthyperParameter[0], besthyperParameter[1]))\n",
    "\n",
    "    print(\"Training Final KNN Learner\")\n",
    "    c = KNeighborsClassifier(n_neighbors = besthyperParameter[0], p = besthyperParameter[1])\n",
    "    \n",
    "    start = time.time()\n",
    "    dt = c.fit(X_data, y_data)\n",
    "    end = time.time()\n",
    "    trainTime = end - start\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = c.predict(X_test)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred) *100\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    y_train_pred = c.predict(X_data)\n",
    "    trainAcc = accuracy_score(y_data, y_train_pred) *100\n",
    "    \n",
    "    return (score, trainTime, testTime, besthyperParameter, trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/20) for i in range(1, 20)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "besthyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupData(finalData, i)\n",
    "    testValues = trainandTestKNN(data, besthyperParameter)\n",
    "    X_data = data[0]\n",
    "    besthyperParameter = testValues[3]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'KNNOutput.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestBoosting(data, besthyperParameter):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_data, y_data, X_test, y_test = data\n",
    "    \n",
    "    n = 5\n",
    "    kf = KFold(n_splits = n)\n",
    "    kf.get_n_splits(X_data)\n",
    "    hyperParameterEstimators = [x*2 for x in range(1, 50)]\n",
    "    hyperParameterLearningRate = [i * .05 for i in range(1, 100)]\n",
    "    hyperParameters = list(itertools.product(hyperParameterEstimators, hyperParameterLearningRate))\n",
    "    hyperParameters = random.sample(hyperParameters, 50)\n",
    "    accuracies = {}\n",
    "\n",
    "    if besthyperParameter is None:\n",
    "        for hyperParameter in hyperParameters:\n",
    "            averageAccuracy = 0\n",
    "            for train_index, validate_index in kf.split(X_data):\n",
    "                c = AdaBoostClassifier(n_estimators = hyperParameter[0], learning_rate = hyperParameter[1])\n",
    "                X_train, X_validate = X_data.iloc[train_index], X_data.iloc[validate_index]\n",
    "                y_train, y_validate = y_data.iloc[train_index], y_data.iloc[validate_index]\n",
    "                dt = c.fit(X_train, y_train)\n",
    "                y_pred = c.predict(X_validate)\n",
    "                score = accuracy_score(y_validate, y_pred) *100\n",
    "                averageAccuracy += score\n",
    "            averageAccuracy = averageAccuracy/n\n",
    "            print(\"for the hyperParameter %d, %d, the accuracy is %f\" % (hyperParameter[0], hyperParameter[1], averageAccuracy))\n",
    "            accuracies[hyperParameter] = averageAccuracy\n",
    "            storeHyperParameters(accuracies, 'BoostingHyperParameters.csv')\n",
    "\n",
    "        print(\"finished \\n\")\n",
    "        besthyperParameter = max(accuracies, key=accuracies.get)\n",
    "        print(\"best hyper parameter: %f, %f\" % (besthyperParameter[0], besthyperParameter[1]))\n",
    "\n",
    "    print(\"Training Final Boosting Learner\")\n",
    "    c = AdaBoostClassifier(n_estimators = besthyperParameter[0], learning_rate = besthyperParameter[1])\n",
    "    \n",
    "    start = time.time()\n",
    "    dt = c.fit(X_data, y_data)\n",
    "    end = time.time()\n",
    "    trainTime = end - start\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = c.predict(X_test)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred) *100\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    y_train_pred = c.predict(X_data)\n",
    "    trainAcc = accuracy_score(y_data, y_train_pred) *100\n",
    "    \n",
    "    return (score, trainTime, testTime, besthyperParameter, trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/20) for i in range(1, 20)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "besthyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupData(finalData, i)\n",
    "    testValues = trainandTestBoosting(data, besthyperParameter)\n",
    "    X_data = data[0]\n",
    "    besthyperParameter = testValues[3]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'boostingOutput.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupDataSVM(finalData, fraction):\n",
    "    \n",
    "    data, test = train_test_split(finalData, test_size = 0.2)\n",
    "    data = data.sample(frac = fraction)\n",
    "    \n",
    "    train, validate = train_test_split(data, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    features = [\"Sex\", \"Age\", \"Height\", \"Weight\", \"Team\", \"Sport\", \"Event\"]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train['Medal']\n",
    "    \n",
    "    X_validate = validate[features]\n",
    "    y_validate = validate['Medal']\n",
    "\n",
    "    X_test = test[features]\n",
    "    y_test = test[\"Medal\"]\n",
    "    return (X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestSVM(data, kernel, besthyperParameter, csvName):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = data\n",
    "    \n",
    "\n",
    "    hyperParameters = []\n",
    "    \n",
    "    hyperParameterDegree = range(1,11)\n",
    "    hyperParameterGamma = [i * 0.1 for i in range(1,10)]\n",
    "    hyperParameterTol = [i * 0.0004 for i in range (1, 10)]\n",
    "    \n",
    "    if kernel is 'poly':\n",
    "        hyperParameters = list(itertools.product(['rbf'], hyperParameterGamma, hyperParameterTol))\n",
    "        hyperParameters = random.sample(hyperParameters, 5)\n",
    "    else:\n",
    "        hyperParameters = list(itertools.product(['linear'], [3], ['auto'], hyperParameterTol))\n",
    "        hyperParameters = random.sample(hyperParameters, 5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    accuracies = {}\n",
    "    \n",
    "    if besthyperParameter is None:\n",
    "        for hyperParameter in hyperParameters:\n",
    "            c = svm.SVC(kernel = hyperParameter[0], degree = hyperParameter[1], gamma = hyperParameter[2], tol = hyperParameter[3])\n",
    "            print('started Training')\n",
    "            dt = c.fit(X_train, y_train)\n",
    "            print('stopped training')\n",
    "            y_pred = c.predict(X_validate)\n",
    "            score = accuracy_score(y_validate, y_pred) *100\n",
    "            accuracy = score\n",
    "            print(\"for the hyperParameter %s, %f, %f, %f the accuracy is %f\", hyperParameter[0], hyperParameter[1], hyperParameter[2], hyperParameter[3], accuracy)\n",
    "            accuracies[hyperParameter] = accuracy\n",
    "            \n",
    "\n",
    "        print(\"finished \\n\")\n",
    "        besthyperParameter = max(accuracies, key=accuracies.get)\n",
    "        print(\"best hyper parameter: %s, %f, %f, %f\" , hyperParameter[0], hyperParameter[1], hyperParameter[2], hyperParameter[3])\n",
    "        storeHyperParameters(accuracies, csvName)\n",
    "    \n",
    "    print(\"Training Final SVM Learner\")\n",
    "    c = svm.SVC(kernel = besthyperParameter[0], degree = besthyperParameter[1], gamma = besthyperParameter[2], tol = besthyperParameter[3])\n",
    "    \n",
    "    start = time.time()\n",
    "    dt = c.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    trainTime = end - start\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = c.predict(X_test)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred) *100\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    y_train_pred = c.predict(X_train)\n",
    "    trainAcc = accuracy_score(y_train, y_train_pred) *100\n",
    "    \n",
    "    return (score, trainTime, testTime, besthyperParameter, trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/8) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "besthyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataSVM(finalData, i)\n",
    "    testValues = trainandTestSVM(data, 'linear', besthyperParameter, 'SVMLinearHP.csv')\n",
    "    besthyperParameter = testValues[3]\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'SVMLinearOutput.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 10)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "besthyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataSVM(finalData, i)\n",
    "    testValues = trainandTestSVM(data, 'rbf', besthyperParameter, 'SVMRBFHP.csv')\n",
    "    besthyperParameter = testValues[3]\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'SVMRBFOutput.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupDataNN(finalData, fraction):\n",
    "    \n",
    "    data, test = train_test_split(finalData, test_size = 0.2)\n",
    "    data = data.sample(frac = fraction)\n",
    "    \n",
    "    train, validate = train_test_split(data, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    features = [\"Sex\", \"Age\", \"Height\", \"Weight\", \"Team\", \"Sport\", \"Event\"]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train['Medal']\n",
    "    \n",
    "    X_validate = validate[features]\n",
    "    y_validate = validate['Medal']\n",
    "\n",
    "    X_test = test[features]\n",
    "    y_test = test[\"Medal\"]\n",
    "    return (X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupModel():\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras import optimizers\n",
    "    import random\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(55, input_dim = 7, activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(55, activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDictToCSV(dictionary, fileName):\n",
    "    df = pd.DataFrame(list(dictionary.items()), columns = ['epochs', 'Accuracy'])\n",
    "    df.to_csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestNeuralNetwork(data, bestHyperParameter):\n",
    "   \n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras import optimizers\n",
    "    import random\n",
    "\n",
    "\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = data\n",
    "\n",
    "\n",
    "    hyperParametersLR = [.0001, .003, .05, .8]\n",
    "    hyperParametersM = [.2, .5, .8]\n",
    "    hyperParameters = list(itertools.product(hyperParametersLR, hyperParametersM))\n",
    "\n",
    "    accuracies = {}\n",
    "\n",
    "\n",
    "    #one-hot encoding\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes = 2)\n",
    "    y_validate = keras.utils.to_categorical(y_validate, num_classes = 2)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes = 2)\n",
    "    \n",
    "    \n",
    "    firstTime = False\n",
    "    if bestHyperParameter is None:\n",
    "        firstTime = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    if bestHyperParameter is None:\n",
    "        for hyperParameter in hyperParameters:\n",
    "            model = setupModel()\n",
    "            sgd = optimizers.SGD(lr = hyperParameter[0], decay = 1e-6, momentum = hyperParameter[1], nesterov=True)\n",
    "            model.compile(loss = 'mean_squared_error', optimizer = sgd, metrics=[\"mean_squared_error\", 'accuracy'])\n",
    "\n",
    "            model.fit(X_train, y_train, epochs = 1500, batch_size = 128)\n",
    "\n",
    "            score1, score2, acc = model.evaluate(X_validate, y_validate, batch_size = 128)\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"for the hyperParameter %d, the accuracy is %f\" , hyperParameter, score1, score2, acc)\n",
    "            accuracies[hyperParameter] = acc\n",
    "\n",
    "        print(\"finished \\n\")\n",
    "        bestHyperParameter = max(accuracies, key=accuracies.get)\n",
    "        print(\"best hyper parameter: %d\" , bestHyperParameter[0], bestHyperParameter[1])\n",
    "        storeHyperParameters(accuracies, 'NeuralNetHP.csv')\n",
    "\n",
    "    model = setupModel()    \n",
    "    sgd = optimizers.SGD(lr = bestHyperParameter[0], decay = 1e-6, momentum = bestHyperParameter[1], nesterov=True)\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = sgd, metrics=[\"mean_squared_error\", 'accuracy'])\n",
    "    \n",
    "    start = time.time()\n",
    "    if firstTime:\n",
    "        learningCurveIterations = {}\n",
    "        counter = 0;\n",
    "        for i in range (1, 100):\n",
    "            model.fit(X_train, y_train, epochs = 15, batch_size = 32)\n",
    "            counter += 10\n",
    "            end = time.time()\n",
    "            score1,score2, acc = model.evaluate(X_test, y_test, batch_size = 32)\n",
    "            scoreTrain1, scoreTrain2, accTrain = model.evaluate(X_train, y_train, batch_size = 32)\n",
    "            learningCurveIterations[counter] = (acc, accTrain)\n",
    "        writeDictToCSV(learningCurveIterations, 'nnlearningIterations.csv')\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs = 1500, batch_size = 32)\n",
    "        end = time.time()\n",
    "    trainTime = end - start\n",
    "        \n",
    "    start = time.time()\n",
    "    performance1, performance2, score = model.evaluate(X_test, y_test, batch_size = 32)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    performance1, performance2, trainAcc = model.evaluate(X_train, y_train, batch_size = 32)\n",
    "\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    return (score, trainTime, testTime, bestHyperParameter, trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalData = importData('finalDataOlympics.csv')\n",
    "\n",
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter)\n",
    "    bestHyperParameter = testValues[3]\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[4]))\n",
    "    \n",
    "makePlots(outputData, 'NeuralNet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
