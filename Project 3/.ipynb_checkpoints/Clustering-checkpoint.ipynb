{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Things and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#random things\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#data stuff\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn stuff\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.mixture import GaussianMixture\n",
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "#import Neural Net stuff\n",
    "import keras\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering and just regular importing\n",
    "def importData(fileName):\n",
    "    finalData = pd.read_csv(fileName)\n",
    "    finalData.count()\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "\n",
    "    for column in finalData.columns:\n",
    "        if finalData[column].dtype == type(object):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            finalData[column] = le.fit_transform(finalData[column])\n",
    "                        \n",
    "    return (finalData.sample(frac = 1))#.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K_Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K vs Distortion\n",
    "- K = num_classes of output variable of NN\n",
    "    - check the output variable value for each cluster and see how well the cluster splits the data for the output variable\n",
    "- TODO_ADD: store ideal K and Make Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K vs Distortion - to get elbow graph to find the otpimal k\n",
    "\n",
    "\n",
    "\n",
    "# importing the data\n",
    "X = importData('finalDataNursing.csv') #TODO: Put the right csv Name\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k for Nursing Data (K_Means)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = num_classes of output\n",
    "num_class = 2 #TODO: Make sure this is correct for each dataset\n",
    "class_names = ['medal', 'no_medal'] #TODO: Make sure this is correct - put the right class names in the order u see them\n",
    "\n",
    "\n",
    "#importing the data\n",
    "X = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "kmeanModel = KMeans(n_clusters = num_class).fit(X)\n",
    "\n",
    "#creating a list for single class\n",
    "classes = list(X[\"Medal\"]) #TODO: Make sure the target feature is correct\n",
    "\n",
    "\n",
    "table = np.zeros(shape = (num_class, num_class))\n",
    "for i in range(0, len(classes)):\n",
    "    cluster = kmeanModel.labels_[i]\n",
    "    classNum = classes[i]\n",
    "    table[cluster, classNum] += 1\n",
    "for i,j in itertools.product(list(range(0,num_class)), list(range(0,num_class))):\n",
    "    table[i,j] = float(table[i,j])/float(len(classes))\n",
    "    \n",
    "cluster_to_class = pd.DataFrame(list(table),columns=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K vs Distortion\n",
    "- K = num_classes of output variable of NN\n",
    "    - check the output variable value for each cluster and see how well the cluster splits the data for the output variable\n",
    "- TODO_ADD: store ideal K and Make Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimationError(X, gaussianModel):\n",
    "    sum = 0\n",
    "    probabilities = gaussianModel.predict_proba(X)\n",
    "    for j in range(0,X.shape[0]):\n",
    "        tempsum = 0\n",
    "        probas = probabilities[j]\n",
    "        for i in range(0,len(probas)):\n",
    "            tempsum += np.linalg.norm(X.iloc[j] - gaussianModel.means_[i])* probas[i]\n",
    "        sum += tempsum\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K vs Distortion - to get elbow graph to find the otpimal k\n",
    "\n",
    "\n",
    "\n",
    "# importing the data\n",
    "X = importData('finalDataOlympics.csv') #TODO: Put the right csv Name\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    gaussianModel = GaussianMixture(n_components = k)\n",
    "    gaussianModel.fit(X)\n",
    "    distortions.append(estimationError(X, gaussianModel))\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X)\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = num_classes of output\n",
    "num_class = 3 #TODO: Make sure this is correct for each dataset\n",
    "class_names = [\"Not Recommended\", \"Priority\", \"Special Priority\"] #TODO: Make sure this is correct - put the right class names in the order u see them\n",
    "\n",
    "\n",
    "#importing the data\n",
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "gaussianModel = GaussianMixture(n_components = num_class)\n",
    "gaussianModel.fit(X)\n",
    "\n",
    "#creating a list for single class\n",
    "classes = list(X[\"app_status\"]) #TODO: Make sure the target feature is correct\n",
    "\n",
    "labels_ = gaussianModel.predict(X)\n",
    "\n",
    "table = np.zeros(shape = (num_class, num_class))\n",
    "for i in range(0, len(classes)):\n",
    "    cluster = labels_[i]\n",
    "    classNum = classes[i]\n",
    "    table[cluster, classNum] += 1\n",
    "for i,j in itertools.product(list(range(0,num_class)), list(range(0,num_class))):\n",
    "    table[i,j] = float(table[i,j])/float(len(classes))\n",
    "    \n",
    "cluster_to_class = pd.DataFrame(list(table),columns=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K Means<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K vs Distortion - to get elbow graph to find the otpimal k\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Expectation Maximization<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "ica = FastICA()\n",
    "ica.fit(X)\n",
    "X = ica.transform(X)\n",
    "totalMutualInformation = 0\n",
    "counter = 0\n",
    "for i, j in itertools.product(list(range(0, len(X[0]))), list(range(0, len(X[0])))):\n",
    "    if i != j:\n",
    "        print(X[:,i])\n",
    "        print(X[:,j])\n",
    "        totalMutualInformation += mutual_info_score(X[:,i], X[:,j])\n",
    "        counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA()\n",
    "ica.fit(X)\n",
    "X = ica.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K Means<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 2 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "X_new = SelectKBest(mutual_info_classif, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = num_classes of output\n",
    "num_class = 2 #TODO: Make sure this is correct for each dataset\n",
    "class_names = ['medal', 'no_medal'] #TODO: Make sure this is correct - put the right class names in the order u see them\n",
    "\n",
    "\n",
    "#importing the data\n",
    "X_full = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "kmeanModel = KMeans(n_clusters = num_class).fit(X)\n",
    "\n",
    "#creating a list for single class\n",
    "classes = list(X_full[\"Medal\"]) #TODO: Make sure the target feature is correct\n",
    "\n",
    "\n",
    "table = np.zeros(shape = (num_class, num_class))\n",
    "for i in range(0, len(classes)):\n",
    "    cluster = kmeanModel.labels_[i]\n",
    "    classNum = classes[i]\n",
    "    table[cluster, classNum] += 1\n",
    "for i,j in itertools.product(list(range(0,num_class)), list(range(0,num_class))):\n",
    "    table[i,j] = float(table[i,j])/float(len(classes))\n",
    "    \n",
    "cluster_to_class = pd.DataFrame(list(table),columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Expectation Maximization<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idealK = 2 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X)\n",
    "X_new = SelectKBest(mutual_info_classif, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "X = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "rp = GaussianRandomProjection(n_components = len(X.columns))\n",
    "rp.fit(X)\n",
    "X = rp.transform(X)\n",
    "variances = []\n",
    "for i in range(0,len(X[0])):\n",
    "    variances.append(np.var(X[:,i]))\n",
    "print(np.sort(variances/(sum(variances))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K Means<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "X_new = SelectKBest(mutual_info_classif, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = num_classes of output\n",
    "num_class = 2 #TODO: Make sure this is correct for each dataset\n",
    "class_names = ['medal', 'no_medal'] #TODO: Make sure this is correct - put the right class names in the order u see them\n",
    "\n",
    "\n",
    "#importing the data\n",
    "X_full = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "kmeanModel = KMeans(n_clusters = num_class).fit(X)\n",
    "\n",
    "#creating a list for single class\n",
    "classes = list(X_full[\"Medal\"]) #TODO: Make sure the target feature is correct\n",
    "\n",
    "\n",
    "table = np.zeros(shape = (num_class, num_class))\n",
    "for i in range(0, len(classes)):\n",
    "    cluster = kmeanModel.labels_[i]\n",
    "    classNum = classes[i]\n",
    "    table[cluster, classNum] += 1\n",
    "for i,j in itertools.product(list(range(0,num_class)), list(range(0,num_class))):\n",
    "    table[i,j] = float(table[i,j])/float(len(classes))\n",
    "    \n",
    "cluster_to_class = pd.DataFrame(list(table),columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Expectation Maximization<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X)\n",
    "X_new = SelectKBest(mutual_info_classif, k=2).fit_transform(X, y)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "X = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "y = X['Medal']\n",
    "X = X.drop(\"Medal\", axis=1)\n",
    "\n",
    "X = X.values\n",
    "variances = []\n",
    "for i in range(0,len(X[0])):\n",
    "    variances.append(np.var(X[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "X_new1 = SelectKBest(mutual_info_classif, k=2).fit_transform(X, y)\n",
    "variances = []\n",
    "for i in range(0,len(X_new1[0])):\n",
    "    variances.append(np.var(X_new1[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = SelectKBest(chi2, k=2).fit_transform(X,y)\n",
    "variances = []\n",
    "for i in range(0,len(X[0])):\n",
    "    variances.append(np.var(X[:,i]))\n",
    "print(np.sort(variances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "X.drop('Medal', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K Means<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = num_classes of output\n",
    "num_class = 2 #TODO: Make sure this is correct for each dataset\n",
    "class_names = ['medal', 'no_medal'] #TODO: Make sure this is correct - put the right class names in the order u see them\n",
    "\n",
    "\n",
    "#importing the data\n",
    "X_full = importData('finalDataOlympics.csv') #TODO: put the right csv name\n",
    "kmeanModel = KMeans(n_clusters = num_class).fit(X)\n",
    "\n",
    "#creating a list for single class\n",
    "classes = list(X_full[\"Medal\"]) #TODO: Make sure the target feature is correct\n",
    "\n",
    "\n",
    "table = np.zeros(shape = (num_class, num_class))\n",
    "for i in range(0, len(classes)):\n",
    "    cluster = kmeanModel.labels_[i]\n",
    "    classNum = classes[i]\n",
    "    table[cluster, classNum] += 1\n",
    "for i,j in itertools.product(list(range(0,num_class)), list(range(0,num_class))):\n",
    "    table[i,j] = float(table[i,j])/float(len(classes))\n",
    "    \n",
    "cluster_to_class = pd.DataFrame(list(table),columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Expectation Maximization<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealK = 4 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X)\n",
    "\n",
    "# Prepare for Graph\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Stuff - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupDataNN(finalData, fraction):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    train, test = train_test_split(finalData, test_size = 0.2)\n",
    "#     train = train.sample(frac = fraction)\n",
    "    train = train[np.random.choice(train.shape[0],int(fraction*train.shape[0]),replace=False)]\n",
    "        \n",
    "    X_train = train[:,:len(finalData[0])-1]\n",
    "    y_train = train[:,len(finalData[0])-1]\n",
    "\n",
    "    X_test = test[:,:len(finalData[0])-1]\n",
    "    y_test = test[:,len(finalData[0])-1]\n",
    "                    \n",
    "    #one hot encoding\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes = 3)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes = 3)\n",
    "    \n",
    "    print(y_train)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(data, fileName):\n",
    "    print(data)\n",
    "    numbers, scores, trainTimes, testTimes, trainAcc = [i[0] for i in data], [i[1] for i in data], [i[2] for i in data], [i[3] for i in data], [i[4] for i in data]\n",
    "    \n",
    "    plotData = [('numbers', numbers), ('scores', scores), ('train times', trainTimes), ('testTimes', testTimes), ('train accuracy', trainAcc)]\n",
    "    \n",
    "    df = pd.DataFrame.from_items(plotData)\n",
    "    df.to_csv(fileName)\n",
    "    \n",
    "    \n",
    "    #leanring curve\n",
    "    plt.plot(numbers, scores, 'bo')\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"% Accuracy\")\n",
    "    plt.show()\n",
    "    #train curve time\n",
    "    plt.plot(numbers, trainTimes, 'ro')\n",
    "    plt.title(\"Train Timing Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"Time (Seconds)\")\n",
    "    plt.show()\n",
    "    #test curve time\n",
    "    plt.plot(numbers, testTimes, 'ro')\n",
    "    plt.title(\"Test Timing Curve\")\n",
    "    plt.xlabel(\"Number of Examples\")\n",
    "    plt.ylabel(\"Time (Seconds)\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDictToCSV(dictionary, fileName):\n",
    "    df = pd.DataFrame(list(dictionary.items()), columns = ['epochs', 'Accuracy'])\n",
    "    df.to_csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupModel(inputNum):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras import optimizers\n",
    "    import random\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(55, input_dim = inputNum, activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(55, activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, inputNum):\n",
    "   \n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras import optimizers\n",
    "    import random\n",
    "    import time\n",
    "\n",
    "\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "\n",
    "\n",
    "    accuracies = {}\n",
    "    \n",
    "\n",
    "    model = setupModel(inputNum)    \n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=[\"mean_squared_error\", 'accuracy'])\n",
    "    \n",
    "    start = time.time()\n",
    "    if firstTime != '':\n",
    "        learningCurveIterations = {}\n",
    "        counter = 0;\n",
    "        for i in range (1, 20):\n",
    "            model.fit(X_train, y_train, epochs = 15, batch_size = 32)\n",
    "            counter += 10\n",
    "            end = time.time()\n",
    "            score1,score2, acc = model.evaluate(X_test, y_test, batch_size = 32)\n",
    "            scoreTrain1, scoreTrain2, accTrain = model.evaluate(X_train, y_train, batch_size = 32)\n",
    "            learningCurveIterations[counter] = (acc, accTrain)\n",
    "        writeDictToCSV(learningCurveIterations, firstTime)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs = 300, batch_size = 32)\n",
    "        end = time.time()\n",
    "    trainTime = end - start\n",
    "        \n",
    "    start = time.time()\n",
    "    performance1, performance2, score = model.evaluate(X_test, y_test, batch_size = 32)\n",
    "    end = time.time()\n",
    "    testTime = end - start\n",
    "    \n",
    "    performance1, performance2, trainAcc = model.evaluate(X_train, y_train, batch_size = 32)\n",
    "\n",
    "    print(\"The Score is %f\" % (score))\n",
    "    \n",
    "    return (score, trainTime, testTime, trainAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCA<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "pca.fit(X_inputs)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2) #set based on variance ratio\n",
    "pca.fit(X_inputs)\n",
    "X_inputs = pca.transform(X_inputs)\n",
    "\n",
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsPCA.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 2)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetPCA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.1786 - mean_squared_error: 0.1786 - acc: 0.6034\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6718\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.1217 - mean_squared_error: 0.1217 - acc: 0.7581\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0967 - mean_squared_error: 0.0967 - acc: 0.8238\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0763 - mean_squared_error: 0.0763 - acc: 0.8629\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0668 - mean_squared_error: 0.0668 - acc: 0.8796\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0627 - mean_squared_error: 0.0627 - acc: 0.8826\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0538 - mean_squared_error: 0.0538 - acc: 0.9019\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0519 - mean_squared_error: 0.0519 - acc: 0.9033\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0488 - mean_squared_error: 0.0488 - acc: 0.91130s - loss: 0.0371 - mean_squar\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0444 - mean_squared_error: 0.0444 - acc: 0.9234\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9149\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9249\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9239\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0463 - acc: 0.91 - 1s 91us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9144\n",
      "2526/2526 [==============================] - 0s 72us/step\n",
      "8083/8083 [==============================] - 0s 46us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9230\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.93200s - loss: 0.0382 - mean_squared_error: 0.0382 -\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9192\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0462 - mean_squared_error: 0.0462 - acc: 0.91270s - loss: 0.0404 - mean_squared_error: \n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0481 - mean_squared_error: 0.0481 - acc: 0.9096\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9240\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.92000s - loss: 0.0339 - mean_squ\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.93860s - loss: 0.0403 - mean_squar\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9362\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9339\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9310\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9229\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9307\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9261\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9312\n",
      "2526/2526 [==============================] - 0s 58us/step\n",
      "8083/8083 [==============================] - 0s 52us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9358\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0450 - mean_squared_error: 0.0450 - acc: 0.9187\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9186\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9320\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9322\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 199us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.93011s - loss: 0.0378 - mean_squared_e\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 183us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9339\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 306us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9217\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.0483 - mean_squared_error: 0.0483 - acc: 0.9125\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0418 - mean_squared_error: 0.0418 - acc: 0.9228\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9303\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9344\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 269us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.91590s - loss: 0.0380 - mean_squared_error: 0.0380 - - ETA: \n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.92400s - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.92 - 2s 230us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9299\n",
      "2526/2526 [==============================] - 0s 121us/step\n",
      "8083/8083 [==============================] - 1s 116us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9316\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 199us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.92280s - loss: 0.0415 - mean_squared_error: \n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9332\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9291\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9274\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9292\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 225us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9297\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 276us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9311\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9322\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9375\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9333\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9285 0s - loss: 0.0429 - mean_squared_err\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9321\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.93310s - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0. - ETA: 0s - loss: 0.0381 - mean_squared_err\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 218us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9419\n",
      "2526/2526 [==============================] - 0s 162us/step\n",
      "8083/8083 [==============================] - 0s 47us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9404\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.91400s - loss: 0.0360 - me\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9192\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9209\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9337\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9406\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9395\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9482\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9273\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9406\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9311\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9337\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.9284\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9273 0s - loss: 0.0400 - mean_squared_error: 0.0400 - acc\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9362\n",
      "2526/2526 [==============================] - 0s 46us/step\n",
      "8083/8083 [==============================] - 0s 43us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9462\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9472\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9537\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9519\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9261\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9446\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9524\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9514\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9508\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9489 0s - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.94\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.93620s - loss: 0.0314 - mean_squared_error: 0.\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9344\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9482\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9302\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9401\n",
      "2526/2526 [==============================] - 0s 81us/step\n",
      "8083/8083 [==============================] - 1s 94us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 192us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9404\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.94890s - loss: 0.0331 - mean_squar\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9487\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9436\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9534\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9442\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.93 - 1s 130us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9294\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9442\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9541\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 199us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9525\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 177us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.95320s - loss: 0.0333 - mean_squared_error\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9555\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9514\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9396\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9459\n",
      "2526/2526 [==============================] - 0s 46us/step\n",
      "8083/8083 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9527\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9563\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9466\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9449\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9607\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9506\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.94992s - loss: 0.0265 - mean_squared_error: 0.0265 - acc: 0.95 - ETA: 2s - loss: 0.0210 - mean_squared_error:  - ETA: 0s - loss: 0.0330 - mean_squared\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0239 - mean_squared_error: 0.0239 - acc: 0.9613\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9572\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9431\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9482\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.95630s - loss: 0.0270 - mean_squared_error: 0.0270 - a\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9534\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9607\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9537\n",
      "2526/2526 [==============================] - 0s 48us/step\n",
      "8083/8083 [==============================] - 0s 62us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9301\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9381\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9416\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9526\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9498\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9479\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9494\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9484\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.94460s - loss: 0.0359 \n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.92921s - loss: 0.041\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9384\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.95 - 1s 122us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9519\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.94980s - loss: 0.0332 - mean_squared_err\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9503\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9558\n",
      "2526/2526 [==============================] - 0s 40us/step\n",
      "8083/8083 [==============================] - 0s 48us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9555\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9531\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 193us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9464\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9475\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9445\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9398\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9354\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.93230s - loss: 0.0406 - mean_squared_error: 0.0406 - acc: \n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9436\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9553\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9567\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.94740s - loss: 0.0311 - mean_squared_error: \n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9514\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.95110s - loss: 0.0253 - mean\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9369\n",
      "2526/2526 [==============================] - 0s 49us/step\n",
      "8083/8083 [==============================] - 0s 47us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9419\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9394\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9443\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9532\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.94950s - loss: 0.0303 - mean_squared_error: 0.0303 - acc: \n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9537\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9485\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9514\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9563 0s - loss: 0.0212 - mean_squared_err\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9561\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9432\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9436\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9543\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9602\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.9615 0s - loss: 0.0253 - mean_squared_error\n",
      "2526/2526 [==============================] - 0s 50us/step\n",
      "8083/8083 [==============================] - 0s 42us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.95360s - loss: 0.0198 - mean_s\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9470\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9568\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9541\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9548\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9453\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9378\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9484\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9261\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9416\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.94670s - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.94\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9504\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9484\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9346\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9389\n",
      "2526/2526 [==============================] - 0s 47us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9433\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.91920s - loss: 0.0493 - mean_squared_e\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9383\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9383\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9332\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9414\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.94940s - loss: 0.0263 - mean_squared_error\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9526\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9472\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9365\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9451\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9441\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9522\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9492\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9469\n",
      "2526/2526 [==============================] - 0s 46us/step\n",
      "8083/8083 [==============================] - 0s 46us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9505\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9437\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 266us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9238\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 3s 384us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.93550s - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 3s 328us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9445\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9438\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.95210s - loss: 0.0290 - mean_squared_error: 0.0290 - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.02\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9529\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 208us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.95140s - loss: 0.0279 - mean_squared_error: 0.\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 237us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9423\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9385\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9323\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9302\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9456\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9411\n",
      "2526/2526 [==============================] - 0s 45us/step\n",
      "8083/8083 [==============================] - 0s 48us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9320\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9421\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.94250s - loss: 0.0341 - mean_squared_error: 0.\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9362\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9541\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9526\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0265 - mean_squared_error: 0.0265 - acc: 0.9578\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0249 - mean_squared_error: 0.0249 - acc: 0.95 - 1s 124us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9524\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9536\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9588\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.95780s - loss: 0.0347 - mean\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9527\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9557\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9399\n",
      "2526/2526 [==============================] - 0s 72us/step\n",
      "8083/8083 [==============================] - 1s 66us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9449\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9448\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9420\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9483\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9457\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9487\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9513\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9556\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9560\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9577\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9553\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9608\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9573\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9581\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9612\n",
      "2526/2526 [==============================] - 0s 51us/step\n",
      "8083/8083 [==============================] - 0s 50us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9661\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9550\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9542\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9524\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9581\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9548\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9474\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9602\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9593\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9445\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9374\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9508\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9545\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9464\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9515\n",
      "2526/2526 [==============================] - 0s 44us/step\n",
      "8083/8083 [==============================] - 0s 42us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9539\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9493\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9539\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9605\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9604\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9614\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9560\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9561\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9594\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9534\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9615\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9609\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9537\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0256 - mean_squared_error: 0.0256 - acc: 0.9597\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.95610s - loss: 0.0273 - mean_squ\n",
      "2526/2526 [==============================] - 0s 67us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9416\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9503\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9615\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9602\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9535\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9582\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0498 - mean_squared_error: 0.0498 - acc: 0.9134\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9352\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9433\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9478\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.95770s - loss: 0.0272 - mean_squared_error: 0.0272 - acc\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 179us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9584\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.95160s - loss: 0.0284 - mean_squared_error: \n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9520\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.95400s - loss: 0.0267 - mean_squared_error\n",
      "2526/2526 [==============================] - 0s 57us/step\n",
      "8083/8083 [==============================] - 0s 50us/step\n",
      "2526/2526 [==============================] - 0s 49us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "The Score is 0.972684\n",
      "current iteration fraction: 0.700000\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 2s 226us/step - loss: 0.1770 - mean_squared_error: 0.1770 - acc: 0.6055\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1558 - mean_squared_error: 0.1558 - acc: 0.6546\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.1410 - mean_squared_error: 0.1410 - acc: 0.70230s - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.70\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1280 - mean_squared_error: 0.1280 - acc: 0.7361\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1065 - mean_squared_error: 0.1065 - acc: 0.8027\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0801 - mean_squared_error: 0.0801 - acc: 0.8630\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0706 - mean_squared_error: 0.0706 - acc: 0.8819\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0630 - mean_squared_error: 0.0630 - acc: 0.89420s - loss: 0.0646 - mean_squared_error: 0.0646\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0557 - mean_squared_error: 0.0557 - acc: 0.9051\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0490 - mean_squared_error: 0.0490 - acc: 0.91800s - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9207\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0473 - mean_squared_error: 0.0473 - acc: 0.9210\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.0440 - mean_squared_error: 0.0440 - acc: 0.9255\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0680 - mean_squared_error: 0.0680 - acc: 0.87920s - loss: 0.0781 - mean_squared_error: 0.0781\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0465 - mean_squared_error: 0.0465 - acc: 0.9239\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0466 - mean_squared_error: 0.0466 - acc: 0.9195\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 2s 237us/step - loss: 0.0449 - mean_squared_error: 0.0449 - acc: 0.9246\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 182us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9259\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9334\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 194us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9256\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 193us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.93681s - loss: 0\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 207us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.93810s - loss: 0.0343 \n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - 3s 383us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9338\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 2s 276us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.92292s - loss: 0\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 159us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9419\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 184us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9395\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.93920s - loss: 0.0436 - mean_squar\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9167\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9316\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 151us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9371\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9311\n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.94150s - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.94240s - loss: 0.0367 - mean_squared_error: 0.\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9406\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - 1s 200us/step - loss: 0.0569 - mean_squared_error: 0.0569 - acc: 0.8954\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.0519 - mean_squared_error: 0.0519 - acc: 0.9096\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9409\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9357\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 2s 271us/step - loss: 0.0433 - mean_squared_error: 0.0433 - acc: 0.92750s - loss: 0.0421 - mean_squared_err\n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 3s 364us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9352\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 173us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9314\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 3s 357us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9437\n",
      "Epoch 43/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9531\n",
      "Epoch 44/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9347\n",
      "Epoch 45/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9296\n",
      "Epoch 46/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9311\n",
      "Epoch 47/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.0427 - mean_squared_error: 0.0427 - acc: 0.9256\n",
      "Epoch 48/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9321\n",
      "Epoch 49/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9446\n",
      "Epoch 50/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9467\n",
      "Epoch 51/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9376\n",
      "Epoch 52/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9416\n",
      "Epoch 53/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9392\n",
      "Epoch 54/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9320\n",
      "Epoch 55/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9335\n",
      "Epoch 56/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9340\n",
      "Epoch 57/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9173\n",
      "Epoch 58/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9342\n",
      "Epoch 59/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9522\n",
      "Epoch 60/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9398\n",
      "Epoch 61/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0444 - mean_squared_error: 0.0444 - acc: 0.9252 0s - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "Epoch 62/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9371\n",
      "Epoch 63/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9359\n",
      "Epoch 64/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9482\n",
      "Epoch 65/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9463\n",
      "Epoch 66/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9229\n",
      "Epoch 67/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9170\n",
      "Epoch 68/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9359\n",
      "Epoch 69/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9440\n",
      "Epoch 70/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9522\n",
      "Epoch 71/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9262\n",
      "Epoch 72/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9283\n",
      "Epoch 73/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9299\n",
      "Epoch 74/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9406 0s - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.94\n",
      "Epoch 75/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9432 0s - loss: 0.0326 - mean_squared_error\n",
      "Epoch 76/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.9241\n",
      "Epoch 77/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9422\n",
      "Epoch 78/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9553\n",
      "Epoch 79/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9495\n",
      "Epoch 80/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9501\n",
      "Epoch 81/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9497\n",
      "Epoch 82/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9449\n",
      "Epoch 83/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9471\n",
      "Epoch 84/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9499\n",
      "Epoch 85/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9507\n",
      "Epoch 86/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9386\n",
      "Epoch 87/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9498\n",
      "Epoch 88/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9491\n",
      "Epoch 89/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9420\n",
      "Epoch 90/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9508\n",
      "Epoch 91/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9504\n",
      "Epoch 92/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9514\n",
      "Epoch 93/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9504\n",
      "Epoch 94/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9509\n",
      "Epoch 95/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9589\n",
      "Epoch 96/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9492\n",
      "Epoch 97/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0515 - mean_squared_error: 0.0515 - acc: 0.9072 0s - loss: 0.0542 - mean_squared_error: 0.0542 - acc\n",
      "Epoch 98/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9340\n",
      "Epoch 99/300\n",
      "7072/7072 [==============================] - 1s 89us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9475\n",
      "Epoch 100/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9447\n",
      "Epoch 101/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9509\n",
      "Epoch 102/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9491\n",
      "Epoch 103/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9340\n",
      "Epoch 104/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9477\n",
      "Epoch 105/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9470\n",
      "Epoch 106/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9473\n",
      "Epoch 107/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9381\n",
      "Epoch 108/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9473\n",
      "Epoch 109/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9381\n",
      "Epoch 110/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9487\n",
      "Epoch 111/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9512\n",
      "Epoch 112/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9542\n",
      "Epoch 113/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9523\n",
      "Epoch 114/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9443\n",
      "Epoch 115/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9507\n",
      "Epoch 116/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9382 0s - loss: 0.0351 - mean_squared_error: 0.0351 - a\n",
      "Epoch 117/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9385\n",
      "Epoch 118/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9383\n",
      "Epoch 119/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9156\n",
      "Epoch 120/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9330\n",
      "Epoch 121/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9337\n",
      "Epoch 122/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9323\n",
      "Epoch 123/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9149\n",
      "Epoch 124/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9344\n",
      "Epoch 125/300\n",
      "7072/7072 [==============================] - 1s 86us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9412\n",
      "Epoch 126/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9468\n",
      "Epoch 127/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9494\n",
      "Epoch 128/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9487 0s - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.\n",
      "Epoch 129/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9447\n",
      "Epoch 130/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9539\n",
      "Epoch 131/300\n",
      "7072/7072 [==============================] - 1s 159us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9456\n",
      "Epoch 132/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9603\n",
      "Epoch 133/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0239 - mean_squared_error: 0.0239 - acc: 0.9625\n",
      "Epoch 134/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9426\n",
      "Epoch 135/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9439\n",
      "Epoch 136/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9504 0s - loss: 0.0297 - mean_squared_error: 0.0297 -\n",
      "Epoch 137/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9451\n",
      "Epoch 138/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9540\n",
      "Epoch 139/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9492\n",
      "Epoch 140/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0472 - mean_squared_error: 0.0472 - acc: 0.9149\n",
      "Epoch 141/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9241\n",
      "Epoch 142/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0400 - mean_squared_error: 0.0400 - acc: 0.9303\n",
      "Epoch 143/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0558 - mean_squared_error: 0.0558 - acc: 0.8935\n",
      "Epoch 144/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0505 - mean_squared_error: 0.0505 - acc: 0.9101\n",
      "Epoch 145/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.91600s - loss: 0.0455 - mean_squared_error: 0.0455 - acc: \n",
      "Epoch 146/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0461 - mean_squared_error: 0.0461 - acc: 0.9198\n",
      "Epoch 147/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.0560 - mean_squared_error: 0.0560 - acc: 0.89760s - loss: 0.0574 - mean_squared_error: 0.0574 - acc: 0.\n",
      "Epoch 148/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9194\n",
      "Epoch 149/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9255\n",
      "Epoch 150/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9211\n",
      "Epoch 151/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9246\n",
      "Epoch 152/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0524 - mean_squared_error: 0.0524 - acc: 0.9029\n",
      "Epoch 153/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9252\n",
      "Epoch 154/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9324\n",
      "Epoch 155/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9326\n",
      "Epoch 156/300\n",
      "7072/7072 [==============================] - 1s 151us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9374\n",
      "Epoch 157/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9354\n",
      "Epoch 158/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9432\n",
      "Epoch 159/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9484\n",
      "Epoch 160/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9439\n",
      "Epoch 161/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9395\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9440\n",
      "Epoch 163/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9367\n",
      "Epoch 164/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9161\n",
      "Epoch 165/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9259\n",
      "Epoch 166/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9385\n",
      "Epoch 167/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9412\n",
      "Epoch 168/300\n",
      "7072/7072 [==============================] - 1s 166us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9382\n",
      "Epoch 169/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.94611s - loss: 0.0271 - mean\n",
      "Epoch 170/300\n",
      "7072/7072 [==============================] - 1s 159us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9440\n",
      "Epoch 171/300\n",
      "7072/7072 [==============================] - 1s 198us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9480\n",
      "Epoch 172/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9432\n",
      "Epoch 173/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9437\n",
      "Epoch 174/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9423\n",
      "Epoch 175/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.92680s - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.\n",
      "Epoch 176/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9277\n",
      "Epoch 177/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9292\n",
      "Epoch 178/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9393\n",
      "Epoch 179/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9406\n",
      "Epoch 180/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9446\n",
      "Epoch 181/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9412\n",
      "Epoch 182/300\n",
      "7072/7072 [==============================] - 1s 184us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9376\n",
      "Epoch 183/300\n",
      "7072/7072 [==============================] - 2s 226us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.92290s - loss: 0.0428 - mean_squared_error: 0.0428 - acc\n",
      "Epoch 184/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.92850s - loss: 0.0412 - mean_squared_error: 0.0412 -\n",
      "Epoch 185/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9161\n",
      "Epoch 186/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9367\n",
      "Epoch 187/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9504\n",
      "Epoch 188/300\n",
      "7072/7072 [==============================] - 1s 200us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9536\n",
      "Epoch 189/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0555 - mean_squared_error: 0.0555 - acc: 0.9005\n",
      "Epoch 190/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9195\n",
      "Epoch 191/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9385\n",
      "Epoch 192/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9231\n",
      "Epoch 193/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9408\n",
      "Epoch 194/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9451\n",
      "Epoch 195/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9426\n",
      "Epoch 196/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.94390s - loss: 0.0335 - mean_squared_error\n",
      "Epoch 197/300\n",
      "7072/7072 [==============================] - 1s 186us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9423\n",
      "Epoch 198/300\n",
      "7072/7072 [==============================] - 1s 156us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9484\n",
      "Epoch 199/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9352\n",
      "Epoch 200/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9412\n",
      "Epoch 201/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9409\n",
      "Epoch 202/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9406\n",
      "Epoch 203/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9342\n",
      "Epoch 204/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.93540s - loss: 0.0336 - mean_squared_error: 0.\n",
      "Epoch 205/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9515\n",
      "Epoch 206/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0513 - mean_squared_error: 0.0513 - acc: 0.9060\n",
      "Epoch 207/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.94150s - loss: 0.0346 - mean_squared_err\n",
      "Epoch 208/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9484\n",
      "Epoch 209/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9415\n",
      "Epoch 210/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.93780s - loss: 0.0345 - mean\n",
      "Epoch 211/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9460\n",
      "Epoch 212/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9531\n",
      "Epoch 213/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9591\n",
      "Epoch 214/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.95930s - loss: 0.0253 - mean_squared_err\n",
      "Epoch 215/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9584\n",
      "Epoch 216/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0501 - mean_squared_error: 0.0501 - acc: 0.9072\n",
      "Epoch 217/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0502 - mean_squared_error: 0.0502 - acc: 0.9112\n",
      "Epoch 218/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9345\n",
      "Epoch 219/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9283\n",
      "Epoch 220/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9430\n",
      "Epoch 221/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0422 - mean_squared_error: 0.0422 - acc: 0.9229\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.92120s - loss: 0.0419 - mean_squared_error: 0.0419\n",
      "Epoch 223/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0425 - mean_squared_error: 0.0425 - acc: 0.9246\n",
      "Epoch 224/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9296\n",
      "Epoch 225/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9381\n",
      "Epoch 226/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9400\n",
      "Epoch 227/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9382\n",
      "Epoch 228/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9266\n",
      "Epoch 229/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9429\n",
      "Epoch 230/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9395\n",
      "Epoch 231/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9391\n",
      "Epoch 232/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9403\n",
      "Epoch 233/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9437\n",
      "Epoch 234/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9481\n",
      "Epoch 235/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9505\n",
      "Epoch 236/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9374\n",
      "Epoch 237/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9374\n",
      "Epoch 238/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9532 0s - loss: 0.0320 - mean_squared_error: 0.0320 -\n",
      "Epoch 239/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9553\n",
      "Epoch 240/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9424\n",
      "Epoch 241/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9457\n",
      "Epoch 242/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9282\n",
      "Epoch 243/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9166\n",
      "Epoch 244/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9327\n",
      "Epoch 245/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9266\n",
      "Epoch 246/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0552 - mean_squared_error: 0.0552 - acc: 0.9007\n",
      "Epoch 247/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0427 - mean_squared_error: 0.0427 - acc: 0.9225\n",
      "Epoch 248/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9314\n",
      "Epoch 249/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9290\n",
      "Epoch 250/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9328\n",
      "Epoch 251/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.93830s - loss: 0.0288 - mean_squared\n",
      "Epoch 252/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9361\n",
      "Epoch 253/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9364\n",
      "Epoch 254/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9439\n",
      "Epoch 255/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9505\n",
      "Epoch 256/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9468\n",
      "Epoch 257/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9358\n",
      "Epoch 258/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9227\n",
      "Epoch 259/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9415\n",
      "Epoch 260/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9361 0s - loss: 0.0306 - mean_squared_e\n",
      "Epoch 261/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9361\n",
      "Epoch 262/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9381 0s - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Epoch 263/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9412\n",
      "Epoch 264/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9511 0s - loss: 0.0286 - mean_squared_error: 0.0286 - acc\n",
      "Epoch 265/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9598\n",
      "Epoch 266/300\n",
      "7072/7072 [==============================] - 1s 181us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.95891s - loss: 0.0237 - mean\n",
      "Epoch 267/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9628\n",
      "Epoch 268/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9533\n",
      "Epoch 269/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9579\n",
      "Epoch 270/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9587\n",
      "Epoch 271/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9583\n",
      "Epoch 272/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9583\n",
      "Epoch 273/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0215 - mean_squared_error: 0.0215 - acc: 0.9663 0s - loss: 0.0218 - mean_squared_error: 0.0218 - acc:  - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.96\n",
      "Epoch 274/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9593\n",
      "Epoch 275/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9613\n",
      "Epoch 276/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9549\n",
      "Epoch 277/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9507\n",
      "Epoch 278/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0265 - mean_squared_error: 0.0265 - acc: 0.9552\n",
      "Epoch 279/300\n",
      "7072/7072 [==============================] - 1s 170us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9563\n",
      "Epoch 280/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9417\n",
      "Epoch 281/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9392\n",
      "Epoch 282/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9490\n",
      "Epoch 283/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9395\n",
      "Epoch 284/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.95050s - loss: 0.0349 - mean_squared_error: 0.0349 - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.94\n",
      "Epoch 285/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9570\n",
      "Epoch 286/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9536\n",
      "Epoch 287/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9406 0s - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0. - ETA: 0s - loss: 0.0381 - mean_squared_error: \n",
      "Epoch 288/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9512\n",
      "Epoch 289/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9478\n",
      "Epoch 290/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9470\n",
      "Epoch 291/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9488\n",
      "Epoch 292/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9475\n",
      "Epoch 293/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9481\n",
      "Epoch 294/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9593\n",
      "Epoch 295/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9505\n",
      "Epoch 296/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9399 0s - loss: 0.0380 - mean_squared_error: 0.0380\n",
      "Epoch 297/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9548\n",
      "Epoch 298/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9468\n",
      "Epoch 299/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9378\n",
      "Epoch 300/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9417\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "7072/7072 [==============================] - 0s 43us/step\n",
      "The Score is 0.979414\n",
      "current iteration fraction: 0.600000\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(6062, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "6062/6062 [==============================] - 1s 166us/step - loss: 0.1824 - mean_squared_error: 0.1824 - acc: 0.5886\n",
      "Epoch 2/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.1626 - mean_squared_error: 0.1626 - acc: 0.6438\n",
      "Epoch 3/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.1521 - mean_squared_error: 0.1521 - acc: 0.6610\n",
      "Epoch 4/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.1399 - mean_squared_error: 0.1399 - acc: 0.7029\n",
      "Epoch 5/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.1243 - mean_squared_error: 0.1243 - acc: 0.7539\n",
      "Epoch 6/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.1188 - mean_squared_error: 0.1188 - acc: 0.7606\n",
      "Epoch 7/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.0974 - mean_squared_error: 0.0974 - acc: 0.8174\n",
      "Epoch 8/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0797 - mean_squared_error: 0.0797 - acc: 0.8571\n",
      "Epoch 9/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0746 - mean_squared_error: 0.0746 - acc: 0.8669\n",
      "Epoch 10/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0625 - mean_squared_error: 0.0625 - acc: 0.8898\n",
      "Epoch 11/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0623 - mean_squared_error: 0.0623 - acc: 0.88700s - loss: 0.0610 - mean_squared_error: 0.0610 - acc: 0.89 - ETA: 0s - loss: 0.0609 - mean_squared_error: 0.06 - ETA: 0s - loss: 0.0618 - mean_squared_error: 0.0618 - acc: \n",
      "Epoch 12/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0594 - mean_squared_error: 0.0594 - acc: 0.8933\n",
      "Epoch 13/300\n",
      "6062/6062 [==============================] - 1s 139us/step - loss: 0.0528 - mean_squared_error: 0.0528 - acc: 0.9091\n",
      "Epoch 14/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9192\n",
      "Epoch 15/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.9200\n",
      "Epoch 16/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9378\n",
      "Epoch 17/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9327\n",
      "Epoch 18/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9322\n",
      "Epoch 19/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9378\n",
      "Epoch 20/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0432 - mean_squared_error: 0.0432 - acc: 0.92460s - loss: 0.0439 - mean_squared_error: 0.0439 - acc\n",
      "Epoch 21/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9320\n",
      "Epoch 22/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.0557 - acc: 0.89 - 1s 103us/step - loss: 0.0565 - mean_squared_error: 0.0565 - acc: 0.8908\n",
      "Epoch 23/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9277\n",
      "Epoch 24/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0432 - mean_squared_error: 0.0432 - acc: 0.9202\n",
      "Epoch 25/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9299\n",
      "Epoch 26/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9131\n",
      "Epoch 27/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.93040s - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0. - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.\n",
      "Epoch 28/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9373\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9324\n",
      "Epoch 30/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9352\n",
      "Epoch 31/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0519 - mean_squared_error: 0.0519 - acc: 0.8985\n",
      "Epoch 32/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0483 - mean_squared_error: 0.0483 - acc: 0.9086\n",
      "Epoch 33/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9178\n",
      "Epoch 34/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9324\n",
      "Epoch 35/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.9286\n",
      "Epoch 36/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0412 - mean_squared_error: 0.0412 - acc: 0.9253\n",
      "Epoch 37/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9325\n",
      "Epoch 38/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9403\n",
      "Epoch 39/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9334\n",
      "Epoch 40/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9378\n",
      "Epoch 41/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9310 0s - loss: 0.0386 - mean_squared_error: 0.0386 - acc: \n",
      "Epoch 42/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9315\n",
      "Epoch 43/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9404\n",
      "Epoch 44/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9390\n",
      "Epoch 45/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9409\n",
      "Epoch 46/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9365\n",
      "Epoch 47/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9343\n",
      "Epoch 48/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9289\n",
      "Epoch 49/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9306\n",
      "Epoch 50/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9330\n",
      "Epoch 51/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9548\n",
      "Epoch 52/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9414\n",
      "Epoch 53/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9442\n",
      "Epoch 54/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.93670s - loss: 0.0269 - mean_squared_error: 0.0269 - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0367 - a\n",
      "Epoch 55/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0440 - mean_squared_error: 0.0440 - acc: 0.9248\n",
      "Epoch 56/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9332\n",
      "Epoch 57/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9373\n",
      "Epoch 58/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9395\n",
      "Epoch 59/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9457\n",
      "Epoch 60/300\n",
      "6062/6062 [==============================] - 1s 95us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9429\n",
      "Epoch 61/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9395\n",
      "Epoch 62/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9281\n",
      "Epoch 63/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9329\n",
      "Epoch 64/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9360\n",
      "Epoch 65/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9470\n",
      "Epoch 66/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9423\n",
      "Epoch 67/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9494\n",
      "Epoch 68/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0265 - mean_squared_error: 0.0265 - acc: 0.9543\n",
      "Epoch 69/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9390\n",
      "Epoch 70/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9510\n",
      "Epoch 71/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9533\n",
      "Epoch 72/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9520\n",
      "Epoch 73/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9485\n",
      "Epoch 74/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9591\n",
      "Epoch 75/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9528\n",
      "Epoch 76/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9380\n",
      "Epoch 77/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9375\n",
      "Epoch 78/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9459\n",
      "Epoch 79/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9441\n",
      "Epoch 80/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9413\n",
      "Epoch 81/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9442\n",
      "Epoch 82/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9499\n",
      "Epoch 83/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9503\n",
      "Epoch 84/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9536\n",
      "Epoch 85/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9428\n",
      "Epoch 86/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9411\n",
      "Epoch 87/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9393\n",
      "Epoch 88/300\n",
      "6062/6062 [==============================] - 1s 145us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9418\n",
      "Epoch 89/300\n",
      "6062/6062 [==============================] - 1s 140us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9404\n",
      "Epoch 90/300\n",
      "6062/6062 [==============================] - 1s 150us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9484\n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9343\n",
      "Epoch 92/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9497\n",
      "Epoch 93/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.0430 - mean_squared_error: 0.0430 - acc: 0.9253\n",
      "Epoch 94/300\n",
      "6062/6062 [==============================] - 1s 182us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9343\n",
      "Epoch 95/300\n",
      "6062/6062 [==============================] - 1s 219us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9419\n",
      "Epoch 96/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0430 - mean_squared_error: 0.0430 - acc: 0.9230\n",
      "Epoch 97/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9332\n",
      "Epoch 98/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9406\n",
      "Epoch 99/300\n",
      "6062/6062 [==============================] - 1s 211us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9500\n",
      "Epoch 100/300\n",
      "6062/6062 [==============================] - 2s 251us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9451\n",
      "Epoch 101/300\n",
      "6062/6062 [==============================] - 1s 223us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9281\n",
      "Epoch 102/300\n",
      "6062/6062 [==============================] - 1s 174us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9409\n",
      "Epoch 103/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9467\n",
      "Epoch 104/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9522\n",
      "Epoch 105/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9528\n",
      "Epoch 106/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9578\n",
      "Epoch 107/300\n",
      "6062/6062 [==============================] - 1s 162us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9527\n",
      "Epoch 108/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9475\n",
      "Epoch 109/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9500\n",
      "Epoch 110/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9500\n",
      "Epoch 111/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.91820s - loss: 0.0369 - mean_squared_error: 0.0369 - acc:  - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.03\n",
      "Epoch 112/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0441 - mean_squared_error: 0.0441 - acc: 0.9188\n",
      "Epoch 113/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9441\n",
      "Epoch 114/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9474\n",
      "Epoch 115/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9543\n",
      "Epoch 116/300\n",
      "6062/6062 [==============================] - 1s 173us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9421\n",
      "Epoch 117/300\n",
      "6062/6062 [==============================] - 1s 204us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9456\n",
      "Epoch 118/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.92 - 1s 227us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9251\n",
      "Epoch 119/300\n",
      "6062/6062 [==============================] - 2s 280us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9238\n",
      "Epoch 120/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9411\n",
      "Epoch 121/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9398\n",
      "Epoch 122/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9157\n",
      "Epoch 123/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9433\n",
      "Epoch 124/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9339\n",
      "Epoch 125/300\n",
      "6062/6062 [==============================] - 1s 139us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9282\n",
      "Epoch 126/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9297\n",
      "Epoch 127/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9254\n",
      "Epoch 128/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9317\n",
      "Epoch 129/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9418\n",
      "Epoch 130/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9462\n",
      "Epoch 131/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9442\n",
      "Epoch 132/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9457\n",
      "Epoch 133/300\n",
      "6062/6062 [==============================] - 1s 198us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.95300s - loss: 0.0279 - mean_squared_error: 0.0279\n",
      "Epoch 134/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.94 - 1s 199us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9411\n",
      "Epoch 135/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0425 - mean_squared_error: 0.0425 - acc: 0.9211\n",
      "Epoch 136/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9464\n",
      "Epoch 137/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9429\n",
      "Epoch 138/300\n",
      "6062/6062 [==============================] - 1s 194us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9523\n",
      "Epoch 139/300\n",
      "6062/6062 [==============================] - 1s 142us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9505\n",
      "Epoch 140/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9503\n",
      "Epoch 141/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9454 0s - loss: 0.0290 - mean_squared_error: \n",
      "Epoch 142/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9380\n",
      "Epoch 143/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9119\n",
      "Epoch 144/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9462\n",
      "Epoch 145/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9249\n",
      "Epoch 146/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9429\n",
      "Epoch 147/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9479\n",
      "Epoch 148/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9373\n",
      "Epoch 149/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9256\n",
      "Epoch 150/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9469\n",
      "Epoch 151/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9467\n",
      "Epoch 152/300\n",
      "6062/6062 [==============================] - 1s 93us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9459\n",
      "Epoch 153/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9446\n",
      "Epoch 154/300\n",
      "6062/6062 [==============================] - 1s 93us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9424\n",
      "Epoch 155/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9466\n",
      "Epoch 156/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9502\n",
      "Epoch 157/300\n",
      "6062/6062 [==============================] - 1s 95us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9518\n",
      "Epoch 158/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9522\n",
      "Epoch 159/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.9207\n",
      "Epoch 160/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9215\n",
      "Epoch 161/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9437\n",
      "Epoch 162/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9467\n",
      "Epoch 163/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9469\n",
      "Epoch 164/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9426\n",
      "Epoch 165/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9388\n",
      "Epoch 166/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9457\n",
      "Epoch 167/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9512\n",
      "Epoch 168/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9480\n",
      "Epoch 169/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9461\n",
      "Epoch 170/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9477\n",
      "Epoch 171/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9452\n",
      "Epoch 172/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9223\n",
      "Epoch 173/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9256\n",
      "Epoch 174/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9330\n",
      "Epoch 175/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9282\n",
      "Epoch 176/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9437\n",
      "Epoch 177/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9459\n",
      "Epoch 178/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9429\n",
      "Epoch 179/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9368\n",
      "Epoch 180/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9294\n",
      "Epoch 181/300\n",
      "6062/6062 [==============================] - 1s 148us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.94990s - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.\n",
      "Epoch 182/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.9231\n",
      "Epoch 183/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9337\n",
      "Epoch 184/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9470\n",
      "Epoch 185/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9409\n",
      "Epoch 186/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9538\n",
      "Epoch 187/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9571\n",
      "Epoch 188/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9555\n",
      "Epoch 189/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9461\n",
      "Epoch 190/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9426\n",
      "Epoch 191/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.94390s - loss: 0.0360 - mean_squared_error: \n",
      "Epoch 192/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9398\n",
      "Epoch 193/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9441\n",
      "Epoch 194/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9505\n",
      "Epoch 195/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9500\n",
      "Epoch 196/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9315\n",
      "Epoch 197/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9396\n",
      "Epoch 198/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9494\n",
      "Epoch 199/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9492\n",
      "Epoch 200/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9530\n",
      "Epoch 201/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9543\n",
      "Epoch 202/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9431\n",
      "Epoch 203/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.93 - 1s 102us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9388\n",
      "Epoch 204/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9363\n",
      "Epoch 205/300\n",
      "6062/6062 [==============================] - 1s 155us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9419\n",
      "Epoch 206/300\n",
      "6062/6062 [==============================] - 1s 152us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9523\n",
      "Epoch 207/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9553\n",
      "Epoch 208/300\n",
      "6062/6062 [==============================] - 1s 158us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9543\n",
      "Epoch 209/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.96 - 1s 146us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9652\n",
      "Epoch 210/300\n",
      "6062/6062 [==============================] - 1s 156us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9589\n",
      "Epoch 211/300\n",
      "6062/6062 [==============================] - 1s 139us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9622\n",
      "Epoch 212/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 247us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9599\n",
      "Epoch 213/300\n",
      "6062/6062 [==============================] - 2s 269us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9624\n",
      "Epoch 214/300\n",
      "6062/6062 [==============================] - 1s 221us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.95070s - loss: 0.0304 - mean_squared_error: \n",
      "Epoch 215/300\n",
      "6062/6062 [==============================] - 1s 192us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9560\n",
      "Epoch 216/300\n",
      "6062/6062 [==============================] - 1s 139us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9548\n",
      "Epoch 217/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9617\n",
      "Epoch 218/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9576\n",
      "Epoch 219/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9522\n",
      "Epoch 220/300\n",
      "6062/6062 [==============================] - 1s 147us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9395\n",
      "Epoch 221/300\n",
      "6062/6062 [==============================] - 1s 141us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9535\n",
      "Epoch 222/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9437\n",
      "Epoch 223/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9466\n",
      "Epoch 224/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9545\n",
      "Epoch 225/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0231 - mean_squared_error: 0.0231 - acc: 0.9621\n",
      "Epoch 226/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9550\n",
      "Epoch 227/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9536\n",
      "Epoch 228/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9446\n",
      "Epoch 229/300\n",
      "6062/6062 [==============================] - 1s 140us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9546\n",
      "Epoch 230/300\n",
      "6062/6062 [==============================] - 1s 239us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9512\n",
      "Epoch 231/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9474\n",
      "Epoch 232/300\n",
      "6062/6062 [==============================] - 2s 311us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9423\n",
      "Epoch 233/300\n",
      "6062/6062 [==============================] - 1s 175us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9411\n",
      "Epoch 234/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9561\n",
      "Epoch 235/300\n",
      "6062/6062 [==============================] - 1s 95us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9593\n",
      "Epoch 236/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9563\n",
      "Epoch 237/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9449\n",
      "Epoch 238/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.95080s - loss: 0.0268 - mean_squared_error: 0.0268 -\n",
      "Epoch 239/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9558\n",
      "Epoch 240/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9560\n",
      "Epoch 241/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.9621\n",
      "Epoch 242/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9622\n",
      "Epoch 243/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9561\n",
      "Epoch 244/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9541\n",
      "Epoch 245/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9456\n",
      "Epoch 246/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9484\n",
      "Epoch 247/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9518\n",
      "Epoch 248/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9543\n",
      "Epoch 249/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.95220s - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.\n",
      "Epoch 250/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9172\n",
      "Epoch 251/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9467\n",
      "Epoch 252/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9503\n",
      "Epoch 253/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9532\n",
      "Epoch 254/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9456\n",
      "Epoch 255/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.94080s - loss: 0.0282 - mean_squared_error\n",
      "Epoch 256/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9306\n",
      "Epoch 257/300\n",
      "6062/6062 [==============================] - 1s 159us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9456\n",
      "Epoch 258/300\n",
      "6062/6062 [==============================] - 1s 166us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9467\n",
      "Epoch 259/300\n",
      "6062/6062 [==============================] - 1s 231us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9292\n",
      "Epoch 260/300\n",
      "6062/6062 [==============================] - 1s 152us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9543\n",
      "Epoch 261/300\n",
      "6062/6062 [==============================] - 1s 155us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9523\n",
      "Epoch 262/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.95120s - loss: 0.0309 - mean_squared_error: \n",
      "Epoch 263/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9553\n",
      "Epoch 264/300\n",
      "6062/6062 [==============================] - 1s 89us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9505\n",
      "Epoch 265/300\n",
      "6062/6062 [==============================] - 0s 80us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9561\n",
      "Epoch 266/300\n",
      "6062/6062 [==============================] - 0s 73us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9525\n",
      "Epoch 267/300\n",
      "6062/6062 [==============================] - 0s 77us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9560\n",
      "Epoch 268/300\n",
      "6062/6062 [==============================] - 1s 87us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9530\n",
      "Epoch 269/300\n",
      "6062/6062 [==============================] - 0s 74us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9540\n",
      "Epoch 270/300\n",
      "6062/6062 [==============================] - 0s 80us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9538\n",
      "Epoch 271/300\n",
      "6062/6062 [==============================] - 1s 84us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9523\n",
      "Epoch 272/300\n",
      "6062/6062 [==============================] - 0s 76us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9376\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 83us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9538\n",
      "Epoch 274/300\n",
      "6062/6062 [==============================] - 0s 82us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9482\n",
      "Epoch 275/300\n",
      "6062/6062 [==============================] - 0s 82us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9345\n",
      "Epoch 276/300\n",
      "6062/6062 [==============================] - 0s 79us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9515 0s - loss: 0.0316 - mean_squared_error: 0.0316 - a\n",
      "Epoch 277/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9530\n",
      "Epoch 278/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9533\n",
      "Epoch 279/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9566\n",
      "Epoch 280/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9597\n",
      "Epoch 281/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9566 0s - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.95\n",
      "Epoch 282/300\n",
      "6062/6062 [==============================] - 1s 88us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9484\n",
      "Epoch 283/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9459\n",
      "Epoch 284/300\n",
      "6062/6062 [==============================] - 1s 143us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9404\n",
      "Epoch 285/300\n",
      "6062/6062 [==============================] - 1s 154us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9602\n",
      "Epoch 286/300\n",
      "6062/6062 [==============================] - 0s 81us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9583\n",
      "Epoch 287/300\n",
      "6062/6062 [==============================] - 0s 76us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9315\n",
      "Epoch 288/300\n",
      "6062/6062 [==============================] - 0s 81us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9373\n",
      "Epoch 289/300\n",
      "6062/6062 [==============================] - 1s 91us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9426\n",
      "Epoch 290/300\n",
      "6062/6062 [==============================] - 0s 76us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9545\n",
      "Epoch 291/300\n",
      "6062/6062 [==============================] - 0s 80us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9503\n",
      "Epoch 292/300\n",
      "6062/6062 [==============================] - 1s 83us/step - loss: 0.0235 - mean_squared_error: 0.0235 - acc: 0.9617\n",
      "Epoch 293/300\n",
      "6062/6062 [==============================] - 0s 77us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9447\n",
      "Epoch 294/300\n",
      "6062/6062 [==============================] - 1s 92us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9324\n",
      "Epoch 295/300\n",
      "6062/6062 [==============================] - 0s 81us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9545\n",
      "Epoch 296/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.96 - 1s 85us/step - loss: 0.0235 - mean_squared_error: 0.0235 - acc: 0.9627\n",
      "Epoch 297/300\n",
      "6062/6062 [==============================] - 1s 83us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9579\n",
      "Epoch 298/300\n",
      "6062/6062 [==============================] - 1s 83us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9573\n",
      "Epoch 299/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9558\n",
      "Epoch 300/300\n",
      "6062/6062 [==============================] - 1s 84us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9480\n",
      "2526/2526 [==============================] - 0s 88us/step\n",
      "6062/6062 [==============================] - 0s 34us/step\n",
      "The Score is 0.975455\n",
      "current iteration fraction: 0.500000\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(5052, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "5052/5052 [==============================] - 1s 222us/step - loss: 0.1853 - mean_squared_error: 0.1853 - acc: 0.5903\n",
      "Epoch 2/300\n",
      "5052/5052 [==============================] - 0s 93us/step - loss: 0.1609 - mean_squared_error: 0.1609 - acc: 0.6461\n",
      "Epoch 3/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.1483 - mean_squared_error: 0.1483 - acc: 0.6702\n",
      "Epoch 4/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.1308 - mean_squared_error: 0.1308 - acc: 0.7332\n",
      "Epoch 5/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.1153 - mean_squared_error: 0.1153 - acc: 0.7856\n",
      "Epoch 6/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0989 - mean_squared_error: 0.0989 - acc: 0.8288\n",
      "Epoch 7/300\n",
      "5052/5052 [==============================] - 0s 87us/step - loss: 0.0908 - mean_squared_error: 0.0908 - acc: 0.8389\n",
      "Epoch 8/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0789 - mean_squared_error: 0.0789 - acc: 0.8640\n",
      "Epoch 9/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0647 - mean_squared_error: 0.0647 - acc: 0.8925\n",
      "Epoch 10/300\n",
      "5052/5052 [==============================] - 0s 82us/step - loss: 0.0550 - mean_squared_error: 0.0550 - acc: 0.9121\n",
      "Epoch 11/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0635 - mean_squared_error: 0.0635 - acc: 0.8868\n",
      "Epoch 12/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0536 - mean_squared_error: 0.0536 - acc: 0.9070\n",
      "Epoch 13/300\n",
      "5052/5052 [==============================] - 1s 101us/step - loss: 0.0536 - mean_squared_error: 0.0536 - acc: 0.90380s - loss: 0.0542 - mean_squared_error: 0.0542 - acc: 0.\n",
      "Epoch 14/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0534 - mean_squared_error: 0.0534 - acc: 0.9084 0s - loss: 0.0501 - mean_squared_error: 0.0501 -\n",
      "Epoch 15/300\n",
      "5052/5052 [==============================] - 0s 87us/step - loss: 0.0536 - mean_squared_error: 0.0536 - acc: 0.9054\n",
      "Epoch 16/300\n",
      "5052/5052 [==============================] - 1s 104us/step - loss: 0.0489 - mean_squared_error: 0.0489 - acc: 0.9137\n",
      "Epoch 17/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.0466 - mean_squared_error: 0.0466 - acc: 0.9173\n",
      "Epoch 18/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.0542 - mean_squared_error: 0.0542 - acc: 0.8987\n",
      "Epoch 19/300\n",
      "5052/5052 [==============================] - 0s 86us/step - loss: 0.0456 - mean_squared_error: 0.0456 - acc: 0.9143\n",
      "Epoch 20/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0527 - mean_squared_error: 0.0527 - acc: 0.9028\n",
      "Epoch 21/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.9305\n",
      "Epoch 22/300\n",
      "5052/5052 [==============================] - 0s 92us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9347\n",
      "Epoch 23/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9218\n",
      "Epoch 24/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9186\n",
      "Epoch 25/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9157\n",
      "Epoch 26/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9327\n",
      "Epoch 27/300\n",
      "5052/5052 [==============================] - 0s 82us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9517\n",
      "Epoch 28/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9325\n",
      "Epoch 29/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9349\n",
      "Epoch 30/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9420\n",
      "Epoch 31/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9321\n",
      "Epoch 32/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9390\n",
      "Epoch 33/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9337\n",
      "Epoch 34/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9325\n",
      "Epoch 35/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9384\n",
      "Epoch 36/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0441 - mean_squared_error: 0.0441 - acc: 0.9177\n",
      "Epoch 37/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9341\n",
      "Epoch 38/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9378\n",
      "Epoch 39/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9365\n",
      "Epoch 40/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0441 - mean_squared_error: 0.0441 - acc: 0.9214\n",
      "Epoch 41/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9367\n",
      "Epoch 42/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9466 0s - loss: 0.0322 - mean_squared_error: 0.0322 - a\n",
      "Epoch 43/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9458\n",
      "Epoch 44/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9462\n",
      "Epoch 45/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9293\n",
      "Epoch 46/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9351\n",
      "Epoch 47/300\n",
      "5052/5052 [==============================] - 0s 69us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9386\n",
      "Epoch 48/300\n",
      "5052/5052 [==============================] - 0s 83us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9365\n",
      "Epoch 49/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9319\n",
      "Epoch 50/300\n",
      "5052/5052 [==============================] - 0s 79us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9428\n",
      "Epoch 51/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9384 0s - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.93 - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0354 - a\n",
      "Epoch 52/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9481\n",
      "Epoch 53/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9418\n",
      "Epoch 54/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9258\n",
      "Epoch 55/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9254\n",
      "Epoch 56/300\n",
      "5052/5052 [==============================] - 0s 79us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9248\n",
      "Epoch 57/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9339\n",
      "Epoch 58/300\n",
      "5052/5052 [==============================] - 0s 83us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9228\n",
      "Epoch 59/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9323\n",
      "Epoch 60/300\n",
      "5052/5052 [==============================] - 0s 79us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9458\n",
      "Epoch 61/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9283 0s - loss: 0.0389 - mean_squared_error: 0.0389 - acc: \n",
      "Epoch 62/300\n",
      "5052/5052 [==============================] - 0s 90us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9412\n",
      "Epoch 63/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9495\n",
      "Epoch 64/300\n",
      "5052/5052 [==============================] - 0s 82us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9325\n",
      "Epoch 65/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9359\n",
      "Epoch 66/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9337\n",
      "Epoch 67/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9440\n",
      "Epoch 68/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9471\n",
      "Epoch 69/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9517\n",
      "Epoch 70/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9416\n",
      "Epoch 71/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9382\n",
      "Epoch 72/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9349\n",
      "Epoch 73/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9343\n",
      "Epoch 74/300\n",
      "5052/5052 [==============================] - 0s 87us/step - loss: 0.0561 - mean_squared_error: 0.0561 - acc: 0.8943\n",
      "Epoch 75/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9291\n",
      "Epoch 76/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9042\n",
      "Epoch 77/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9339\n",
      "Epoch 78/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9313\n",
      "Epoch 79/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9301\n",
      "Epoch 80/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9283\n",
      "Epoch 81/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9323\n",
      "Epoch 82/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9341\n",
      "Epoch 83/300\n",
      "5052/5052 [==============================] - 1s 135us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.94750s - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.\n",
      "Epoch 84/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9341\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9355\n",
      "Epoch 86/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9414\n",
      "Epoch 87/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9487\n",
      "Epoch 88/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9303\n",
      "Epoch 89/300\n",
      "5052/5052 [==============================] - 0s 79us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9517\n",
      "Epoch 90/300\n",
      "5052/5052 [==============================] - 1s 99us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9270\n",
      "Epoch 91/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9242\n",
      "Epoch 92/300\n",
      "5052/5052 [==============================] - 0s 93us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9418\n",
      "Epoch 93/300\n",
      "5052/5052 [==============================] - 1s 114us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9375\n",
      "Epoch 94/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9384 0s - loss: 0.0347 - mean_squared_error: 0.0347 - acc: \n",
      "Epoch 95/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9244\n",
      "Epoch 96/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0481 - mean_squared_error: 0.0481 - acc: 0.9137\n",
      "Epoch 97/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0441 - mean_squared_error: 0.0441 - acc: 0.9222\n",
      "Epoch 98/300\n",
      "5052/5052 [==============================] - 0s 88us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9468\n",
      "Epoch 99/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9412\n",
      "Epoch 100/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9426\n",
      "Epoch 101/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9491\n",
      "Epoch 102/300\n",
      "5052/5052 [==============================] - 1s 104us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9446\n",
      "Epoch 103/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9555\n",
      "Epoch 104/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9521\n",
      "Epoch 105/300\n",
      "5052/5052 [==============================] - 0s 88us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9517\n",
      "Epoch 106/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9416\n",
      "Epoch 107/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9361\n",
      "Epoch 108/300\n",
      "5052/5052 [==============================] - 1s 156us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9266\n",
      "Epoch 109/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9523\n",
      "Epoch 110/300\n",
      "5052/5052 [==============================] - 1s 146us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9523\n",
      "Epoch 111/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9438\n",
      "Epoch 112/300\n",
      "5052/5052 [==============================] - 0s 90us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9517\n",
      "Epoch 113/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9438\n",
      "Epoch 114/300\n",
      "5052/5052 [==============================] - 0s 96us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9481\n",
      "Epoch 115/300\n",
      "5052/5052 [==============================] - 1s 149us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9481\n",
      "Epoch 116/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9464\n",
      "Epoch 117/300\n",
      "5052/5052 [==============================] - 0s 88us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9276\n",
      "Epoch 118/300\n",
      "5052/5052 [==============================] - 0s 99us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9450\n",
      "Epoch 119/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9410\n",
      "Epoch 120/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9491\n",
      "Epoch 121/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9539\n",
      "Epoch 122/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9535\n",
      "Epoch 123/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9246 0s - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Epoch 124/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9337\n",
      "Epoch 125/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9487\n",
      "Epoch 126/300\n",
      "5052/5052 [==============================] - 1s 163us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9527\n",
      "Epoch 127/300\n",
      "5052/5052 [==============================] - 1s 142us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.92780s - loss: 0.0313 - mean_squared_error: 0.0313 - a\n",
      "Epoch 128/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9475\n",
      "Epoch 129/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9464\n",
      "Epoch 130/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9507\n",
      "Epoch 131/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9563\n",
      "Epoch 132/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9475\n",
      "Epoch 133/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9535\n",
      "Epoch 134/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0488 - mean_squared_error: 0.0488 - acc: 0.9113\n",
      "Epoch 135/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9254\n",
      "Epoch 136/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9303\n",
      "Epoch 137/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9376\n",
      "Epoch 138/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9315\n",
      "Epoch 139/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9434\n",
      "Epoch 140/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9452\n",
      "Epoch 141/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9424\n",
      "Epoch 142/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9343\n",
      "Epoch 143/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9388\n",
      "Epoch 144/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9446\n",
      "Epoch 145/300\n",
      "5052/5052 [==============================] - 0s 86us/step - loss: 0.0497 - mean_squared_error: 0.0497 - acc: 0.9087\n",
      "Epoch 146/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9367\n",
      "Epoch 147/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9438\n",
      "Epoch 148/300\n",
      "5052/5052 [==============================] - 0s 86us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9365\n",
      "Epoch 149/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9248\n",
      "Epoch 150/300\n",
      "5052/5052 [==============================] - 1s 100us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9363\n",
      "Epoch 151/300\n",
      "5052/5052 [==============================] - 1s 148us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9363\n",
      "Epoch 152/300\n",
      "5052/5052 [==============================] - 1s 137us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9396\n",
      "Epoch 153/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0504 - mean_squared_error: 0.0504 - acc: 0.9072\n",
      "Epoch 154/300\n",
      "5052/5052 [==============================] - 1s 170us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9161\n",
      "Epoch 155/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.0451 - mean_squared_error: 0.0451 - acc: 0.9212\n",
      "Epoch 156/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9390\n",
      "Epoch 157/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9307\n",
      "Epoch 158/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9252\n",
      "Epoch 159/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.9283\n",
      "Epoch 160/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9240\n",
      "Epoch 161/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9438\n",
      "Epoch 162/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9373\n",
      "Epoch 163/300\n",
      "5052/5052 [==============================] - 1s 143us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9434\n",
      "Epoch 164/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9519\n",
      "Epoch 165/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9246\n",
      "Epoch 166/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9347\n",
      "Epoch 167/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9361\n",
      "Epoch 168/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9386\n",
      "Epoch 169/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9285\n",
      "Epoch 170/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9276\n",
      "Epoch 171/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9260\n",
      "Epoch 172/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9355\n",
      "Epoch 173/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9436\n",
      "Epoch 174/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9404\n",
      "Epoch 175/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9353\n",
      "Epoch 176/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9430\n",
      "Epoch 177/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9497\n",
      "Epoch 178/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9357\n",
      "Epoch 179/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9420\n",
      "Epoch 180/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9466\n",
      "Epoch 181/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9422\n",
      "Epoch 182/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9426\n",
      "Epoch 183/300\n",
      "5052/5052 [==============================] - 0s 96us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9266\n",
      "Epoch 184/300\n",
      "5052/5052 [==============================] - 1s 114us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9222\n",
      "Epoch 185/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0412 - mean_squared_error: 0.0412 - acc: 0.9287\n",
      "Epoch 186/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9321\n",
      "Epoch 187/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9432\n",
      "Epoch 188/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9410\n",
      "Epoch 189/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9527\n",
      "Epoch 190/300\n",
      "5052/5052 [==============================] - 1s 137us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9466\n",
      "Epoch 191/300\n",
      "5052/5052 [==============================] - 0s 88us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9464\n",
      "Epoch 192/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9408\n",
      "Epoch 193/300\n",
      "5052/5052 [==============================] - 0s 84us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9479\n",
      "Epoch 194/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9462\n",
      "Epoch 195/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9537\n",
      "Epoch 196/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9578\n",
      "Epoch 197/300\n",
      "5052/5052 [==============================] - 0s 92us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9505\n",
      "Epoch 198/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9578\n",
      "Epoch 199/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9537\n",
      "Epoch 200/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9464\n",
      "Epoch 201/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0479 - mean_squared_error: 0.0479 - acc: 0.9099\n",
      "Epoch 202/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9339\n",
      "Epoch 203/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9454\n",
      "Epoch 204/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9527\n",
      "Epoch 205/300\n",
      "5052/5052 [==============================] - 0s 82us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9588\n",
      "Epoch 206/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9567\n",
      "Epoch 207/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9561\n",
      "Epoch 208/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9367\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9452\n",
      "Epoch 210/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9503\n",
      "Epoch 211/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9477\n",
      "Epoch 212/300\n",
      "5052/5052 [==============================] - 0s 82us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9430\n",
      "Epoch 213/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9568\n",
      "Epoch 214/300\n",
      "5052/5052 [==============================] - 0s 69us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9567\n",
      "Epoch 215/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9473\n",
      "Epoch 216/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9501\n",
      "Epoch 217/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9470\n",
      "Epoch 218/300\n",
      "5052/5052 [==============================] - 0s 69us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9493\n",
      "Epoch 219/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9315\n",
      "Epoch 220/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9380\n",
      "Epoch 221/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9485\n",
      "Epoch 222/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9523 0s - loss: 0.0277 - mean_squared_error: 0.0277 - acc\n",
      "Epoch 223/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9481\n",
      "Epoch 224/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9529\n",
      "Epoch 225/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9375\n",
      "Epoch 226/300\n",
      "5052/5052 [==============================] - 0s 85us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9202\n",
      "Epoch 227/300\n",
      "5052/5052 [==============================] - 1s 113us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9386\n",
      "Epoch 228/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9464\n",
      "Epoch 229/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9576\n",
      "Epoch 230/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9576\n",
      "Epoch 231/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9565\n",
      "Epoch 232/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9616\n",
      "Epoch 233/300\n",
      "5052/5052 [==============================] - 0s 69us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9493\n",
      "Epoch 234/300\n",
      "5052/5052 [==============================] - 0s 68us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9483\n",
      "Epoch 235/300\n",
      "5052/5052 [==============================] - 0s 81us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9442\n",
      "Epoch 236/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9456\n",
      "Epoch 237/300\n",
      "5052/5052 [==============================] - 0s 96us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9586\n",
      "Epoch 238/300\n",
      "5052/5052 [==============================] - 0s 90us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9531\n",
      "Epoch 239/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9582\n",
      "Epoch 240/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9624\n",
      "Epoch 241/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0230 - mean_squared_error: 0.0230 - acc: 0.9622\n",
      "Epoch 242/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9519\n",
      "Epoch 243/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9559\n",
      "Epoch 244/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9105\n",
      "Epoch 245/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9404\n",
      "Epoch 246/300\n",
      "5052/5052 [==============================] - 0s 73us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9440\n",
      "Epoch 247/300\n",
      "5052/5052 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.92 - 0s 71us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9264\n",
      "Epoch 248/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9303\n",
      "Epoch 249/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9276\n",
      "Epoch 250/300\n",
      "5052/5052 [==============================] - 0s 98us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9311\n",
      "Epoch 251/300\n",
      "5052/5052 [==============================] - 1s 100us/step - loss: 0.0424 - mean_squared_error: 0.0424 - acc: 0.9252\n",
      "Epoch 252/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9412\n",
      "Epoch 253/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9392\n",
      "Epoch 254/300\n",
      "5052/5052 [==============================] - 0s 79us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9503\n",
      "Epoch 255/300\n",
      "5052/5052 [==============================] - 0s 80us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9452\n",
      "Epoch 256/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9323\n",
      "Epoch 257/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0709 - mean_squared_error: 0.0709 - acc: 0.8727\n",
      "Epoch 258/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0507 - mean_squared_error: 0.0507 - acc: 0.9115\n",
      "Epoch 259/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9244\n",
      "Epoch 260/300\n",
      "5052/5052 [==============================] - 0s 72us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9371\n",
      "Epoch 261/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9493\n",
      "Epoch 262/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9458\n",
      "Epoch 263/300\n",
      "5052/5052 [==============================] - 0s 71us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9434\n",
      "Epoch 264/300\n",
      "5052/5052 [==============================] - 0s 83us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9535\n",
      "Epoch 265/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9513\n",
      "Epoch 266/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9563\n",
      "Epoch 267/300\n",
      "5052/5052 [==============================] - 0s 87us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9452\n",
      "Epoch 268/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9400\n",
      "Epoch 269/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.94560s - loss: 0.0372 - mean_squared_error: \n",
      "Epoch 270/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9497\n",
      "Epoch 271/300\n",
      "5052/5052 [==============================] - 1s 100us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9454\n",
      "Epoch 272/300\n",
      "5052/5052 [==============================] - 0s 90us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9497\n",
      "Epoch 273/300\n",
      "5052/5052 [==============================] - 0s 88us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9464\n",
      "Epoch 274/300\n",
      "5052/5052 [==============================] - 1s 210us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9491\n",
      "Epoch 275/300\n",
      "5052/5052 [==============================] - 1s 212us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9329\n",
      "Epoch 276/300\n",
      "5052/5052 [==============================] - 1s 135us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9337\n",
      "Epoch 277/300\n",
      "5052/5052 [==============================] - 2s 352us/step - loss: 0.0465 - mean_squared_error: 0.0465 - acc: 0.9153\n",
      "Epoch 278/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9327\n",
      "Epoch 279/300\n",
      "5052/5052 [==============================] - 0s 86us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9547\n",
      "Epoch 280/300\n",
      "5052/5052 [==============================] - 1s 188us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9460\n",
      "Epoch 281/300\n",
      "5052/5052 [==============================] - 1s 100us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9505\n",
      "Epoch 282/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9515\n",
      "Epoch 283/300\n",
      "5052/5052 [==============================] - 0s 97us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9547\n",
      "Epoch 284/300\n",
      "5052/5052 [==============================] - 0s 95us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9311\n",
      "Epoch 285/300\n",
      "5052/5052 [==============================] - 0s 92us/step - loss: 0.0466 - mean_squared_error: 0.0466 - acc: 0.9143\n",
      "Epoch 286/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9323\n",
      "Epoch 287/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9473\n",
      "Epoch 288/300\n",
      "5052/5052 [==============================] - 0s 74us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9456\n",
      "Epoch 289/300\n",
      "5052/5052 [==============================] - 0s 77us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9466\n",
      "Epoch 290/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9547\n",
      "Epoch 291/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9501\n",
      "Epoch 292/300\n",
      "5052/5052 [==============================] - 0s 78us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9535\n",
      "Epoch 293/300\n",
      "5052/5052 [==============================] - 0s 76us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9477\n",
      "Epoch 294/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9501\n",
      "Epoch 295/300\n",
      "5052/5052 [==============================] - 0s 75us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9315\n",
      "Epoch 296/300\n",
      "5052/5052 [==============================] - 0s 70us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9471\n",
      "Epoch 297/300\n",
      "5052/5052 [==============================] - 0s 97us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9519\n",
      "Epoch 298/300\n",
      "5052/5052 [==============================] - 1s 114us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9321\n",
      "Epoch 299/300\n",
      "5052/5052 [==============================] - 0s 99us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9477\n",
      "Epoch 300/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9321\n",
      "2526/2526 [==============================] - 0s 90us/step\n",
      "5052/5052 [==============================] - 0s 35us/step\n",
      "The Score is 0.982977\n",
      "current iteration fraction: 0.400000\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(4041, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4041/4041 [==============================] - 2s 410us/step - loss: 0.1869 - mean_squared_error: 0.1869 - acc: 0.5746\n",
      "Epoch 2/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.1649 - mean_squared_error: 0.1649 - acc: 0.6340\n",
      "Epoch 3/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.1577 - mean_squared_error: 0.1577 - acc: 0.6506\n",
      "Epoch 4/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.1523 - mean_squared_error: 0.1523 - acc: 0.6560\n",
      "Epoch 5/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.1467 - mean_squared_error: 0.1467 - acc: 0.6746\n",
      "Epoch 6/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.1325 - mean_squared_error: 0.1325 - acc: 0.7228\n",
      "Epoch 7/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.1219 - mean_squared_error: 0.1219 - acc: 0.7644\n",
      "Epoch 8/300\n",
      "4041/4041 [==============================] - 0s 98us/step - loss: 0.1178 - mean_squared_error: 0.1178 - acc: 0.7832\n",
      "Epoch 9/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.1014 - mean_squared_error: 0.1014 - acc: 0.8241\n",
      "Epoch 10/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.0819 - mean_squared_error: 0.0819 - acc: 0.8683\n",
      "Epoch 11/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.0743 - mean_squared_error: 0.0743 - acc: 0.8758 0s - loss: 0.0694 - mean_squared_error: 0.0694\n",
      "Epoch 12/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0654 - mean_squared_error: 0.0654 - acc: 0.8928\n",
      "Epoch 13/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0740 - mean_squared_error: 0.0740 - acc: 0.8753\n",
      "Epoch 14/300\n",
      "4041/4041 [==============================] - 0s 82us/step - loss: 0.0689 - mean_squared_error: 0.0689 - acc: 0.8839\n",
      "Epoch 15/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0582 - mean_squared_error: 0.0582 - acc: 0.9032\n",
      "Epoch 16/300\n",
      "4041/4041 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0511 - acc: 0.91 - 0s 76us/step - loss: 0.0502 - mean_squared_error: 0.0502 - acc: 0.9176\n",
      "Epoch 17/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.0495 - mean_squared_error: 0.0495 - acc: 0.9213\n",
      "Epoch 18/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0529 - mean_squared_error: 0.0529 - acc: 0.9141\n",
      "Epoch 19/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0626 - mean_squared_error: 0.0626 - acc: 0.8946\n",
      "Epoch 20/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0574 - mean_squared_error: 0.0574 - acc: 0.9013\n",
      "Epoch 21/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0578 - mean_squared_error: 0.0578 - acc: 0.8990\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9319\n",
      "Epoch 23/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0449 - mean_squared_error: 0.0449 - acc: 0.9292\n",
      "Epoch 24/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0433 - mean_squared_error: 0.0433 - acc: 0.9305\n",
      "Epoch 25/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9302\n",
      "Epoch 26/300\n",
      "4041/4041 [==============================] - 0s 92us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9406\n",
      "Epoch 27/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9319\n",
      "Epoch 28/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9270\n",
      "Epoch 29/300\n",
      "4041/4041 [==============================] - 0s 93us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9268\n",
      "Epoch 30/300\n",
      "4041/4041 [==============================] - 0s 101us/step - loss: 0.0499 - mean_squared_error: 0.0499 - acc: 0.9109\n",
      "Epoch 31/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9386\n",
      "Epoch 32/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9213\n",
      "Epoch 33/300\n",
      "4041/4041 [==============================] - 0s 89us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9258\n",
      "Epoch 34/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.0453 - mean_squared_error: 0.0453 - acc: 0.9216\n",
      "Epoch 35/300\n",
      "4041/4041 [==============================] - 1s 146us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9376\n",
      "Epoch 36/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9300\n",
      "Epoch 37/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9324\n",
      "Epoch 38/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0494 - mean_squared_error: 0.0494 - acc: 0.9134\n",
      "Epoch 39/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0522 - mean_squared_error: 0.0522 - acc: 0.9087\n",
      "Epoch 40/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.9302\n",
      "Epoch 41/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9389\n",
      "Epoch 42/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0504 - mean_squared_error: 0.0504 - acc: 0.9107\n",
      "Epoch 43/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9344\n",
      "Epoch 44/300\n",
      "4041/4041 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.93 - 0s 77us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9310\n",
      "Epoch 45/300\n",
      "4041/4041 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0427 - acc: 0.92 - 0s 123us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9292\n",
      "Epoch 46/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0426 - mean_squared_error: 0.0426 - acc: 0.9268\n",
      "Epoch 47/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9342\n",
      "Epoch 48/300\n",
      "4041/4041 [==============================] - 1s 133us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9475\n",
      "Epoch 49/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9384\n",
      "Epoch 50/300\n",
      "4041/4041 [==============================] - 1s 129us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9277\n",
      "Epoch 51/300\n",
      "4041/4041 [==============================] - 1s 141us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9366\n",
      "Epoch 52/300\n",
      "4041/4041 [==============================] - 1s 144us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9418\n",
      "Epoch 53/300\n",
      "4041/4041 [==============================] - 1s 191us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9475\n",
      "Epoch 54/300\n",
      "4041/4041 [==============================] - 1s 198us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9384\n",
      "Epoch 55/300\n",
      "4041/4041 [==============================] - 0s 96us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9344\n",
      "Epoch 56/300\n",
      "4041/4041 [==============================] - 0s 101us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9500\n",
      "Epoch 57/300\n",
      "4041/4041 [==============================] - 0s 109us/step - loss: 0.0440 - mean_squared_error: 0.0440 - acc: 0.9228\n",
      "Epoch 58/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0441 - mean_squared_error: 0.0441 - acc: 0.9253\n",
      "Epoch 59/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0630 - mean_squared_error: 0.0630 - acc: 0.8829\n",
      "Epoch 60/300\n",
      "4041/4041 [==============================] - 0s 92us/step - loss: 0.0583 - mean_squared_error: 0.0583 - acc: 0.8936\n",
      "Epoch 61/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0557 - mean_squared_error: 0.0557 - acc: 0.9008\n",
      "Epoch 62/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9282\n",
      "Epoch 63/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9369\n",
      "Epoch 64/300\n",
      "4041/4041 [==============================] - 0s 89us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9282\n",
      "Epoch 65/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9245\n",
      "Epoch 66/300\n",
      "4041/4041 [==============================] - 0s 84us/step - loss: 0.0444 - mean_squared_error: 0.0444 - acc: 0.9260\n",
      "Epoch 67/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9451\n",
      "Epoch 68/300\n",
      "4041/4041 [==============================] - 1s 162us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9317\n",
      "Epoch 69/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.0520 - mean_squared_error: 0.0520 - acc: 0.9087\n",
      "Epoch 70/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9166\n",
      "Epoch 71/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.0400 - mean_squared_error: 0.0400 - acc: 0.9329\n",
      "Epoch 72/300\n",
      "4041/4041 [==============================] - 0s 99us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9416\n",
      "Epoch 73/300\n",
      "4041/4041 [==============================] - 1s 135us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9250\n",
      "Epoch 74/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9339\n",
      "Epoch 75/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9379\n",
      "Epoch 76/300\n",
      "4041/4041 [==============================] - 1s 146us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9379\n",
      "Epoch 77/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.0418 - mean_squared_error: 0.0418 - acc: 0.9307\n",
      "Epoch 78/300\n",
      "4041/4041 [==============================] - 0s 92us/step - loss: 0.0544 - mean_squared_error: 0.0544 - acc: 0.9027\n",
      "Epoch 79/300\n",
      "4041/4041 [==============================] - 0s 97us/step - loss: 0.0511 - mean_squared_error: 0.0511 - acc: 0.9107\n",
      "Epoch 80/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0470 - mean_squared_error: 0.0470 - acc: 0.9156\n",
      "Epoch 81/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0518 - mean_squared_error: 0.0518 - acc: 0.9070\n",
      "Epoch 82/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.0422 - mean_squared_error: 0.0422 - acc: 0.9292\n",
      "Epoch 83/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.0576 - mean_squared_error: 0.0576 - acc: 0.89430s - loss: 0.0577 - mean_squared_error: 0.0577 - acc: 0.89\n",
      "Epoch 84/300\n",
      "4041/4041 [==============================] - 1s 180us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.92430s - loss: 0.0514 - mean_squared_error\n",
      "Epoch 85/300\n",
      "4041/4041 [==============================] - 1s 231us/step - loss: 0.0466 - mean_squared_error: 0.0466 - acc: 0.9178\n",
      "Epoch 86/300\n",
      "4041/4041 [==============================] - 1s 240us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9287\n",
      "Epoch 87/300\n",
      "4041/4041 [==============================] - 1s 247us/step - loss: 0.0615 - mean_squared_error: 0.0615 - acc: 0.8872\n",
      "Epoch 88/300\n",
      "4041/4041 [==============================] - 1s 201us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9070\n",
      "Epoch 89/300\n",
      "4041/4041 [==============================] - 1s 134us/step - loss: 0.0494 - mean_squared_error: 0.0494 - acc: 0.9087\n",
      "Epoch 90/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.0627 - mean_squared_error: 0.0627 - acc: 0.8782\n",
      "Epoch 91/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0556 - mean_squared_error: 0.0556 - acc: 0.8956\n",
      "Epoch 92/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0476 - mean_squared_error: 0.0476 - acc: 0.9134\n",
      "Epoch 93/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0461 - mean_squared_error: 0.0461 - acc: 0.9159\n",
      "Epoch 94/300\n",
      "4041/4041 [==============================] - 0s 78us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9223\n",
      "Epoch 95/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9211\n",
      "Epoch 96/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.9188\n",
      "Epoch 97/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9201\n",
      "Epoch 98/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9272\n",
      "Epoch 99/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9315\n",
      "Epoch 100/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9371\n",
      "Epoch 101/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9379\n",
      "Epoch 102/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9443\n",
      "Epoch 103/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9310\n",
      "Epoch 104/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9292\n",
      "Epoch 105/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9354\n",
      "Epoch 106/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9322\n",
      "Epoch 107/300\n",
      "4041/4041 [==============================] - 0s 97us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9342\n",
      "Epoch 108/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9359\n",
      "Epoch 109/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9339\n",
      "Epoch 110/300\n",
      "4041/4041 [==============================] - 0s 96us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9265\n",
      "Epoch 111/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9399\n",
      "Epoch 112/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9431\n",
      "Epoch 113/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9465\n",
      "Epoch 114/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9436\n",
      "Epoch 115/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9332\n",
      "Epoch 116/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9183\n",
      "Epoch 117/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9302\n",
      "Epoch 118/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9324\n",
      "Epoch 119/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.0478 - mean_squared_error: 0.0478 - acc: 0.9070\n",
      "Epoch 120/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9371\n",
      "Epoch 121/300\n",
      "4041/4041 [==============================] - 1s 135us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9277\n",
      "Epoch 122/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9287\n",
      "Epoch 123/300\n",
      "4041/4041 [==============================] - 1s 185us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9186\n",
      "Epoch 124/300\n",
      "4041/4041 [==============================] - 1s 147us/step - loss: 0.0450 - mean_squared_error: 0.0450 - acc: 0.91220s - loss: 0.0489 - mean_squared_error: 0.\n",
      "Epoch 125/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9428\n",
      "Epoch 126/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9443\n",
      "Epoch 127/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9371\n",
      "Epoch 128/300\n",
      "4041/4041 [==============================] - 0s 89us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9404\n",
      "Epoch 129/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9334\n",
      "Epoch 130/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9310\n",
      "Epoch 131/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9414\n",
      "Epoch 132/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9399\n",
      "Epoch 133/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9428 0s - loss: 0.0279 - mean_squared_error: 0.0279 - a\n",
      "Epoch 134/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9443\n",
      "Epoch 135/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9423\n",
      "Epoch 136/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9302\n",
      "Epoch 137/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9389\n",
      "Epoch 138/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9332\n",
      "Epoch 139/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0856 - mean_squared_error: 0.0856 - acc: 0.8275\n",
      "Epoch 140/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0530 - mean_squared_error: 0.0530 - acc: 0.9050\n",
      "Epoch 141/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9223\n",
      "Epoch 142/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0526 - mean_squared_error: 0.0526 - acc: 0.9035\n",
      "Epoch 143/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0498 - mean_squared_error: 0.0498 - acc: 0.9072\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.9183\n",
      "Epoch 145/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.9188\n",
      "Epoch 146/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9292\n",
      "Epoch 147/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0422 - mean_squared_error: 0.0422 - acc: 0.9272\n",
      "Epoch 148/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9409\n",
      "Epoch 149/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0508 - mean_squared_error: 0.0508 - acc: 0.9055\n",
      "Epoch 150/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0424 - mean_squared_error: 0.0424 - acc: 0.9230\n",
      "Epoch 151/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9240\n",
      "Epoch 152/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9374\n",
      "Epoch 153/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9366\n",
      "Epoch 154/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9334 0s - loss: 0.0324 - mean_squared_error: 0.0324 -\n",
      "Epoch 155/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9399\n",
      "Epoch 156/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9431\n",
      "Epoch 157/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9478\n",
      "Epoch 158/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9287 0s - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.\n",
      "Epoch 159/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9260\n",
      "Epoch 160/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9349\n",
      "Epoch 161/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9463\n",
      "Epoch 162/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9532\n",
      "Epoch 163/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9461\n",
      "Epoch 164/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9322\n",
      "Epoch 165/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9280\n",
      "Epoch 166/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0422 - mean_squared_error: 0.0422 - acc: 0.9216\n",
      "Epoch 167/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9433 0s - loss: 0.0347 - mean_squared_error: 0.0347 - acc\n",
      "Epoch 168/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9255\n",
      "Epoch 169/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9354\n",
      "Epoch 170/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9411\n",
      "Epoch 171/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9337\n",
      "Epoch 172/300\n",
      "4041/4041 [==============================] - 0s 90us/step - loss: 0.0475 - mean_squared_error: 0.0475 - acc: 0.9171\n",
      "Epoch 173/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0475 - mean_squared_error: 0.0475 - acc: 0.9144\n",
      "Epoch 174/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9225\n",
      "Epoch 175/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9280\n",
      "Epoch 176/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9359\n",
      "Epoch 177/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9453\n",
      "Epoch 178/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9436\n",
      "Epoch 179/300\n",
      "4041/4041 [==============================] - 1s 153us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9423\n",
      "Epoch 180/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9362\n",
      "Epoch 181/300\n",
      "4041/4041 [==============================] - 1s 152us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9317\n",
      "Epoch 182/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9305\n",
      "Epoch 183/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9433\n",
      "Epoch 184/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9438\n",
      "Epoch 185/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9376\n",
      "Epoch 186/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9414\n",
      "Epoch 187/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9394 0s - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.94\n",
      "Epoch 188/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9265\n",
      "Epoch 189/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9475\n",
      "Epoch 190/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9458\n",
      "Epoch 191/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9391\n",
      "Epoch 192/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9426\n",
      "Epoch 193/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9352\n",
      "Epoch 194/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9342\n",
      "Epoch 195/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9332\n",
      "Epoch 196/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9342\n",
      "Epoch 197/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9359\n",
      "Epoch 198/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0424 - mean_squared_error: 0.0424 - acc: 0.9263\n",
      "Epoch 199/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9339\n",
      "Epoch 200/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9421\n",
      "Epoch 201/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9362\n",
      "Epoch 202/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9406\n",
      "Epoch 203/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9510\n",
      "Epoch 204/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9562 0s - loss: 0.0267 - mean_squared_error: 0.0267 - acc: \n",
      "Epoch 205/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9564\n",
      "Epoch 206/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9560\n",
      "Epoch 207/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9562\n",
      "Epoch 208/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9431\n",
      "Epoch 209/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9436\n",
      "Epoch 210/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9552\n",
      "Epoch 211/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9287\n",
      "Epoch 212/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9478\n",
      "Epoch 213/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9540\n",
      "Epoch 214/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9483\n",
      "Epoch 215/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9522\n",
      "Epoch 216/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9510\n",
      "Epoch 217/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9493\n",
      "Epoch 218/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9552\n",
      "Epoch 219/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9512\n",
      "Epoch 220/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9379\n",
      "Epoch 221/300\n",
      "4041/4041 [==============================] - 0s 82us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9490\n",
      "Epoch 222/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9503\n",
      "Epoch 223/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9607 0s - loss: 0.0191 - mean_squared_error: 0.0191 - a\n",
      "Epoch 224/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9594\n",
      "Epoch 225/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9527\n",
      "Epoch 226/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9483\n",
      "Epoch 227/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9441\n",
      "Epoch 228/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0468 - mean_squared_error: 0.0468 - acc: 0.9097\n",
      "Epoch 229/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0425 - mean_squared_error: 0.0425 - acc: 0.9258\n",
      "Epoch 230/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0430 - mean_squared_error: 0.0430 - acc: 0.9211\n",
      "Epoch 231/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9334\n",
      "Epoch 232/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9376\n",
      "Epoch 233/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9243\n",
      "Epoch 234/300\n",
      "4041/4041 [==============================] - 0s 78us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9431\n",
      "Epoch 235/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9522\n",
      "Epoch 236/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.9280\n",
      "Epoch 237/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9389\n",
      "Epoch 238/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9423\n",
      "Epoch 239/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9470 0s - loss: 0.0301 - mean_squared_error: 0.0301 - acc: \n",
      "Epoch 240/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9307\n",
      "Epoch 241/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9384\n",
      "Epoch 242/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9431\n",
      "Epoch 243/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9495\n",
      "Epoch 244/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9448\n",
      "Epoch 245/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9317\n",
      "Epoch 246/300\n",
      "4041/4041 [==============================] - 0s 99us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9438\n",
      "Epoch 247/300\n",
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9438\n",
      "Epoch 248/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9461\n",
      "Epoch 249/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9337\n",
      "Epoch 250/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9406\n",
      "Epoch 251/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9409\n",
      "Epoch 252/300\n",
      "4041/4041 [==============================] - 0s 78us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9532\n",
      "Epoch 253/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9470\n",
      "Epoch 254/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9490\n",
      "Epoch 255/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9626\n",
      "Epoch 256/300\n",
      "4041/4041 [==============================] - 0s 78us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9572\n",
      "Epoch 257/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9584\n",
      "Epoch 258/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9498\n",
      "Epoch 259/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9540\n",
      "Epoch 260/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9584\n",
      "Epoch 261/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9475\n",
      "Epoch 262/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9599\n",
      "Epoch 263/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0210 - mean_squared_error: 0.0210 - acc: 0.9659\n",
      "Epoch 264/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9624\n",
      "Epoch 265/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 83us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9512\n",
      "Epoch 266/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9508\n",
      "Epoch 267/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9401\n",
      "Epoch 268/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9463\n",
      "Epoch 269/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9560\n",
      "Epoch 270/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9505\n",
      "Epoch 271/300\n",
      "4041/4041 [==============================] - 0s 72us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9564\n",
      "Epoch 272/300\n",
      "4041/4041 [==============================] - 0s 73us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9537\n",
      "Epoch 273/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9552\n",
      "Epoch 274/300\n",
      "4041/4041 [==============================] - 0s 70us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9525\n",
      "Epoch 275/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9483\n",
      "Epoch 276/300\n",
      "4041/4041 [==============================] - 0s 69us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9463\n",
      "Epoch 277/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9560\n",
      "Epoch 278/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9436\n",
      "Epoch 279/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9547\n",
      "Epoch 280/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9564\n",
      "Epoch 281/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9493\n",
      "Epoch 282/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9366\n",
      "Epoch 283/300\n",
      "4041/4041 [==============================] - 0s 85us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9465\n",
      "Epoch 284/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9517\n",
      "Epoch 285/300\n",
      "4041/4041 [==============================] - 0s 89us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9515\n",
      "Epoch 286/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9379\n",
      "Epoch 287/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9366\n",
      "Epoch 288/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9550\n",
      "Epoch 289/300\n",
      "4041/4041 [==============================] - 1s 137us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9582\n",
      "Epoch 290/300\n",
      "4041/4041 [==============================] - 0s 101us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9594\n",
      "Epoch 291/300\n",
      "4041/4041 [==============================] - 0s 82us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9619\n",
      "Epoch 292/300\n",
      "4041/4041 [==============================] - 0s 75us/step - loss: 0.0220 - mean_squared_error: 0.0220 - acc: 0.9644\n",
      "Epoch 293/300\n",
      "4041/4041 [==============================] - 0s 74us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9414\n",
      "Epoch 294/300\n",
      "4041/4041 [==============================] - 0s 76us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9510\n",
      "Epoch 295/300\n",
      "4041/4041 [==============================] - 0s 80us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9542 0s - loss: 0.0276 - mean_squared_error: 0.0276 - acc: \n",
      "Epoch 296/300\n",
      "4041/4041 [==============================] - 0s 79us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9443\n",
      "Epoch 297/300\n",
      "4041/4041 [==============================] - 0s 71us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9577\n",
      "Epoch 298/300\n",
      "4041/4041 [==============================] - 0s 81us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9411\n",
      "Epoch 299/300\n",
      "4041/4041 [==============================] - 0s 77us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9443\n",
      "Epoch 300/300\n",
      "4041/4041 [==============================] - 1s 155us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9498\n",
      "2526/2526 [==============================] - 0s 92us/step\n",
      "4041/4041 [==============================] - 0s 31us/step\n",
      "The Score is 0.966746\n",
      "current iteration fraction: 0.300000\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "(3031, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "3031/3031 [==============================] - 1s 386us/step - loss: 0.2072 - mean_squared_error: 0.2072 - acc: 0.5292\n",
      "Epoch 2/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.1692 - mean_squared_error: 0.1692 - acc: 0.6397\n",
      "Epoch 3/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.1608 - mean_squared_error: 0.1608 - acc: 0.6470\n",
      "Epoch 4/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.1555 - mean_squared_error: 0.1555 - acc: 0.6572\n",
      "Epoch 5/300\n",
      "3031/3031 [==============================] - 0s 135us/step - loss: 0.1513 - mean_squared_error: 0.1513 - acc: 0.6701\n",
      "Epoch 6/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.1447 - mean_squared_error: 0.1447 - acc: 0.6787\n",
      "Epoch 7/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.1391 - mean_squared_error: 0.1391 - acc: 0.7113\n",
      "Epoch 8/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.1332 - mean_squared_error: 0.1332 - acc: 0.7281\n",
      "Epoch 9/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.1226 - mean_squared_error: 0.1226 - acc: 0.7631\n",
      "Epoch 10/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.1148 - mean_squared_error: 0.1148 - acc: 0.7786\n",
      "Epoch 11/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.1065 - mean_squared_error: 0.1065 - acc: 0.8014\n",
      "Epoch 12/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0931 - mean_squared_error: 0.0931 - acc: 0.8397\n",
      "Epoch 13/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0892 - mean_squared_error: 0.0892 - acc: 0.8439\n",
      "Epoch 14/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0790 - mean_squared_error: 0.0790 - acc: 0.8713\n",
      "Epoch 15/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.0819 - mean_squared_error: 0.0819 - acc: 0.8525\n",
      "Epoch 16/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0701 - mean_squared_error: 0.0701 - acc: 0.8816\n",
      "Epoch 17/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0710 - mean_squared_error: 0.0710 - acc: 0.8743\n",
      "Epoch 18/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.0662 - mean_squared_error: 0.0662 - acc: 0.8878\n",
      "Epoch 19/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.0589 - mean_squared_error: 0.0589 - acc: 0.9023\n",
      "Epoch 20/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.0681 - mean_squared_error: 0.0681 - acc: 0.8819\n",
      "Epoch 21/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.0608 - mean_squared_error: 0.0608 - acc: 0.8964\n",
      "Epoch 22/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0624 - mean_squared_error: 0.0624 - acc: 0.8895\n",
      "Epoch 23/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0604 - mean_squared_error: 0.0604 - acc: 0.8971\n",
      "Epoch 24/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0548 - mean_squared_error: 0.0548 - acc: 0.9050\n",
      "Epoch 25/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0547 - mean_squared_error: 0.0547 - acc: 0.9063\n",
      "Epoch 26/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0546 - mean_squared_error: 0.0546 - acc: 0.9080\n",
      "Epoch 27/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0520 - mean_squared_error: 0.0520 - acc: 0.9162\n",
      "Epoch 28/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0475 - mean_squared_error: 0.0475 - acc: 0.9182\n",
      "Epoch 29/300\n",
      "3031/3031 [==============================] - 0s 89us/step - loss: 0.0470 - mean_squared_error: 0.0470 - acc: 0.9228\n",
      "Epoch 30/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9261\n",
      "Epoch 31/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9320\n",
      "Epoch 32/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9218\n",
      "Epoch 33/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9310\n",
      "Epoch 34/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0436 - mean_squared_error: 0.0436 - acc: 0.9248\n",
      "Epoch 35/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9188\n",
      "Epoch 36/300\n",
      "3031/3031 [==============================] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.0527 - acc: 0.90 - 0s 84us/step - loss: 0.0514 - mean_squared_error: 0.0514 - acc: 0.9056\n",
      "Epoch 37/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9281\n",
      "Epoch 38/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9347\n",
      "Epoch 39/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0426 - mean_squared_error: 0.0426 - acc: 0.9301\n",
      "Epoch 40/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9235\n",
      "Epoch 41/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9400\n",
      "Epoch 42/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9304\n",
      "Epoch 43/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0572 - mean_squared_error: 0.0572 - acc: 0.8921\n",
      "Epoch 44/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0527 - mean_squared_error: 0.0527 - acc: 0.9060\n",
      "Epoch 45/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9307\n",
      "Epoch 46/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0453 - mean_squared_error: 0.0453 - acc: 0.9254\n",
      "Epoch 47/300\n",
      "3031/3031 [==============================] - 0s 146us/step - loss: 0.0432 - mean_squared_error: 0.0432 - acc: 0.92680s - loss: 0.0474 - mean_squared_error: 0.04\n",
      "Epoch 48/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.0528 - mean_squared_error: 0.0528 - acc: 0.9007\n",
      "Epoch 49/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9172\n",
      "Epoch 50/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9350\n",
      "Epoch 51/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9439\n",
      "Epoch 52/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9324\n",
      "Epoch 53/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9218\n",
      "Epoch 54/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9376\n",
      "Epoch 55/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0473 - mean_squared_error: 0.0473 - acc: 0.9192\n",
      "Epoch 56/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.9254\n",
      "Epoch 57/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.9139\n",
      "Epoch 58/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9317\n",
      "Epoch 59/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9274\n",
      "Epoch 60/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9327\n",
      "Epoch 61/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9390\n",
      "Epoch 62/300\n",
      "3031/3031 [==============================] - 0s 102us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9390\n",
      "Epoch 63/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9324\n",
      "Epoch 64/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9419\n",
      "Epoch 65/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9314\n",
      "Epoch 66/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0465 - mean_squared_error: 0.0465 - acc: 0.9228\n",
      "Epoch 67/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9274\n",
      "Epoch 68/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9324\n",
      "Epoch 69/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9479\n",
      "Epoch 70/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9337\n",
      "Epoch 71/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9360\n",
      "Epoch 72/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9268 0s - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.92\n",
      "Epoch 73/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9218\n",
      "Epoch 74/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9403\n",
      "Epoch 75/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9386\n",
      "Epoch 76/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9376\n",
      "Epoch 77/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9360\n",
      "Epoch 78/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9373\n",
      "Epoch 79/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9373\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9340\n",
      "Epoch 81/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0436 - mean_squared_error: 0.0436 - acc: 0.9254\n",
      "Epoch 82/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0535 - mean_squared_error: 0.0535 - acc: 0.9066\n",
      "Epoch 83/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9258\n",
      "Epoch 84/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9406\n",
      "Epoch 85/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9426\n",
      "Epoch 86/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9386\n",
      "Epoch 87/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9429\n",
      "Epoch 88/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9363\n",
      "Epoch 89/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0676 - mean_squared_error: 0.0676 - acc: 0.8657\n",
      "Epoch 90/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0461 - mean_squared_error: 0.0461 - acc: 0.9228\n",
      "Epoch 91/300\n",
      "3031/3031 [==============================] - 0s 73us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9231\n",
      "Epoch 92/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0473 - mean_squared_error: 0.0473 - acc: 0.9215\n",
      "Epoch 93/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9291\n",
      "Epoch 94/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0617 - mean_squared_error: 0.0617 - acc: 0.8865\n",
      "Epoch 95/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0564 - mean_squared_error: 0.0564 - acc: 0.8974\n",
      "Epoch 96/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0607 - mean_squared_error: 0.0607 - acc: 0.8934\n",
      "Epoch 97/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0491 - mean_squared_error: 0.0491 - acc: 0.9152\n",
      "Epoch 98/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9301\n",
      "Epoch 99/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9337\n",
      "Epoch 100/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9413\n",
      "Epoch 101/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9386\n",
      "Epoch 102/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9409\n",
      "Epoch 103/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9390\n",
      "Epoch 104/300\n",
      "3031/3031 [==============================] - 0s 72us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9340\n",
      "Epoch 105/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9508\n",
      "Epoch 106/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9429\n",
      "Epoch 107/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9324\n",
      "Epoch 108/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9396\n",
      "Epoch 109/300\n",
      "3031/3031 [==============================] - 0s 141us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9367\n",
      "Epoch 110/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9258\n",
      "Epoch 111/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0457 - mean_squared_error: 0.0457 - acc: 0.9208\n",
      "Epoch 112/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9310\n",
      "Epoch 113/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9172\n",
      "Epoch 114/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0529 - mean_squared_error: 0.0529 - acc: 0.9060\n",
      "Epoch 115/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9132\n",
      "Epoch 116/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9307\n",
      "Epoch 117/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9423\n",
      "Epoch 118/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9433\n",
      "Epoch 119/300\n",
      "3031/3031 [==============================] - 0s 87us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9442\n",
      "Epoch 120/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9433\n",
      "Epoch 121/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9436\n",
      "Epoch 122/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9390\n",
      "Epoch 123/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9419\n",
      "Epoch 124/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9406\n",
      "Epoch 125/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9383\n",
      "Epoch 126/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9442\n",
      "Epoch 127/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9502\n",
      "Epoch 128/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9515\n",
      "Epoch 129/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9439\n",
      "Epoch 130/300\n",
      "3031/3031 [==============================] - 0s 89us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9466\n",
      "Epoch 131/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9512\n",
      "Epoch 132/300\n",
      "3031/3031 [==============================] - 0s 105us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9489\n",
      "Epoch 133/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9360\n",
      "Epoch 134/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0489 - mean_squared_error: 0.0489 - acc: 0.9136\n",
      "Epoch 135/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9452\n",
      "Epoch 136/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9403\n",
      "Epoch 137/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0514 - mean_squared_error: 0.0514 - acc: 0.9033\n",
      "Epoch 138/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9327\n",
      "Epoch 139/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0851 - mean_squared_error: 0.0851 - acc: 0.8357\n",
      "Epoch 140/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0568 - mean_squared_error: 0.0568 - acc: 0.8931\n",
      "Epoch 141/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9122\n",
      "Epoch 142/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0530 - mean_squared_error: 0.0530 - acc: 0.8997\n",
      "Epoch 143/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0478 - mean_squared_error: 0.0478 - acc: 0.9182\n",
      "Epoch 144/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0519 - mean_squared_error: 0.0519 - acc: 0.9106\n",
      "Epoch 145/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9195\n",
      "Epoch 146/300\n",
      "3031/3031 [==============================] - 0s 91us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9268\n",
      "Epoch 147/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0474 - mean_squared_error: 0.0474 - acc: 0.9172\n",
      "Epoch 148/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0461 - mean_squared_error: 0.0461 - acc: 0.9221\n",
      "Epoch 149/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9310\n",
      "Epoch 150/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.0426 - mean_squared_error: 0.0426 - acc: 0.9301\n",
      "Epoch 151/300\n",
      "3031/3031 [==============================] - 0s 87us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9281\n",
      "Epoch 152/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9291\n",
      "Epoch 153/300\n",
      "3031/3031 [==============================] - 0s 105us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.93500s - loss: 0.0358 - mean_squared_error: 0.0358 - a\n",
      "Epoch 154/300\n",
      "3031/3031 [==============================] - 0s 91us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9324\n",
      "Epoch 155/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.0477 - mean_squared_error: 0.0477 - acc: 0.9225\n",
      "Epoch 156/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0468 - mean_squared_error: 0.0468 - acc: 0.9178\n",
      "Epoch 157/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0474 - mean_squared_error: 0.0474 - acc: 0.9169\n",
      "Epoch 158/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9350\n",
      "Epoch 159/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9301\n",
      "Epoch 160/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9357\n",
      "Epoch 161/300\n",
      "3031/3031 [==============================] - 0s 98us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9413\n",
      "Epoch 162/300\n",
      "3031/3031 [==============================] - 0s 88us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9340\n",
      "Epoch 163/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9360\n",
      "Epoch 164/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9314\n",
      "Epoch 165/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9370\n",
      "Epoch 166/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0487 - mean_squared_error: 0.0487 - acc: 0.9162\n",
      "Epoch 167/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9347\n",
      "Epoch 168/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9406\n",
      "Epoch 169/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0450 - mean_squared_error: 0.0450 - acc: 0.9202\n",
      "Epoch 170/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9208\n",
      "Epoch 171/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0481 - mean_squared_error: 0.0481 - acc: 0.9106\n",
      "Epoch 172/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9360\n",
      "Epoch 173/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0424 - mean_squared_error: 0.0424 - acc: 0.9195\n",
      "Epoch 174/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9291\n",
      "Epoch 175/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9307\n",
      "Epoch 176/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9446\n",
      "Epoch 177/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9426\n",
      "Epoch 178/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9508\n",
      "Epoch 179/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9373\n",
      "Epoch 180/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9459\n",
      "Epoch 181/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9452\n",
      "Epoch 182/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9413\n",
      "Epoch 183/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9330\n",
      "Epoch 184/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0453 - mean_squared_error: 0.0453 - acc: 0.9221\n",
      "Epoch 185/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9363\n",
      "Epoch 186/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0456 - mean_squared_error: 0.0456 - acc: 0.9136\n",
      "Epoch 187/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9409\n",
      "Epoch 188/300\n",
      "3031/3031 [==============================] - 0s 73us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9314\n",
      "Epoch 189/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9396\n",
      "Epoch 190/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9518\n",
      "Epoch 191/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9317\n",
      "Epoch 192/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0492 - mean_squared_error: 0.0492 - acc: 0.9089\n",
      "Epoch 193/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9307\n",
      "Epoch 194/300\n",
      "3031/3031 [==============================] - 0s 89us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9380\n",
      "Epoch 195/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9162\n",
      "Epoch 196/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0633 - mean_squared_error: 0.0633 - acc: 0.8789 0s - loss: 0.0641 - mean_squared_error: 0.0641 - acc: 0.\n",
      "Epoch 197/300\n",
      "3031/3031 [==============================] - 0s 88us/step - loss: 0.0522 - mean_squared_error: 0.0522 - acc: 0.9099\n",
      "Epoch 198/300\n",
      "3031/3031 [==============================] - 0s 89us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9248\n",
      "Epoch 199/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0430 - mean_squared_error: 0.0430 - acc: 0.9284\n",
      "Epoch 200/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9350\n",
      "Epoch 201/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9264 0s - loss: 0.0388 - mean_squared_error: 0.0388 - acc: \n",
      "Epoch 202/300\n",
      "3031/3031 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.93 - 0s 84us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9376\n",
      "Epoch 203/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9310\n",
      "Epoch 204/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9390\n",
      "Epoch 205/300\n",
      "3031/3031 [==============================] - 0s 105us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9423\n",
      "Epoch 206/300\n",
      "3031/3031 [==============================] - 0s 98us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9456\n",
      "Epoch 207/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0354 - mean_squared_error: 0.0354 - acc: 0.9380\n",
      "Epoch 208/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0412 - mean_squared_error: 0.0412 - acc: 0.9287\n",
      "Epoch 209/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9235\n",
      "Epoch 210/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9241\n",
      "Epoch 211/300\n",
      "3031/3031 [==============================] - 0s 91us/step - loss: 0.0497 - mean_squared_error: 0.0497 - acc: 0.9119\n",
      "Epoch 212/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0509 - mean_squared_error: 0.0509 - acc: 0.9096\n",
      "Epoch 213/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0477 - mean_squared_error: 0.0477 - acc: 0.9152\n",
      "Epoch 214/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9254\n",
      "Epoch 215/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9291\n",
      "Epoch 216/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9340\n",
      "Epoch 217/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9353\n",
      "Epoch 218/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9380\n",
      "Epoch 219/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9403\n",
      "Epoch 220/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9426\n",
      "Epoch 221/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9357\n",
      "Epoch 222/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9317\n",
      "Epoch 223/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9442\n",
      "Epoch 224/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9469\n",
      "Epoch 225/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9400\n",
      "Epoch 226/300\n",
      "3031/3031 [==============================] - 0s 88us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9433\n",
      "Epoch 227/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9489\n",
      "Epoch 228/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9413\n",
      "Epoch 229/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9357\n",
      "Epoch 230/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9403\n",
      "Epoch 231/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.9294\n",
      "Epoch 232/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0476 - mean_squared_error: 0.0476 - acc: 0.9149\n",
      "Epoch 233/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0483 - mean_squared_error: 0.0483 - acc: 0.9103\n",
      "Epoch 234/300\n",
      "3031/3031 [==============================] - 0s 74us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9271\n",
      "Epoch 235/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9304\n",
      "Epoch 236/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9274\n",
      "Epoch 237/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9284\n",
      "Epoch 238/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9228\n",
      "Epoch 239/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9406\n",
      "Epoch 240/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9442\n",
      "Epoch 241/300\n",
      "3031/3031 [==============================] - 0s 102us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9475\n",
      "Epoch 242/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9334\n",
      "Epoch 243/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9353\n",
      "Epoch 244/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9406\n",
      "Epoch 245/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9334\n",
      "Epoch 246/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9304\n",
      "Epoch 247/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9271\n",
      "Epoch 248/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9403\n",
      "Epoch 249/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9436\n",
      "Epoch 250/300\n",
      "3031/3031 [==============================] - 0s 104us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9479\n",
      "Epoch 251/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9479\n",
      "Epoch 252/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9337\n",
      "Epoch 253/300\n",
      "3031/3031 [==============================] - 0s 142us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9469\n",
      "Epoch 254/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9393\n",
      "Epoch 255/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9416\n",
      "Epoch 256/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9538\n",
      "Epoch 257/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9558\n",
      "Epoch 258/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9505\n",
      "Epoch 259/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9505\n",
      "Epoch 260/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9416\n",
      "Epoch 261/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9396\n",
      "Epoch 262/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9492\n",
      "Epoch 263/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9383\n",
      "Epoch 264/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9535\n",
      "Epoch 265/300\n",
      "3031/3031 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.94 - 0s 85us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9499\n",
      "Epoch 266/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9310\n",
      "Epoch 267/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9327\n",
      "Epoch 268/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.0507 - mean_squared_error: 0.0507 - acc: 0.9076\n",
      "Epoch 269/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9541\n",
      "Epoch 270/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9449\n",
      "Epoch 271/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9551\n",
      "Epoch 272/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9462\n",
      "Epoch 273/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0230 - mean_squared_error: 0.0230 - acc: 0.9630\n",
      "Epoch 274/300\n",
      "3031/3031 [==============================] - 0s 78us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9601\n",
      "Epoch 275/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9611\n",
      "Epoch 276/300\n",
      "3031/3031 [==============================] - 0s 94us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9555\n",
      "Epoch 277/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9423\n",
      "Epoch 278/300\n",
      "3031/3031 [==============================] - 0s 88us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9433\n",
      "Epoch 279/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9466\n",
      "Epoch 280/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0416 - mean_squared_error: 0.0416 - acc: 0.9244\n",
      "Epoch 281/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9383\n",
      "Epoch 282/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9482\n",
      "Epoch 283/300\n",
      "3031/3031 [==============================] - 0s 88us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9492\n",
      "Epoch 284/300\n",
      "3031/3031 [==============================] - 0s 82us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9528\n",
      "Epoch 285/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9353\n",
      "Epoch 286/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9314\n",
      "Epoch 287/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9357\n",
      "Epoch 288/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9508\n",
      "Epoch 289/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9466\n",
      "Epoch 290/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9475\n",
      "Epoch 291/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0478 - mean_squared_error: 0.0478 - acc: 0.9165\n",
      "Epoch 292/300\n",
      "3031/3031 [==============================] - 0s 80us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9340\n",
      "Epoch 293/300\n",
      "3031/3031 [==============================] - 0s 77us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9409\n",
      "Epoch 294/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9340\n",
      "Epoch 295/300\n",
      "3031/3031 [==============================] - 0s 73us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9390\n",
      "Epoch 296/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9324\n",
      "Epoch 297/300\n",
      "3031/3031 [==============================] - 0s 76us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9304\n",
      "Epoch 298/300\n",
      "3031/3031 [==============================] - 0s 81us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9334\n",
      "Epoch 299/300\n",
      "3031/3031 [==============================] - 0s 75us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9281\n",
      "Epoch 300/300\n",
      "3031/3031 [==============================] - 0s 79us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9419\n",
      "2526/2526 [==============================] - 0s 95us/step\n",
      "3031/3031 [==============================] - 0s 31us/step\n",
      "The Score is 0.979018\n",
      "current iteration fraction: 0.200000\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(2020, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2020/2020 [==============================] - 1s 382us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.4634\n",
      "Epoch 2/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.1760 - mean_squared_error: 0.1760 - acc: 0.6178\n",
      "Epoch 3/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.1626 - mean_squared_error: 0.1626 - acc: 0.6564\n",
      "Epoch 4/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.1550 - mean_squared_error: 0.1550 - acc: 0.6673\n",
      "Epoch 5/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.1552 - mean_squared_error: 0.1552 - acc: 0.6609\n",
      "Epoch 6/300\n",
      "2020/2020 [==============================] - 0s 99us/step - loss: 0.1475 - mean_squared_error: 0.1475 - acc: 0.6772\n",
      "Epoch 7/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.1391 - mean_squared_error: 0.1391 - acc: 0.7114\n",
      "Epoch 8/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.1406 - mean_squared_error: 0.1406 - acc: 0.7015\n",
      "Epoch 9/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.1263 - mean_squared_error: 0.1263 - acc: 0.7406\n",
      "Epoch 10/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.1231 - mean_squared_error: 0.1231 - acc: 0.7678\n",
      "Epoch 11/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.1120 - mean_squared_error: 0.1120 - acc: 0.7960\n",
      "Epoch 12/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.1122 - mean_squared_error: 0.1122 - acc: 0.7936\n",
      "Epoch 13/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.1100 - mean_squared_error: 0.1100 - acc: 0.7931\n",
      "Epoch 14/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0906 - mean_squared_error: 0.0906 - acc: 0.8475\n",
      "Epoch 15/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0855 - mean_squared_error: 0.0855 - acc: 0.8545\n",
      "Epoch 16/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0937 - mean_squared_error: 0.0937 - acc: 0.8262\n",
      "Epoch 17/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0818 - mean_squared_error: 0.0818 - acc: 0.8599\n",
      "Epoch 18/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0710 - mean_squared_error: 0.0710 - acc: 0.8911\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0699 - mean_squared_error: 0.0699 - acc: 0.8851\n",
      "Epoch 20/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0651 - mean_squared_error: 0.0651 - acc: 0.8901\n",
      "Epoch 21/300\n",
      "2020/2020 [==============================] - 0s 95us/step - loss: 0.0806 - mean_squared_error: 0.0806 - acc: 0.8371\n",
      "Epoch 22/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.0753 - mean_squared_error: 0.0753 - acc: 0.8649\n",
      "Epoch 23/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0695 - mean_squared_error: 0.0695 - acc: 0.8812\n",
      "Epoch 24/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0672 - mean_squared_error: 0.0672 - acc: 0.8856\n",
      "Epoch 25/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0598 - mean_squared_error: 0.0598 - acc: 0.9045\n",
      "Epoch 26/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0556 - mean_squared_error: 0.0556 - acc: 0.9045\n",
      "Epoch 27/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0557 - mean_squared_error: 0.0557 - acc: 0.9069\n",
      "Epoch 28/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.0597 - mean_squared_error: 0.0597 - acc: 0.8941\n",
      "Epoch 29/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.0545 - mean_squared_error: 0.0545 - acc: 0.9119\n",
      "Epoch 30/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0547 - mean_squared_error: 0.0547 - acc: 0.9074\n",
      "Epoch 31/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0500 - mean_squared_error: 0.0500 - acc: 0.9149\n",
      "Epoch 32/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0534 - mean_squared_error: 0.0534 - acc: 0.9104\n",
      "Epoch 33/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0560 - mean_squared_error: 0.0560 - acc: 0.9020\n",
      "Epoch 34/300\n",
      "2020/2020 [==============================] - 0s 74us/step - loss: 0.0534 - mean_squared_error: 0.0534 - acc: 0.9000\n",
      "Epoch 35/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0514 - mean_squared_error: 0.0514 - acc: 0.9188\n",
      "Epoch 36/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9208\n",
      "Epoch 37/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0529 - mean_squared_error: 0.0529 - acc: 0.9050\n",
      "Epoch 38/300\n",
      "2020/2020 [==============================] - 0s 99us/step - loss: 0.0463 - mean_squared_error: 0.0463 - acc: 0.9193\n",
      "Epoch 39/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9228 0s - loss: 0.0444 - mean_squared_error: 0.0444 - acc: 0.92\n",
      "Epoch 40/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9391\n",
      "Epoch 41/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9203\n",
      "Epoch 42/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9252\n",
      "Epoch 43/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9208\n",
      "Epoch 44/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.92970s - loss: 0.0380 - mean_squared_error: 0.0380 - acc: \n",
      "Epoch 45/300\n",
      "2020/2020 [==============================] - 0s 98us/step - loss: 0.0432 - mean_squared_error: 0.0432 - acc: 0.9213\n",
      "Epoch 46/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9342\n",
      "Epoch 47/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.0463 - mean_squared_error: 0.0463 - acc: 0.9129\n",
      "Epoch 48/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9406\n",
      "Epoch 49/300\n",
      "2020/2020 [==============================] - 0s 73us/step - loss: 0.0463 - mean_squared_error: 0.0463 - acc: 0.9173\n",
      "Epoch 50/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9347\n",
      "Epoch 51/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9376\n",
      "Epoch 52/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.9307\n",
      "Epoch 53/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0433 - mean_squared_error: 0.0433 - acc: 0.9238\n",
      "Epoch 54/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9322\n",
      "Epoch 55/300\n",
      "2020/2020 [==============================] - 0s 112us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9302\n",
      "Epoch 56/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0525 - mean_squared_error: 0.0525 - acc: 0.8975\n",
      "Epoch 57/300\n",
      "2020/2020 [==============================] - 0s 85us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9431\n",
      "Epoch 58/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9347\n",
      "Epoch 59/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9292\n",
      "Epoch 60/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9302\n",
      "Epoch 61/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9356\n",
      "Epoch 62/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9252\n",
      "Epoch 63/300\n",
      "2020/2020 [==============================] - 0s 95us/step - loss: 0.0433 - mean_squared_error: 0.0433 - acc: 0.9238\n",
      "Epoch 64/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9277\n",
      "Epoch 65/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0637 - mean_squared_error: 0.0637 - acc: 0.8802\n",
      "Epoch 66/300\n",
      "2020/2020 [==============================] - 0s 98us/step - loss: 0.0472 - mean_squared_error: 0.0472 - acc: 0.9144\n",
      "Epoch 67/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0466 - mean_squared_error: 0.0466 - acc: 0.9163\n",
      "Epoch 68/300\n",
      "2020/2020 [==============================] - 0s 81us/step - loss: 0.0567 - mean_squared_error: 0.0567 - acc: 0.9020\n",
      "Epoch 69/300\n",
      "2020/2020 [==============================] - 0s 97us/step - loss: 0.0536 - mean_squared_error: 0.0536 - acc: 0.9054\n",
      "Epoch 70/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0473 - mean_squared_error: 0.0473 - acc: 0.9193\n",
      "Epoch 71/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.94 - 0s 99us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9337\n",
      "Epoch 72/300\n",
      "2020/2020 [==============================] - 0s 94us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9347\n",
      "Epoch 73/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9391\n",
      "Epoch 74/300\n",
      "2020/2020 [==============================] - 0s 114us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9307\n",
      "Epoch 75/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0529 - mean_squared_error: 0.0529 - acc: 0.8990\n",
      "Epoch 76/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9317\n",
      "Epoch 77/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0521 - mean_squared_error: 0.0521 - acc: 0.9045\n",
      "Epoch 78/300\n",
      "2020/2020 [==============================] - 0s 108us/step - loss: 0.0425 - mean_squared_error: 0.0425 - acc: 0.9243\n",
      "Epoch 79/300\n",
      "2020/2020 [==============================] - 0s 104us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9297\n",
      "Epoch 80/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.9153\n",
      "Epoch 81/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0417 - mean_squared_error: 0.0417 - acc: 0.9257\n",
      "Epoch 82/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0393 - mean_squared_error: 0.0393 - acc: 0.9287\n",
      "Epoch 83/300\n",
      "2020/2020 [==============================] - 0s 119us/step - loss: 0.0383 - mean_squared_error: 0.0383 - acc: 0.9322\n",
      "Epoch 84/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.0487 - mean_squared_error: 0.0487 - acc: 0.9064\n",
      "Epoch 85/300\n",
      "2020/2020 [==============================] - 0s 98us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9396\n",
      "Epoch 86/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.92 - 0s 96us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9302\n",
      "Epoch 87/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.0459 - mean_squared_error: 0.0459 - acc: 0.9218\n",
      "Epoch 88/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.93 - 0s 104us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9356\n",
      "Epoch 89/300\n",
      "2020/2020 [==============================] - 0s 112us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9446\n",
      "Epoch 90/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9347\n",
      "Epoch 91/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9401\n",
      "Epoch 92/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9356\n",
      "Epoch 93/300\n",
      "2020/2020 [==============================] - 0s 109us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9426\n",
      "Epoch 94/300\n",
      "2020/2020 [==============================] - 0s 113us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9337\n",
      "Epoch 95/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9391\n",
      "Epoch 96/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9465\n",
      "Epoch 97/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9441\n",
      "Epoch 98/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9327\n",
      "Epoch 99/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.9272\n",
      "Epoch 100/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0511 - mean_squared_error: 0.0511 - acc: 0.9119\n",
      "Epoch 101/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9386\n",
      "Epoch 102/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9337\n",
      "Epoch 103/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9376\n",
      "Epoch 104/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9406\n",
      "Epoch 105/300\n",
      "2020/2020 [==============================] - 0s 110us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9500\n",
      "Epoch 106/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9327\n",
      "Epoch 107/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9312\n",
      "Epoch 108/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9361\n",
      "Epoch 109/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9203\n",
      "Epoch 110/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9371\n",
      "Epoch 111/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9238\n",
      "Epoch 112/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9262\n",
      "Epoch 113/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9411\n",
      "Epoch 114/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9500\n",
      "Epoch 115/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9396\n",
      "Epoch 116/300\n",
      "2020/2020 [==============================] - 0s 183us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9490\n",
      "Epoch 117/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9545\n",
      "Epoch 118/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9480\n",
      "Epoch 119/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9535\n",
      "Epoch 120/300\n",
      "2020/2020 [==============================] - 0s 97us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9416\n",
      "Epoch 121/300\n",
      "2020/2020 [==============================] - 0s 94us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9337\n",
      "Epoch 122/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9327\n",
      "Epoch 123/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9307\n",
      "Epoch 124/300\n",
      "2020/2020 [==============================] - 0s 161us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9376\n",
      "Epoch 125/300\n",
      "2020/2020 [==============================] - 0s 140us/step - loss: 0.0628 - mean_squared_error: 0.0628 - acc: 0.8861\n",
      "Epoch 126/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9238\n",
      "Epoch 127/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9376\n",
      "Epoch 128/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9337\n",
      "Epoch 129/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9431\n",
      "Epoch 130/300\n",
      "2020/2020 [==============================] - 0s 94us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9490\n",
      "Epoch 131/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9386\n",
      "Epoch 132/300\n",
      "2020/2020 [==============================] - 0s 71us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9272\n",
      "Epoch 133/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9386\n",
      "Epoch 134/300\n",
      "2020/2020 [==============================] - 0s 85us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9356\n",
      "Epoch 135/300\n",
      "2020/2020 [==============================] - 0s 71us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9386\n",
      "Epoch 136/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9396\n",
      "Epoch 137/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9470\n",
      "Epoch 138/300\n",
      "2020/2020 [==============================] - 0s 74us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9262\n",
      "Epoch 139/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9411\n",
      "Epoch 140/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9307\n",
      "Epoch 141/300\n",
      "2020/2020 [==============================] - 0s 74us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9446\n",
      "Epoch 142/300\n",
      "2020/2020 [==============================] - 0s 74us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9436\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9574\n",
      "Epoch 144/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9540\n",
      "Epoch 145/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9515\n",
      "Epoch 146/300\n",
      "2020/2020 [==============================] - 0s 85us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9470\n",
      "Epoch 147/300\n",
      "2020/2020 [==============================] - 0s 81us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9381\n",
      "Epoch 148/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0470 - mean_squared_error: 0.0470 - acc: 0.9134\n",
      "Epoch 149/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.0572 - mean_squared_error: 0.0572 - acc: 0.8936\n",
      "Epoch 150/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9089\n",
      "Epoch 151/300\n",
      "2020/2020 [==============================] - 0s 73us/step - loss: 0.0578 - mean_squared_error: 0.0578 - acc: 0.8866\n",
      "Epoch 152/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9069\n",
      "Epoch 153/300\n",
      "2020/2020 [==============================] - 0s 85us/step - loss: 0.0468 - mean_squared_error: 0.0468 - acc: 0.9099\n",
      "Epoch 154/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0498 - mean_squared_error: 0.0498 - acc: 0.9064\n",
      "Epoch 155/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0440 - mean_squared_error: 0.0440 - acc: 0.9168\n",
      "Epoch 156/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9139\n",
      "Epoch 157/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9287\n",
      "Epoch 158/300\n",
      "2020/2020 [==============================] - 0s 72us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9287\n",
      "Epoch 159/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9366\n",
      "Epoch 160/300\n",
      "2020/2020 [==============================] - 0s 81us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9223\n",
      "Epoch 161/300\n",
      "2020/2020 [==============================] - 0s 73us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9386\n",
      "Epoch 162/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9441 0s - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.\n",
      "Epoch 163/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9307\n",
      "Epoch 164/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9351\n",
      "Epoch 165/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9297\n",
      "Epoch 166/300\n",
      "2020/2020 [==============================] - 0s 173us/step - loss: 0.0442 - mean_squared_error: 0.0442 - acc: 0.9124\n",
      "Epoch 167/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9228\n",
      "Epoch 168/300\n",
      "2020/2020 [==============================] - 0s 99us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9342\n",
      "Epoch 169/300\n",
      "2020/2020 [==============================] - 0s 79us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9218\n",
      "Epoch 170/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9356\n",
      "Epoch 171/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9366\n",
      "Epoch 172/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9371\n",
      "Epoch 173/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9342\n",
      "Epoch 174/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9356\n",
      "Epoch 175/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0370 - mean_squared_error: 0.0370 - acc: 0.9322\n",
      "Epoch 176/300\n",
      "2020/2020 [==============================] - 0s 70us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9361\n",
      "Epoch 177/300\n",
      "2020/2020 [==============================] - 0s 72us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9460\n",
      "Epoch 178/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9401\n",
      "Epoch 179/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9248\n",
      "Epoch 180/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9277\n",
      "Epoch 181/300\n",
      "2020/2020 [==============================] - 0s 159us/step - loss: 0.0488 - mean_squared_error: 0.0488 - acc: 0.9045\n",
      "Epoch 182/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.0700 - mean_squared_error: 0.0700 - acc: 0.8604\n",
      "Epoch 183/300\n",
      "2020/2020 [==============================] - 0s 184us/step - loss: 0.0486 - mean_squared_error: 0.0486 - acc: 0.9050\n",
      "Epoch 184/300\n",
      "2020/2020 [==============================] - 0s 154us/step - loss: 0.0400 - mean_squared_error: 0.0400 - acc: 0.9228\n",
      "Epoch 185/300\n",
      "2020/2020 [==============================] - 0s 147us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9257\n",
      "Epoch 186/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9020\n",
      "Epoch 187/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9351\n",
      "Epoch 188/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9327\n",
      "Epoch 189/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9460\n",
      "Epoch 190/300\n",
      "2020/2020 [==============================] - 0s 73us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9396\n",
      "Epoch 191/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9436\n",
      "Epoch 192/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9386\n",
      "Epoch 193/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9376\n",
      "Epoch 194/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9381\n",
      "Epoch 195/300\n",
      "2020/2020 [==============================] - 0s 94us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9446\n",
      "Epoch 196/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9386\n",
      "Epoch 197/300\n",
      "2020/2020 [==============================] - 0s 109us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9238\n",
      "Epoch 198/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9351\n",
      "Epoch 199/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9342\n",
      "Epoch 200/300\n",
      "2020/2020 [==============================] - 0s 132us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9183\n",
      "Epoch 201/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9312\n",
      "Epoch 202/300\n",
      "2020/2020 [==============================] - 0s 141us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9421\n",
      "Epoch 203/300\n",
      "2020/2020 [==============================] - 0s 85us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9356\n",
      "Epoch 204/300\n",
      "2020/2020 [==============================] - 0s 74us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9431\n",
      "Epoch 205/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9455\n",
      "Epoch 206/300\n",
      "2020/2020 [==============================] - 0s 227us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9277\n",
      "Epoch 207/300\n",
      "2020/2020 [==============================] - 0s 225us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9441\n",
      "Epoch 208/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9470\n",
      "Epoch 209/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9386\n",
      "Epoch 210/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9446\n",
      "Epoch 211/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9441\n",
      "Epoch 212/300\n",
      "2020/2020 [==============================] - 0s 203us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9505\n",
      "Epoch 213/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.92820s - loss: 0.0412 - mean_squared_error: 0.0412 - acc: \n",
      "Epoch 214/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9421\n",
      "Epoch 215/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9495\n",
      "Epoch 216/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9386\n",
      "Epoch 217/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9421\n",
      "Epoch 218/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9386\n",
      "Epoch 219/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9406\n",
      "Epoch 220/300\n",
      "2020/2020 [==============================] - 0s 147us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9520\n",
      "Epoch 221/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9188\n",
      "Epoch 222/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0451 - mean_squared_error: 0.0451 - acc: 0.9153\n",
      "Epoch 223/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9396\n",
      "Epoch 224/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0350 - mean_squared_error: 0.0350 - acc: 0.9376\n",
      "Epoch 225/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9455\n",
      "Epoch 226/300\n",
      "2020/2020 [==============================] - 0s 95us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9297\n",
      "Epoch 227/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0772 - mean_squared_error: 0.0772 - acc: 0.8495\n",
      "Epoch 228/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.0627 - mean_squared_error: 0.0627 - acc: 0.8911\n",
      "Epoch 229/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0476 - mean_squared_error: 0.0476 - acc: 0.9213\n",
      "Epoch 230/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9203\n",
      "Epoch 231/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0437 - mean_squared_error: 0.0437 - acc: 0.9228\n",
      "Epoch 232/300\n",
      "2020/2020 [==============================] - 0s 231us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9272\n",
      "Epoch 233/300\n",
      "2020/2020 [==============================] - 0s 199us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9282\n",
      "Epoch 234/300\n",
      "2020/2020 [==============================] - 0s 183us/step - loss: 0.0414 - mean_squared_error: 0.0414 - acc: 0.9282\n",
      "Epoch 235/300\n",
      "2020/2020 [==============================] - 0s 163us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9272\n",
      "Epoch 236/300\n",
      "2020/2020 [==============================] - 0s 163us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9342\n",
      "Epoch 237/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9431\n",
      "Epoch 238/300\n",
      "2020/2020 [==============================] - 0s 110us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9292\n",
      "Epoch 239/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9381\n",
      "Epoch 240/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.94850s - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.94\n",
      "Epoch 241/300\n",
      "2020/2020 [==============================] - 0s 166us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.9535\n",
      "Epoch 242/300\n",
      "2020/2020 [==============================] - 0s 209us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9525\n",
      "Epoch 243/300\n",
      "2020/2020 [==============================] - 0s 239us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9282\n",
      "Epoch 244/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.94500s - loss: 0.0229 - mean_squared_error: 0.0229 - acc\n",
      "Epoch 245/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9446\n",
      "Epoch 246/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9525\n",
      "Epoch 247/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9505\n",
      "Epoch 248/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9530\n",
      "Epoch 249/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9495\n",
      "Epoch 250/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9450\n",
      "Epoch 251/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9485\n",
      "Epoch 252/300\n",
      "2020/2020 [==============================] - 0s 81us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9446\n",
      "Epoch 253/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9450\n",
      "Epoch 254/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9386\n",
      "Epoch 255/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.0343 - mean_squared_error: 0.0343 - acc: 0.9356\n",
      "Epoch 256/300\n",
      "2020/2020 [==============================] - 0s 106us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9356\n",
      "Epoch 257/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.0436 - mean_squared_error: 0.0436 - acc: 0.9218\n",
      "Epoch 258/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.9079\n",
      "Epoch 259/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9337\n",
      "Epoch 260/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9545\n",
      "Epoch 261/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9416\n",
      "Epoch 262/300\n",
      "2020/2020 [==============================] - 0s 94us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9257\n",
      "Epoch 263/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9421\n",
      "Epoch 264/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9520\n",
      "Epoch 265/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9460\n",
      "Epoch 266/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9272\n",
      "Epoch 267/300\n",
      "2020/2020 [==============================] - 0s 76us/step - loss: 0.0378 - mean_squared_error: 0.0378 - acc: 0.9262\n",
      "Epoch 268/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9327\n",
      "Epoch 269/300\n",
      "2020/2020 [==============================] - 0s 82us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.9416\n",
      "Epoch 270/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9421\n",
      "Epoch 271/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9371\n",
      "Epoch 272/300\n",
      "2020/2020 [==============================] - 0s 75us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9292\n",
      "Epoch 273/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9351\n",
      "Epoch 274/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9465\n",
      "Epoch 275/300\n",
      "2020/2020 [==============================] - 0s 106us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9332\n",
      "Epoch 276/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9470\n",
      "Epoch 277/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.9460\n",
      "Epoch 278/300\n",
      "2020/2020 [==============================] - 0s 98us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9332\n",
      "Epoch 279/300\n",
      "2020/2020 [==============================] - 0s 106us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9465\n",
      "Epoch 280/300\n",
      "2020/2020 [==============================] - 0s 175us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9411\n",
      "Epoch 281/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9376\n",
      "Epoch 282/300\n",
      "2020/2020 [==============================] - 0s 104us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9470\n",
      "Epoch 283/300\n",
      "2020/2020 [==============================] - 0s 187us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9292\n",
      "Epoch 284/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.0522 - mean_squared_error: 0.0522 - acc: 0.9054\n",
      "Epoch 285/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9337\n",
      "Epoch 286/300\n",
      "2020/2020 [==============================] - 0s 112us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9371\n",
      "Epoch 287/300\n",
      "2020/2020 [==============================] - 0s 78us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9421\n",
      "Epoch 288/300\n",
      "2020/2020 [==============================] - 0s 77us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9441\n",
      "Epoch 289/300\n",
      "2020/2020 [==============================] - 0s 84us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9450\n",
      "Epoch 290/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9450\n",
      "Epoch 291/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9525\n",
      "Epoch 292/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9540\n",
      "Epoch 293/300\n",
      "2020/2020 [==============================] - 0s 80us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9505\n",
      "Epoch 294/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9416\n",
      "Epoch 295/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9386\n",
      "Epoch 296/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9401\n",
      "Epoch 297/300\n",
      "2020/2020 [==============================] - 0s 83us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9351\n",
      "Epoch 298/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9391\n",
      "Epoch 299/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.0363 - mean_squared_error: 0.0363 - acc: 0.9292\n",
      "Epoch 300/300\n",
      "2020/2020 [==============================] - 0s 104us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9297\n",
      "2526/2526 [==============================] - 1s 279us/step\n",
      "2020/2020 [==============================] - 0s 202us/step\n",
      "The Score is 0.970705\n",
      "current iteration fraction: 0.100000\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(1010, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1010/1010 [==============================] - 2s 2ms/step - loss: 0.2338 - mean_squared_error: 0.2338 - acc: 0.4178\n",
      "Epoch 2/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.1896 - mean_squared_error: 0.1896 - acc: 0.5842\n",
      "Epoch 3/300\n",
      "1010/1010 [==============================] - 0s 111us/step - loss: 0.1718 - mean_squared_error: 0.1718 - acc: 0.6386\n",
      "Epoch 4/300\n",
      "1010/1010 [==============================] - 0s 106us/step - loss: 0.1590 - mean_squared_error: 0.1590 - acc: 0.6554\n",
      "Epoch 5/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.1622 - mean_squared_error: 0.1622 - acc: 0.6703\n",
      "Epoch 6/300\n",
      "1010/1010 [==============================] - 0s 275us/step - loss: 0.1557 - mean_squared_error: 0.1557 - acc: 0.6792\n",
      "Epoch 7/300\n",
      "1010/1010 [==============================] - 1s 500us/step - loss: 0.1531 - mean_squared_error: 0.1531 - acc: 0.67030s - loss: 0.1515 - mean_squared_error: 0.1515 -\n",
      "Epoch 8/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.1518 - mean_squared_error: 0.1518 - acc: 0.6782\n",
      "Epoch 9/300\n",
      "1010/1010 [==============================] - 0s 207us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6772\n",
      "Epoch 10/300\n",
      "1010/1010 [==============================] - 1s 524us/step - loss: 0.1461 - mean_squared_error: 0.1461 - acc: 0.69500s - loss: 0.1559 - mean_squared_error: 0.1559 -\n",
      "Epoch 11/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.1482 - mean_squared_error: 0.1482 - acc: 0.6772\n",
      "Epoch 12/300\n",
      "1010/1010 [==============================] - 0s 263us/step - loss: 0.1448 - mean_squared_error: 0.1448 - acc: 0.68220s - loss: 0.1414 - mean_squared_error: 0.1414 - acc\n",
      "Epoch 13/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.1416 - mean_squared_error: 0.1416 - acc: 0.7109\n",
      "Epoch 14/300\n",
      "1010/1010 [==============================] - 0s 298us/step - loss: 0.1403 - mean_squared_error: 0.1403 - acc: 0.7069\n",
      "Epoch 15/300\n",
      "1010/1010 [==============================] - 0s 195us/step - loss: 0.1412 - mean_squared_error: 0.1412 - acc: 0.7089\n",
      "Epoch 16/300\n",
      "1010/1010 [==============================] - 0s 195us/step - loss: 0.1386 - mean_squared_error: 0.1386 - acc: 0.7129\n",
      "Epoch 17/300\n",
      "1010/1010 [==============================] - 0s 109us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.7079\n",
      "Epoch 18/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.1337 - mean_squared_error: 0.1337 - acc: 0.73 - 0s 253us/step - loss: 0.1338 - mean_squared_error: 0.1338 - acc: 0.7396\n",
      "Epoch 19/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.1326 - mean_squared_error: 0.1326 - acc: 0.7327\n",
      "Epoch 20/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.1314 - mean_squared_error: 0.1314 - acc: 0.7406\n",
      "Epoch 21/300\n",
      "1010/1010 [==============================] - 0s 314us/step - loss: 0.1372 - mean_squared_error: 0.1372 - acc: 0.7178\n",
      "Epoch 22/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.1174 - mean_squared_error: 0.1174 - acc: 0.7713\n",
      "Epoch 23/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.1232 - mean_squared_error: 0.1232 - acc: 0.7545\n",
      "Epoch 24/300\n",
      "1010/1010 [==============================] - 0s 253us/step - loss: 0.1258 - mean_squared_error: 0.1258 - acc: 0.7554\n",
      "Epoch 25/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.1245 - mean_squared_error: 0.1245 - acc: 0.7634\n",
      "Epoch 26/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.1200 - mean_squared_error: 0.1200 - acc: 0.78 - 0s 132us/step - loss: 0.1199 - mean_squared_error: 0.1199 - acc: 0.7861\n",
      "Epoch 27/300\n",
      "1010/1010 [==============================] - 0s 248us/step - loss: 0.1113 - mean_squared_error: 0.1113 - acc: 0.7851\n",
      "Epoch 28/300\n",
      "1010/1010 [==============================] - 0s 216us/step - loss: 0.1102 - mean_squared_error: 0.1102 - acc: 0.7941\n",
      "Epoch 29/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.1009 - mean_squared_error: 0.1009 - acc: 0.8168\n",
      "Epoch 30/300\n",
      "1010/1010 [==============================] - 0s 153us/step - loss: 0.1067 - mean_squared_error: 0.1067 - acc: 0.7990\n",
      "Epoch 31/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.1005 - mean_squared_error: 0.1005 - acc: 0.8188\n",
      "Epoch 32/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0974 - mean_squared_error: 0.0974 - acc: 0.8307\n",
      "Epoch 33/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.0969 - mean_squared_error: 0.0969 - acc: 0.8297\n",
      "Epoch 34/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0879 - mean_squared_error: 0.0879 - acc: 0.8545\n",
      "Epoch 35/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0922 - mean_squared_error: 0.0922 - acc: 0.8287\n",
      "Epoch 36/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0851 - mean_squared_error: 0.0851 - acc: 0.8554\n",
      "Epoch 37/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0818 - mean_squared_error: 0.0818 - acc: 0.8644\n",
      "Epoch 38/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0831 - mean_squared_error: 0.0831 - acc: 0.8545\n",
      "Epoch 39/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0867 - mean_squared_error: 0.0867 - acc: 0.8545\n",
      "Epoch 40/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0768 - mean_squared_error: 0.0768 - acc: 0.8733\n",
      "Epoch 41/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0761 - mean_squared_error: 0.0761 - acc: 0.8683\n",
      "Epoch 42/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0771 - mean_squared_error: 0.0771 - acc: 0.8733\n",
      "Epoch 43/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0689 - mean_squared_error: 0.0689 - acc: 0.8881\n",
      "Epoch 44/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0654 - mean_squared_error: 0.0654 - acc: 0.9000\n",
      "Epoch 45/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0723 - mean_squared_error: 0.0723 - acc: 0.8782\n",
      "Epoch 46/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0715 - mean_squared_error: 0.0715 - acc: 0.8832\n",
      "Epoch 47/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0574 - mean_squared_error: 0.0574 - acc: 0.9109\n",
      "Epoch 48/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0577 - mean_squared_error: 0.0577 - acc: 0.9050\n",
      "Epoch 49/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0632 - mean_squared_error: 0.0632 - acc: 0.8950\n",
      "Epoch 50/300\n",
      "1010/1010 [==============================] - 0s 104us/step - loss: 0.0551 - mean_squared_error: 0.0551 - acc: 0.9208\n",
      "Epoch 51/300\n",
      "1010/1010 [==============================] - 0s 113us/step - loss: 0.0567 - mean_squared_error: 0.0567 - acc: 0.9129\n",
      "Epoch 52/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.0600 - mean_squared_error: 0.0600 - acc: 0.9109\n",
      "Epoch 53/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0504 - mean_squared_error: 0.0504 - acc: 0.9119\n",
      "Epoch 54/300\n",
      "1010/1010 [==============================] - 0s 149us/step - loss: 0.0557 - mean_squared_error: 0.0557 - acc: 0.9089\n",
      "Epoch 55/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0643 - mean_squared_error: 0.0643 - acc: 0.8871\n",
      "Epoch 56/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0566 - mean_squared_error: 0.0566 - acc: 0.9089\n",
      "Epoch 57/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0566 - mean_squared_error: 0.0566 - acc: 0.9069\n",
      "Epoch 58/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0499 - mean_squared_error: 0.0499 - acc: 0.9149\n",
      "Epoch 59/300\n",
      "1010/1010 [==============================] - 0s 100us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9356\n",
      "Epoch 60/300\n",
      "1010/1010 [==============================] - 0s 100us/step - loss: 0.0465 - mean_squared_error: 0.0465 - acc: 0.9267\n",
      "Epoch 61/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9366\n",
      "Epoch 62/300\n",
      "1010/1010 [==============================] - 0s 114us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9406\n",
      "Epoch 63/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9257\n",
      "Epoch 64/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0495 - mean_squared_error: 0.0495 - acc: 0.9149\n",
      "Epoch 65/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9218\n",
      "Epoch 66/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.0528 - mean_squared_error: 0.0528 - acc: 0.9109\n",
      "Epoch 67/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0451 - mean_squared_error: 0.0451 - acc: 0.9356\n",
      "Epoch 68/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0523 - mean_squared_error: 0.0523 - acc: 0.9129\n",
      "Epoch 69/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.9208\n",
      "Epoch 70/300\n",
      "1010/1010 [==============================] - 0s 157us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9347\n",
      "Epoch 71/300\n",
      "1010/1010 [==============================] - 0s 111us/step - loss: 0.0490 - mean_squared_error: 0.0490 - acc: 0.9158\n",
      "Epoch 72/300\n",
      "1010/1010 [==============================] - 0s 183us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9208\n",
      "Epoch 73/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0433 - mean_squared_error: 0.0433 - acc: 0.9307\n",
      "Epoch 74/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9406\n",
      "Epoch 75/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9327\n",
      "Epoch 76/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.0457 - mean_squared_error: 0.0457 - acc: 0.9198\n",
      "Epoch 77/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9436\n",
      "Epoch 78/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.0479 - mean_squared_error: 0.0479 - acc: 0.9198\n",
      "Epoch 79/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9218\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9267\n",
      "Epoch 81/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9337\n",
      "Epoch 82/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0449 - mean_squared_error: 0.0449 - acc: 0.9238\n",
      "Epoch 83/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9178\n",
      "Epoch 84/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0598 - mean_squared_error: 0.0598 - acc: 0.9040\n",
      "Epoch 85/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9129\n",
      "Epoch 86/300\n",
      "1010/1010 [==============================] - 0s 185us/step - loss: 0.0505 - mean_squared_error: 0.0505 - acc: 0.9069\n",
      "Epoch 87/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0553 - mean_squared_error: 0.0553 - acc: 0.8921\n",
      "Epoch 88/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0501 - mean_squared_error: 0.0501 - acc: 0.9129\n",
      "Epoch 89/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9396\n",
      "Epoch 90/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0415 - mean_squared_error: 0.0415 - acc: 0.9376\n",
      "Epoch 91/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.0500 - mean_squared_error: 0.0500 - acc: 0.9109\n",
      "Epoch 92/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0502 - mean_squared_error: 0.0502 - acc: 0.9168\n",
      "Epoch 93/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.0527 - mean_squared_error: 0.0527 - acc: 0.9059\n",
      "Epoch 94/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0550 - mean_squared_error: 0.0550 - acc: 0.8960\n",
      "Epoch 95/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9208\n",
      "Epoch 96/300\n",
      "1010/1010 [==============================] - 0s 221us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9307\n",
      "Epoch 97/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9317\n",
      "Epoch 98/300\n",
      "1010/1010 [==============================] - 0s 102us/step - loss: 0.0412 - mean_squared_error: 0.0412 - acc: 0.9366\n",
      "Epoch 99/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0537 - mean_squared_error: 0.0537 - acc: 0.9050\n",
      "Epoch 100/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0453 - mean_squared_error: 0.0453 - acc: 0.9198\n",
      "Epoch 101/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9317\n",
      "Epoch 102/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9515\n",
      "Epoch 103/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9317\n",
      "Epoch 104/300\n",
      "1010/1010 [==============================] - 0s 97us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9386\n",
      "Epoch 105/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9327\n",
      "Epoch 106/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9218\n",
      "Epoch 107/300\n",
      "1010/1010 [==============================] - 0s 100us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9178\n",
      "Epoch 108/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.0553 - mean_squared_error: 0.0553 - acc: 0.9069\n",
      "Epoch 109/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.0689 - mean_squared_error: 0.0689 - acc: 0.8723\n",
      "Epoch 110/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9267\n",
      "Epoch 111/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9277\n",
      "Epoch 112/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9228\n",
      "Epoch 113/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0431 - mean_squared_error: 0.0431 - acc: 0.9307\n",
      "Epoch 114/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9426\n",
      "Epoch 115/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.0465 - mean_squared_error: 0.0465 - acc: 0.9218\n",
      "Epoch 116/300\n",
      "1010/1010 [==============================] - 0s 111us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9366\n",
      "Epoch 117/300\n",
      "1010/1010 [==============================] - 0s 97us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9455\n",
      "Epoch 118/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9218\n",
      "Epoch 119/300\n",
      "1010/1010 [==============================] - 0s 105us/step - loss: 0.0385 - mean_squared_error: 0.0385 - acc: 0.9337\n",
      "Epoch 120/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0459 - mean_squared_error: 0.0459 - acc: 0.9218\n",
      "Epoch 121/300\n",
      "1010/1010 [==============================] - 0s 105us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9515\n",
      "Epoch 122/300\n",
      "1010/1010 [==============================] - 0s 109us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9347\n",
      "Epoch 123/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9416\n",
      "Epoch 124/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9356\n",
      "Epoch 125/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9426\n",
      "Epoch 126/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.94 - 0s 105us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9495\n",
      "Epoch 127/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9436\n",
      "Epoch 128/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9149\n",
      "Epoch 129/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0474 - mean_squared_error: 0.0474 - acc: 0.9158\n",
      "Epoch 130/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0532 - mean_squared_error: 0.0532 - acc: 0.9069\n",
      "Epoch 131/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0495 - mean_squared_error: 0.0495 - acc: 0.9129\n",
      "Epoch 132/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.0534 - mean_squared_error: 0.0534 - acc: 0.9109\n",
      "Epoch 133/300\n",
      "1010/1010 [==============================] - 0s 101us/step - loss: 0.0493 - mean_squared_error: 0.0493 - acc: 0.9208\n",
      "Epoch 134/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9386\n",
      "Epoch 135/300\n",
      "1010/1010 [==============================] - 0s 80us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9347\n",
      "Epoch 136/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9554\n",
      "Epoch 137/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9337\n",
      "Epoch 138/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9376\n",
      "Epoch 139/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0432 - mean_squared_error: 0.0432 - acc: 0.9238\n",
      "Epoch 140/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9446\n",
      "Epoch 141/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9337\n",
      "Epoch 142/300\n",
      "1010/1010 [==============================] - 0s 79us/step - loss: 0.0450 - mean_squared_error: 0.0450 - acc: 0.9267\n",
      "Epoch 143/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0529 - mean_squared_error: 0.0529 - acc: 0.9109\n",
      "Epoch 144/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0553 - mean_squared_error: 0.0553 - acc: 0.9050\n",
      "Epoch 145/300\n",
      "1010/1010 [==============================] - 0s 149us/step - loss: 0.0517 - mean_squared_error: 0.0517 - acc: 0.91290s - loss: 0.0518 - mean_squared_error: 0.0518 - acc: 0.91\n",
      "Epoch 146/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.0445 - mean_squared_error: 0.0445 - acc: 0.9267\n",
      "Epoch 147/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9129\n",
      "Epoch 148/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9337\n",
      "Epoch 149/300\n",
      "1010/1010 [==============================] - 0s 97us/step - loss: 0.0481 - mean_squared_error: 0.0481 - acc: 0.9149\n",
      "Epoch 150/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0541 - mean_squared_error: 0.0541 - acc: 0.8970 0s - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.90\n",
      "Epoch 151/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9228\n",
      "Epoch 152/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.9188\n",
      "Epoch 153/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9386\n",
      "Epoch 154/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9287\n",
      "Epoch 155/300\n",
      "1010/1010 [==============================] - 0s 101us/step - loss: 0.0464 - mean_squared_error: 0.0464 - acc: 0.9198\n",
      "Epoch 156/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.0449 - mean_squared_error: 0.0449 - acc: 0.9208\n",
      "Epoch 157/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.0423 - mean_squared_error: 0.0423 - acc: 0.9307\n",
      "Epoch 158/300\n",
      "1010/1010 [==============================] - 0s 261us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.95350s - loss: 0.0349 - mean_squared_error: 0.0349 - acc: \n",
      "Epoch 159/300\n",
      "1010/1010 [==============================] - 0s 185us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9446\n",
      "Epoch 160/300\n",
      "1010/1010 [==============================] - 0s 251us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9535\n",
      "Epoch 161/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9485\n",
      "Epoch 162/300\n",
      "1010/1010 [==============================] - 0s 259us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9554\n",
      "Epoch 163/300\n",
      "1010/1010 [==============================] - 0s 197us/step - loss: 0.0381 - mean_squared_error: 0.0381 - acc: 0.9376\n",
      "Epoch 164/300\n",
      "1010/1010 [==============================] - 0s 194us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9297\n",
      "Epoch 165/300\n",
      "1010/1010 [==============================] - 0s 194us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9505\n",
      "Epoch 166/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9535\n",
      "Epoch 167/300\n",
      "1010/1010 [==============================] - 0s 158us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9604\n",
      "Epoch 168/300\n",
      "1010/1010 [==============================] - 0s 113us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9366\n",
      "Epoch 169/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9574\n",
      "Epoch 170/300\n",
      "1010/1010 [==============================] - 0s 80us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9475\n",
      "Epoch 171/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9455\n",
      "Epoch 172/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9317\n",
      "Epoch 173/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9406\n",
      "Epoch 174/300\n",
      "1010/1010 [==============================] - 0s 207us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9396\n",
      "Epoch 175/300\n",
      "1010/1010 [==============================] - 0s 395us/step - loss: 0.0438 - mean_squared_error: 0.0438 - acc: 0.9297\n",
      "Epoch 176/300\n",
      "1010/1010 [==============================] - 0s 227us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9465\n",
      "Epoch 177/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9386\n",
      "Epoch 178/300\n",
      "1010/1010 [==============================] - 0s 158us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9366\n",
      "Epoch 179/300\n",
      "1010/1010 [==============================] - 0s 232us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9406\n",
      "Epoch 180/300\n",
      "1010/1010 [==============================] - 0s 282us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9475\n",
      "Epoch 181/300\n",
      "1010/1010 [==============================] - 0s 378us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9416\n",
      "Epoch 182/300\n",
      "1010/1010 [==============================] - 0s 252us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9396\n",
      "Epoch 183/300\n",
      "1010/1010 [==============================] - 0s 188us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9386\n",
      "Epoch 184/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9416\n",
      "Epoch 185/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9455\n",
      "Epoch 186/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.0247 - mean_squared_error: 0.0247 - acc: 0.9624\n",
      "Epoch 187/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9594\n",
      "Epoch 188/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9535\n",
      "Epoch 189/300\n",
      "1010/1010 [==============================] - 0s 264us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9376\n",
      "Epoch 190/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.0418 - mean_squared_error: 0.0418 - acc: 0.9337\n",
      "Epoch 191/300\n",
      "1010/1010 [==============================] - 0s 357us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9356\n",
      "Epoch 192/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9317\n",
      "Epoch 193/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9396\n",
      "Epoch 194/300\n",
      "1010/1010 [==============================] - 0s 102us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9317\n",
      "Epoch 195/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0472 - mean_squared_error: 0.0472 - acc: 0.9257\n",
      "Epoch 196/300\n",
      "1010/1010 [==============================] - 0s 306us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9465\n",
      "Epoch 197/300\n",
      "1010/1010 [==============================] - 0s 309us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9515\n",
      "Epoch 198/300\n",
      "1010/1010 [==============================] - 0s 122us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9545\n",
      "Epoch 199/300\n",
      "1010/1010 [==============================] - 0s 150us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9505\n",
      "Epoch 200/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9485\n",
      "Epoch 201/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9545\n",
      "Epoch 202/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9465\n",
      "Epoch 203/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9436\n",
      "Epoch 204/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9228\n",
      "Epoch 205/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0436 - mean_squared_error: 0.0436 - acc: 0.9307\n",
      "Epoch 206/300\n",
      "1010/1010 [==============================] - 0s 78us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.9366\n",
      "Epoch 207/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0367 - mean_squared_error: 0.0367 - acc: 0.9376\n",
      "Epoch 208/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9248\n",
      "Epoch 209/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0489 - mean_squared_error: 0.0489 - acc: 0.9129\n",
      "Epoch 210/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9337\n",
      "Epoch 211/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.9248\n",
      "Epoch 212/300\n",
      "1010/1010 [==============================] - 0s 80us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9386\n",
      "Epoch 213/300\n",
      "1010/1010 [==============================] - 0s 160us/step - loss: 0.0422 - mean_squared_error: 0.0422 - acc: 0.9337\n",
      "Epoch 214/300\n",
      "1010/1010 [==============================] - 0s 175us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9356\n",
      "Epoch 215/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9307\n",
      "Epoch 216/300\n",
      "1010/1010 [==============================] - 0s 232us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9396\n",
      "Epoch 217/300\n",
      "1010/1010 [==============================] - 0s 195us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9366\n",
      "Epoch 218/300\n",
      "1010/1010 [==============================] - 0s 112us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9406\n",
      "Epoch 219/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9416\n",
      "Epoch 220/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0328 - mean_squared_error: 0.0328 - acc: 0.9515\n",
      "Epoch 221/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0372 - mean_squared_error: 0.0372 - acc: 0.9376\n",
      "Epoch 222/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.0492 - mean_squared_error: 0.0492 - acc: 0.9198\n",
      "Epoch 223/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0394 - mean_squared_error: 0.0394 - acc: 0.9356\n",
      "Epoch 224/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.9396\n",
      "Epoch 225/300\n",
      "1010/1010 [==============================] - 0s 104us/step - loss: 0.0484 - mean_squared_error: 0.0484 - acc: 0.9198\n",
      "Epoch 226/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9248\n",
      "Epoch 227/300\n",
      "1010/1010 [==============================] - 0s 88us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.9465\n",
      "Epoch 228/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9495\n",
      "Epoch 229/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9386\n",
      "Epoch 230/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9297\n",
      "Epoch 231/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9475\n",
      "Epoch 232/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9366\n",
      "Epoch 233/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9436\n",
      "Epoch 234/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9505\n",
      "Epoch 235/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0406 - mean_squared_error: 0.0406 - acc: 0.9356\n",
      "Epoch 236/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.9287\n",
      "Epoch 237/300\n",
      "1010/1010 [==============================] - 0s 118us/step - loss: 0.0397 - mean_squared_error: 0.0397 - acc: 0.9317\n",
      "Epoch 238/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0409 - mean_squared_error: 0.0409 - acc: 0.9327\n",
      "Epoch 239/300\n",
      "1010/1010 [==============================] - 0s 181us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9317\n",
      "Epoch 240/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9327\n",
      "Epoch 241/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9475\n",
      "Epoch 242/300\n",
      "1010/1010 [==============================] - 0s 187us/step - loss: 0.0483 - mean_squared_error: 0.0483 - acc: 0.9059\n",
      "Epoch 243/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0544 - mean_squared_error: 0.0544 - acc: 0.9010\n",
      "Epoch 244/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.0570 - mean_squared_error: 0.0570 - acc: 0.9099\n",
      "Epoch 245/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.0577 - mean_squared_error: 0.0577 - acc: 0.9069\n",
      "Epoch 246/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.0413 - mean_squared_error: 0.0413 - acc: 0.9327\n",
      "Epoch 247/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9406\n",
      "Epoch 248/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.0382 - mean_squared_error: 0.0382 - acc: 0.9426\n",
      "Epoch 249/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.0448 - mean_squared_error: 0.0448 - acc: 0.9248\n",
      "Epoch 250/300\n",
      "1010/1010 [==============================] - 0s 204us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.9277\n",
      "Epoch 251/300\n",
      "1010/1010 [==============================] - 0s 149us/step - loss: 0.0525 - mean_squared_error: 0.0525 - acc: 0.9129\n",
      "Epoch 252/300\n",
      "1010/1010 [==============================] - 0s 175us/step - loss: 0.0461 - mean_squared_error: 0.0461 - acc: 0.9218\n",
      "Epoch 253/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9406\n",
      "Epoch 254/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9485\n",
      "Epoch 255/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9337\n",
      "Epoch 256/300\n",
      "1010/1010 [==============================] - 0s 121us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9386\n",
      "Epoch 257/300\n",
      "1010/1010 [==============================] - 0s 116us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9446\n",
      "Epoch 258/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.0435 - mean_squared_error: 0.0435 - acc: 0.9297\n",
      "Epoch 259/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0458 - mean_squared_error: 0.0458 - acc: 0.9248\n",
      "Epoch 260/300\n",
      "1010/1010 [==============================] - 0s 100us/step - loss: 0.0693 - mean_squared_error: 0.0693 - acc: 0.8743\n",
      "Epoch 261/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0626 - mean_squared_error: 0.0626 - acc: 0.8891\n",
      "Epoch 262/300\n",
      "1010/1010 [==============================] - 0s 124us/step - loss: 0.0542 - mean_squared_error: 0.0542 - acc: 0.9030\n",
      "Epoch 263/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9257\n",
      "Epoch 264/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.0518 - mean_squared_error: 0.0518 - acc: 0.9168\n",
      "Epoch 265/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.0490 - mean_squared_error: 0.0490 - acc: 0.9149\n",
      "Epoch 266/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.92 - 0s 99us/step - loss: 0.0483 - mean_squared_error: 0.0483 - acc: 0.9129\n",
      "Epoch 267/300\n",
      "1010/1010 [==============================] - 0s 105us/step - loss: 0.0685 - mean_squared_error: 0.0685 - acc: 0.8723\n",
      "Epoch 268/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.0482 - mean_squared_error: 0.0482 - acc: 0.9257\n",
      "Epoch 269/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9436\n",
      "Epoch 270/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9287\n",
      "Epoch 271/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.0469 - mean_squared_error: 0.0469 - acc: 0.9248\n",
      "Epoch 272/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.0429 - mean_squared_error: 0.0429 - acc: 0.9287\n",
      "Epoch 273/300\n",
      "1010/1010 [==============================] - 0s 363us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9307\n",
      "Epoch 274/300\n",
      "1010/1010 [==============================] - 0s 359us/step - loss: 0.0424 - mean_squared_error: 0.0424 - acc: 0.93370s - loss: 0.0507 - mean_squared_error: 0.0507 - acc\n",
      "Epoch 275/300\n",
      "1010/1010 [==============================] - 0s 126us/step - loss: 0.0425 - mean_squared_error: 0.0425 - acc: 0.9317\n",
      "Epoch 276/300\n",
      "1010/1010 [==============================] - 0s 122us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9396\n",
      "Epoch 277/300\n",
      "1010/1010 [==============================] - 0s 202us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9485\n",
      "Epoch 278/300\n",
      "1010/1010 [==============================] - 0s 292us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9535\n",
      "Epoch 279/300\n",
      "1010/1010 [==============================] - 0s 110us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9515\n",
      "Epoch 280/300\n",
      "1010/1010 [==============================] - 0s 246us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9386\n",
      "Epoch 281/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.95 - 0s 118us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9554\n",
      "Epoch 282/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9386\n",
      "Epoch 283/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9317\n",
      "Epoch 284/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.0488 - mean_squared_error: 0.0488 - acc: 0.9228\n",
      "Epoch 285/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0467 - mean_squared_error: 0.0467 - acc: 0.9238\n",
      "Epoch 286/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.9386\n",
      "Epoch 287/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.0390 - mean_squared_error: 0.0390 - acc: 0.9386\n",
      "Epoch 288/300\n",
      "1010/1010 [==============================] - 0s 84us/step - loss: 0.0357 - mean_squared_error: 0.0357 - acc: 0.9406\n",
      "Epoch 289/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9426\n",
      "Epoch 290/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0344 - mean_squared_error: 0.0344 - acc: 0.9416\n",
      "Epoch 291/300\n",
      "1010/1010 [==============================] - 0s 82us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9475\n",
      "Epoch 292/300\n",
      "1010/1010 [==============================] - 0s 81us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9475\n",
      "Epoch 293/300\n",
      "1010/1010 [==============================] - 0s 77us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9406\n",
      "Epoch 294/300\n",
      "1010/1010 [==============================] - 0s 80us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9465\n",
      "Epoch 295/300\n",
      "1010/1010 [==============================] - 0s 97us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9228\n",
      "Epoch 296/300\n",
      "1010/1010 [==============================] - 0s 86us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9337\n",
      "Epoch 297/300\n",
      "1010/1010 [==============================] - 0s 83us/step - loss: 0.0386 - mean_squared_error: 0.0386 - acc: 0.9396\n",
      "Epoch 298/300\n",
      "1010/1010 [==============================] - 0s 80us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9485\n",
      "Epoch 299/300\n",
      "1010/1010 [==============================] - 0s 85us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9396\n",
      "Epoch 300/300\n",
      "1010/1010 [==============================] - 0s 87us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9495\n",
      "2526/2526 [==============================] - 0s 112us/step\n",
      "1010/1010 [==============================] - 0s 37us/step\n",
      "The Score is 0.975059\n",
      "[(8083, 0.9726840855106889, 301.8158383369446, 0.12726473808288574, 0.9745144129654831), (7072, 0.9794140930979949, 247.66043829917908, 0.20711755752563477, 0.9806278280542986), (6062, 0.9754552649111381, 213.85423874855042, 0.2265772819519043, 0.9747608050148466), (5052, 0.9829770387965162, 136.09217524528503, 0.23057317733764648, 0.9815914489311164), (4041, 0.9667458429472463, 111.50835919380188, 0.2385573387145996, 0.9685721356099976), (3031, 0.9790182106096595, 81.87540793418884, 0.24554181098937988, 0.975915539425932), (2020, 0.9707046710869102, 62.18049383163452, 0.7081844806671143, 0.9792079207920792), (1010, 0.9750593820924525, 43.550599575042725, 0.29744648933410645, 0.9792079203199632)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsPCAKMeans.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 3)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetPCAK_Means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation Maximizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "pca = PCA(n_components = 2) #set based on variance ratio\n",
    "pca.fit(X_inputs)\n",
    "X_inputs = pca.transform(X_inputs)\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X_inputs)\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 3s 336us/step - loss: 0.1738 - mean_squared_error: 0.1738 - acc: 0.6114\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.1515 - mean_squared_error: 0.1515 - acc: 0.6641\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.1322 - mean_squared_error: 0.1322 - acc: 0.7261\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.1082 - mean_squared_error: 0.1082 - acc: 0.80500s - loss: 0.1085 - mean_squared_error: 0.1085 - acc: 0.\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.0907 - mean_squared_error: 0.0907 - acc: 0.8428\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0740 - mean_squared_error: 0.0740 - acc: 0.8764\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.0771 - mean_squared_error: 0.0771 - acc: 0.8627\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0526 - mean_squared_error: 0.0526 - acc: 0.9110\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0497 - mean_squared_error: 0.0497 - acc: 0.91460s - loss: 0.0496 - mean_squared_error: 0.0496 - acc: 0.91\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0456 - acc: 0.92 - 1s 156us/step - loss: 0.0455 - mean_squared_error: 0.0455 - acc: 0.9223\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.0376 - mean_squared_error: 0.0376 - acc: 0.93851s - loss:\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0398 - mean_squared_error: 0.0398 - acc: 0.9339\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.94370s - loss: 0.0332 - mean_s\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9509\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.94060s - loss: 0.0312 - mean_squ\n",
      "2526/2526 [==============================] - 1s 263us/step\n",
      "8083/8083 [==============================] - 1s 73us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.9312\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9437\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9527\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9452\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9509\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0317 - mean_squared_error: 0.0317 - acc: 0.9446\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9529\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0249 - mean_squared_error: 0.0249 - acc: 0.9586\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0223 - mean_squared_error: 0.0223 - acc: 0.9624\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.93950s - loss: 0.0254 - mean_squared_error: 0.0254 - acc - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0273 -\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9493\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9443\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.9399\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0292 - mean_squared_error: 0.0292 - acc: 0.9478\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9530\n",
      "2526/2526 [==============================] - 0s 49us/step\n",
      "8083/8083 [==============================] - 1s 70us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.95010s - loss: 0.0293 - mean_squared_error: \n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 230us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9555\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 275us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.93780s - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0. - ETA: 0s - loss: 0.0357 - mean_squared_error\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 252us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9454\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 2s 214us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9459\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9302\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0401 - mean_squared_error: 0.0401 - acc: 0.9260\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9483\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9419\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9500\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9514\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9541\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9478\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9529\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9472\n",
      "2526/2526 [==============================] - 0s 99us/step\n",
      "8083/8083 [==============================] - 1s 75us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0421 - mean_squared_error: 0.0421 - acc: 0.9259\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9479\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9493\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9410\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9613\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9563\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9602\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0217 - mean_squared_error: 0.0217 - acc: 0.9619 0s - loss: 0.0217 - mean_squared_error: 0.0217 - acc: 0.96\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0329 - mean_squared_error: 0.0329 - acc: 0.9411\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9388\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9546\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9599\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9624\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9647\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9489\n",
      "2526/2526 [==============================] - 0s 48us/step\n",
      "8083/8083 [==============================] - 0s 50us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9586\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9650\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0216 - mean_squared_error: 0.0216 - acc: 0.9646\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9411\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9516\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9613\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0220 - mean_squared_error: 0.0220 - acc: 0.9616\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9365\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9445\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9563\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9555\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9175\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.94170s - loss: 0.0311 - mean_squared_error\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0318 - mean_squared_error: 0.0318 - acc: 0.9449\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9527\n",
      "2526/2526 [==============================] - 0s 58us/step\n",
      "8083/8083 [==============================] - 0s 56us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.95300s - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9610\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.96120s - loss: 0.0207 - mean_s\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9498\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9493\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0434 - mean_squared_error: 0.0434 - acc: 0.9162\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.0410 - mean_squared_error: 0.0410 - acc: 0.9266\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9417\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9446\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0256 - mean_squared_error: 0.0256 - acc: 0.9571\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.94520s - loss: 0.0314 - mean_squared_error: 0.0314 - acc\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9469\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9494\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0226 - mean_squared_error: 0.0226 - acc: 0.9625\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9581 0s - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.\n",
      "2526/2526 [==============================] - 0s 48us/step\n",
      "8083/8083 [==============================] - 0s 50us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0373 - mean_squared_error: 0.0373 - acc: 0.9286\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9406\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0395 - mean_squared_error: 0.0395 - acc: 0.9268\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.93170s - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0319 - mean_squared_error: 0.0319 - acc: 0.9393\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 183us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9524\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0256 - mean_squared_error: 0.0256 - acc: 0.9555\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9563\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9589\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0205 - mean_squared_error: 0.0205 - acc: 0.96310s - loss: 0.0181 - mean_squared_err\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0225 - mean_squared_error: 0.0225 - acc: 0.9603\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9537\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9488\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9567\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9506\n",
      "2526/2526 [==============================] - 0s 52us/step\n",
      "8083/8083 [==============================] - 0s 50us/step\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.0202 - mean_squared_error: 0.0202 - acc: 0.9654\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9386\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0439 - mean_squared_error: 0.0439 - acc: 0.9223\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0258 - mean_squared_error: 0.0258 - acc: 0.9553\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9521\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9579\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0223 - mean_squared_error: 0.0223 - acc: 0.9621\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9635\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9613\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0220 - mean_squared_error: 0.0220 - acc: 0.9620\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9574\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9555\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9466\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9529\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9597\n",
      "2526/2526 [==============================] - 0s 74us/step\n",
      "8083/8083 [==============================] - 1s 65us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0224 - mean_squared_error: 0.0224 - acc: 0.9609\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0230 - mean_squared_error: 0.0230 - acc: 0.9608\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0202 - mean_squared_error: 0.0202 - acc: 0.9651\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9661\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9618\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9589\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9468\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9529\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9583\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9660\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0209 - mean_squared_error: 0.0209 - acc: 0.9639\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0173 - mean_squared_error: 0.0173 - acc: 0.9701\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9589\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9592\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0249 - mean_squared_error: 0.0249 - acc: 0.95661s - loss: 0.0249 - mean_squ\n",
      "2526/2526 [==============================] - 0s 72us/step\n",
      "8083/8083 [==============================] - 0s 54us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9604\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9473\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9595\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9537\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9652\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0408 - mean_squared_error: 0.0408 - acc: 0.9233\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9579 0s - loss: 0.0283 - mean_squared_error\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0166 - mean_squared_error: 0.0166 - acc: 0.9717\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0178 - mean_squared_error: 0.0178 - acc: 0.9712\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0177 - mean_squared_error: 0.0177 - acc: 0.9707\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9594\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9579\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0299 - mean_squared_error: 0.0299 - acc: 0.9437\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9504\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9526\n",
      "2526/2526 [==============================] - 0s 47us/step\n",
      "8083/8083 [==============================] - 0s 44us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9499\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0224 - mean_squared_error: 0.0224 - acc: 0.9610\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9628\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9639\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0220 - mean_squared_error: 0.0220 - acc: 0.9613\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9621\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0199 - mean_squared_error: 0.0199 - acc: 0.9666\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9665\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9663\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0200 - mean_squared_error: 0.0200 - acc: 0.9668\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0178 - mean_squared_error: 0.0178 - acc: 0.9702\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0172 - mean_squared_error: 0.0172 - acc: 0.9709\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9530\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0212 - mean_squared_error: 0.0212 - acc: 0.9645\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0167 - mean_squared_error: 0.0167 - acc: 0.9724\n",
      "2526/2526 [==============================] - 0s 47us/step\n",
      "8083/8083 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.9624\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9677\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9665\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9478\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0489 - mean_squared_error: 0.0489 - acc: 0.9080\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9355\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9537\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9553\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9547\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9490\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9586\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9598\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9618\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0199 - mean_squared_error: 0.0199 - acc: 0.9677\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0216 - mean_squared_error: 0.0216 - acc: 0.9635\n",
      "2526/2526 [==============================] - 0s 48us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9550\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0239 - mean_squared_error: 0.0239 - acc: 0.9571\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 206us/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.96131s -\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0183 - mean_squared_error: 0.0183 - acc: 0.9697\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0190 - mean_squared_error: 0.0190 - acc: 0.9686\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0147 - mean_squared_error: 0.0147 - acc: 0.9759\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0196 - mean_squared_error: 0.0196 - acc: 0.9670\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.0196 - mean_squared_error: 0.0196 - acc: 0.9672\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0163 - mean_squared_error: 0.0163 - acc: 0.9727\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9557\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9490\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.0404 - mean_squared_error: 0.0404 - acc: 0.9252\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9485\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9532\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.95360s - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.\n",
      "2526/2526 [==============================] - 0s 57us/step\n",
      "8083/8083 [==============================] - 0s 55us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.0193 - mean_squared_error: 0.0193 - acc: 0.9670\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9358\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.9626\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9634\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0195 - mean_squared_error: 0.0195 - acc: 0.9677\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.0185 - mean_squared_error: 0.0185 - acc: 0.9686\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0183 - mean_squared_error: 0.0183 - acc: 0.9685\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9461\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9484\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.95460s - loss: 0.0253 - mean_squared_error: \n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9662\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0196 - mean_squared_error: 0.0196 - acc: 0.9659\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0234 - mean_squared_error: 0.0234 - acc: 0.9608\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0187 - mean_squared_error: 0.0187 - acc: 0.9697\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9635\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "8083/8083 [==============================] - 1s 124us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9550\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9626\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9638\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9631\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9427\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0194 - mean_squared_error: 0.0194 - acc: 0.9682\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9636\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9602\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9573\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0230 - mean_squared_error: 0.0230 - acc: 0.9624\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9498\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9547\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.0234 - mean_squared_error: 0.0234 - acc: 0.9607\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0195 - mean_squared_error: 0.0195 - acc: 0.9671\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9657\n",
      "2526/2526 [==============================] - 0s 78us/step\n",
      "8083/8083 [==============================] - 1s 121us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0186 - mean_squared_error: 0.0186 - acc: 0.9681\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0187 - mean_squared_error: 0.0187 - acc: 0.9691\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.9603\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9589\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9609\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0200 - mean_squared_error: 0.0200 - acc: 0.96650s - loss: 0.0216 - mean\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9608\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9513\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0341 - mean_squared_error: 0.0341 - acc: 0.9390\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0286 - mean_squared_error: 0.0286 - acc: 0.9506\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0181 - mean_squared_error: 0.0181 - acc: 0.9703\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0182 - mean_squared_error: 0.0182 - acc: 0.9702\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0163 - mean_squared_error: 0.0163 - acc: 0.9728\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0167 - mean_squared_error: 0.0167 - acc: 0.9720\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0164 - mean_squared_error: 0.0164 - acc: 0.9725\n",
      "2526/2526 [==============================] - 0s 50us/step\n",
      "8083/8083 [==============================] - 0s 51us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0203 - mean_squared_error: 0.0203 - acc: 0.9650\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0190 - mean_squared_error: 0.0190 - acc: 0.9678\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0152 - mean_squared_error: 0.0152 - acc: 0.9753\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 201us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9394\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9548\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 3s 360us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.94790s - loss: 0.0301 - mean_squared_error\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9568\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0224 - mean_squared_error: 0.0224 - acc: 0.9607\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9635\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0204 - mean_squared_error: 0.0204 - acc: 0.9656\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9650\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 3s 311us/step - loss: 0.0223 - mean_squared_error: 0.0223 - acc: 0.9621\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.96151s - loss: 0.020\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0215 - mean_squared_error: 0.0215 - acc: 0.9630\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9615\n",
      "2526/2526 [==============================] - 0s 52us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9673\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 227us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9589\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0192 - mean_squared_error: 0.0192 - acc: 0.9685\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.9662\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 3s 317us/step - loss: 0.0195 - mean_squared_error: 0.0195 - acc: 0.9678\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 261us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9555\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9483 ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0303 - acc:  - 1s 108us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9495\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9588\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9602\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 221us/step - loss: 0.0182 - mean_squared_error: 0.0182 - acc: 0.97061s\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.0170 - mean_squared_error: 0.0170 - acc: 0.9712\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 283us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9628\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9572\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0204 - mean_squared_error: 0.0204 - acc: 0.9670\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.0179 - mean_squared_error: 0.0179 - acc: 0.9715\n",
      "2526/2526 [==============================] - 0s 46us/step\n",
      "8083/8083 [==============================] - 1s 83us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.0150 - mean_squared_error: 0.0150 - acc: 0.97590s - loss: 0.0151 - mean_squared_error\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.0154 - mean_squared_error: 0.0154 - acc: 0.9750\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0162 - mean_squared_error: 0.0162 - acc: 0.9730\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0179 - mean_squared_error: 0.0179 - acc: 0.9707\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0153 - mean_squared_error: 0.0153 - acc: 0.9751\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.0152 - mean_squared_error: 0.0152 - acc: 0.9744\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0156 - mean_squared_error: 0.0156 - acc: 0.9744\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.0165 - mean_squared_error: 0.0165 - acc: 0.9724\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 0.0166 - mean_squared_error: 0.0166 - acc: 0.9727\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9479\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.9582\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0206 - mean_squared_error: 0.0206 - acc: 0.9636\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9592\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0239 - mean_squared_error: 0.0239 - acc: 0.9597\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0234 - mean_squared_error: 0.0234 - acc: 0.9613\n",
      "2526/2526 [==============================] - 0s 53us/step\n",
      "8083/8083 [==============================] - 0s 54us/step\n",
      "2526/2526 [==============================] - 0s 53us/step\n",
      "8083/8083 [==============================] - 0s 47us/step\n",
      "The Score is 0.987728\n",
      "current iteration fraction: 0.700000\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 2s 307us/step - loss: 0.1776 - mean_squared_error: 0.1776 - acc: 0.6195\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1550 - mean_squared_error: 0.1550 - acc: 0.6622\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1436 - mean_squared_error: 0.1436 - acc: 0.6859\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1319 - mean_squared_error: 0.1319 - acc: 0.7190\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.1143 - mean_squared_error: 0.1143 - acc: 0.7815\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.0932 - acc: 0.83 - 1s 133us/step - loss: 0.0930 - mean_squared_error: 0.0930 - acc: 0.8392\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.0784 - mean_squared_error: 0.0784 - acc: 0.8693\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0704 - mean_squared_error: 0.0704 - acc: 0.8808\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0582 - mean_squared_error: 0.0582 - acc: 0.9057\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0559 - mean_squared_error: 0.0559 - acc: 0.9067\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0514 - mean_squared_error: 0.0514 - acc: 0.9132\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0474 - mean_squared_error: 0.0474 - acc: 0.9173\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0463 - mean_squared_error: 0.0463 - acc: 0.9207\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 200us/step - loss: 0.0502 - mean_squared_error: 0.0502 - acc: 0.9116\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0366 - mean_squared_error: 0.0366 - acc: 0.9388\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9487\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 1s 167us/step - loss: 0.0399 - mean_squared_error: 0.0399 - acc: 0.9300\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9354\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0426 - mean_squared_error: 0.0426 - acc: 0.9249\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0359 - mean_squared_error: 0.0359 - acc: 0.9368\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0364 - mean_squared_error: 0.0364 - acc: 0.9367\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9478\n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.0512 - mean_squared_error: 0.0512 - acc: 0.9087\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0428 - mean_squared_error: 0.0428 - acc: 0.9195\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0355 - mean_squared_error: 0.0355 - acc: 0.9338\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9362\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9432\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.9341\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0310 - mean_squared_error: 0.0310 - acc: 0.9437\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9297\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.9402\n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.93410s - loss: 0.0360 - mean_squared_error: 0.0360 - acc: 0.93\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9395\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9553\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9557\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.93570s - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.93\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 160us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9408\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9478\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9490\n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9375\n",
      "Epoch 41/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.92620s - loss: 0.0458 - mean_squared_error\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9422\n",
      "Epoch 43/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0277 - mean_squared_error: 0.0277 - acc: 0.9484\n",
      "Epoch 44/300\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9519\n",
      "Epoch 45/300\n",
      "7072/7072 [==============================] - 1s 154us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9531\n",
      "Epoch 46/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9487\n",
      "Epoch 47/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9525\n",
      "Epoch 48/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.94750s - loss: 0.0269 - mean_squared_error: 0.0269 - acc\n",
      "Epoch 49/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9188\n",
      "Epoch 50/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.0480 - mean_squared_error: 0.0480 - acc: 0.9094\n",
      "Epoch 51/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9328\n",
      "Epoch 52/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.93330s - loss: 0.0343 - mean_squared_error: 0.0343 - acc\n",
      "Epoch 53/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9381\n",
      "Epoch 54/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9504\n",
      "Epoch 55/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0331 - mean_squared_error: 0.0331 - acc: 0.9403\n",
      "Epoch 56/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0403 - mean_squared_error: 0.0403 - acc: 0.9236\n",
      "Epoch 57/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.0335 - mean_squared_error: 0.0335 - acc: 0.9396\n",
      "Epoch 58/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9603\n",
      "Epoch 59/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.95490s - loss: 0.0254 - mean_squared_error: 0.0254 - acc\n",
      "Epoch 60/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9549\n",
      "Epoch 61/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9463\n",
      "Epoch 62/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9488\n",
      "Epoch 63/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0247 - mean_squared_error: 0.0247 - acc: 0.9567\n",
      "Epoch 64/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9574\n",
      "Epoch 65/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9540\n",
      "Epoch 66/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0304 - mean_squared_error: 0.0304 - acc: 0.9446\n",
      "Epoch 67/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9453\n",
      "Epoch 68/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9505\n",
      "Epoch 69/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9392\n",
      "Epoch 70/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9347\n",
      "Epoch 71/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9316\n",
      "Epoch 72/300\n",
      "7072/7072 [==============================] - 1s 158us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9364\n",
      "Epoch 73/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9555\n",
      "Epoch 74/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9497\n",
      "Epoch 75/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9498\n",
      "Epoch 76/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9485\n",
      "Epoch 77/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9454\n",
      "Epoch 78/300\n",
      "7072/7072 [==============================] - 1s 156us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9573\n",
      "Epoch 79/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0402 - mean_squared_error: 0.0402 - acc: 0.9269\n",
      "Epoch 80/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9364\n",
      "Epoch 81/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0300 - mean_squared_error: 0.0300 - acc: 0.9487\n",
      "Epoch 82/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9484\n",
      "Epoch 83/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9335\n",
      "Epoch 84/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9453\n",
      "Epoch 85/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9512\n",
      "Epoch 86/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.9499\n",
      "Epoch 87/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9458\n",
      "Epoch 88/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9559\n",
      "Epoch 89/300\n",
      "7072/7072 [==============================] - 1s 158us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.95380s - loss: 0.0245 - mean_squared_e\n",
      "Epoch 90/300\n",
      "7072/7072 [==============================] - 1s 207us/step - loss: 0.0305 - mean_squared_error: 0.0305 - acc: 0.9433\n",
      "Epoch 91/300\n",
      "7072/7072 [==============================] - 1s 192us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9494\n",
      "Epoch 92/300\n",
      "7072/7072 [==============================] - 1s 188us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9597\n",
      "Epoch 93/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0235 - mean_squared_error: 0.0235 - acc: 0.9611\n",
      "Epoch 94/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9600\n",
      "Epoch 95/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9608\n",
      "Epoch 96/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0229 - mean_squared_error: 0.0229 - acc: 0.9614\n",
      "Epoch 97/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.95 - 1s 126us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9583\n",
      "Epoch 98/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0296 - mean_squared_error: 0.0296 - acc: 0.9487\n",
      "Epoch 99/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9501\n",
      "Epoch 100/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9567\n",
      "Epoch 101/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0490 - mean_squared_error: 0.0490 - acc: 0.90411s - loss: 0.0592 - mean_squared_err\n",
      "Epoch 102/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9413\n",
      "Epoch 103/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9386\n",
      "Epoch 104/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9484\n",
      "Epoch 105/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.0326 - mean_squared_error: 0.0326 - acc: 0.9430\n",
      "Epoch 106/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0332 - mean_squared_error: 0.0332 - acc: 0.93810s - loss: 0.0345 - mean_squared_error: 0.03\n",
      "Epoch 107/300\n",
      "7072/7072 [==============================] - 1s 154us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9577\n",
      "Epoch 108/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9522\n",
      "Epoch 109/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/300\n",
      "7072/7072 [==============================] - 2s 227us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.95671s - loss: 0.0208 - mean_s\n",
      "Epoch 111/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9514\n",
      "Epoch 112/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9465\n",
      "Epoch 113/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9572\n",
      "Epoch 114/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.9576\n",
      "Epoch 115/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.0204 - mean_squared_error: 0.0204 - acc: 0.9662\n",
      "Epoch 116/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.0346 - mean_squared_error: 0.0346 - acc: 0.93650s - loss: 0.0312 - mean_squared_error: 0.03\n",
      "Epoch 117/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9533\n",
      "Epoch 118/300\n",
      "7072/7072 [==============================] - 1s 169us/step - loss: 0.0255 - mean_squared_error: 0.0255 - acc: 0.9572\n",
      "Epoch 119/300\n",
      "7072/7072 [==============================] - 1s 204us/step - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.9511\n",
      "Epoch 120/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9540\n",
      "Epoch 121/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9492\n",
      "Epoch 122/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9555\n",
      "Epoch 123/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9458\n",
      "Epoch 124/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0457 - mean_squared_error: 0.0457 - acc: 0.9153\n",
      "Epoch 125/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0411 - mean_squared_error: 0.0411 - acc: 0.9249\n",
      "Epoch 126/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9383\n",
      "Epoch 127/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9569\n",
      "Epoch 128/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9577\n",
      "Epoch 129/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9567\n",
      "Epoch 130/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9473\n",
      "Epoch 131/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9572\n",
      "Epoch 132/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9509\n",
      "Epoch 133/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9590 0s - loss: 0.0249 - mean_squared_error: 0.0249 - acc: \n",
      "Epoch 134/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9572\n",
      "Epoch 135/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.9648\n",
      "Epoch 136/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9539\n",
      "Epoch 137/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0498 - mean_squared_error: 0.0498 - acc: 0.9050\n",
      "Epoch 138/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9443\n",
      "Epoch 139/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9594\n",
      "Epoch 140/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9584\n",
      "Epoch 141/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9514\n",
      "Epoch 142/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0314 - mean_squared_error: 0.0314 - acc: 0.9450\n",
      "Epoch 143/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9576\n",
      "Epoch 144/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9601\n",
      "Epoch 145/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9580\n",
      "Epoch 146/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9605\n",
      "Epoch 147/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9655\n",
      "Epoch 148/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0191 - mean_squared_error: 0.0191 - acc: 0.9692\n",
      "Epoch 149/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9596\n",
      "Epoch 150/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.0339 - mean_squared_error: 0.0339 - acc: 0.9409\n",
      "Epoch 151/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9624\n",
      "Epoch 152/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.9641\n",
      "Epoch 153/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9560\n",
      "Epoch 154/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0223 - mean_squared_error: 0.0223 - acc: 0.9642\n",
      "Epoch 155/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.9624\n",
      "Epoch 156/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0197 - mean_squared_error: 0.0197 - acc: 0.9685\n",
      "Epoch 157/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9533\n",
      "Epoch 158/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0349 - mean_squared_error: 0.0349 - acc: 0.9388\n",
      "Epoch 159/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0279 - mean_squared_error: 0.0279 - acc: 0.9519\n",
      "Epoch 160/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9573\n",
      "Epoch 161/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9579\n",
      "Epoch 162/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9468\n",
      "Epoch 163/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9545\n",
      "Epoch 164/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0375 - mean_squared_error: 0.0375 - acc: 0.9303\n",
      "Epoch 165/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9485\n",
      "Epoch 166/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0227 - mean_squared_error: 0.0227 - acc: 0.9618\n",
      "Epoch 167/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.9590\n",
      "Epoch 168/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.9563\n",
      "Epoch 169/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9439\n",
      "Epoch 170/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9549\n",
      "Epoch 171/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9529\n",
      "Epoch 172/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9683\n",
      "Epoch 173/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.9627\n",
      "Epoch 174/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0244 - mean_squared_error: 0.0244 - acc: 0.9601\n",
      "Epoch 175/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0239 - mean_squared_error: 0.0239 - acc: 0.9603\n",
      "Epoch 176/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.9618\n",
      "Epoch 177/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9639\n",
      "Epoch 178/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9437\n",
      "Epoch 179/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0389 - mean_squared_error: 0.0389 - acc: 0.9310\n",
      "Epoch 180/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9529 0s - loss: 0.0298 - mean_squared_error: 0.0298 - a\n",
      "Epoch 181/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9600\n",
      "Epoch 182/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9573\n",
      "Epoch 183/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0290 - mean_squared_error: 0.0290 - acc: 0.9518\n",
      "Epoch 184/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9533\n",
      "Epoch 185/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.0230 - mean_squared_error: 0.0230 - acc: 0.9605\n",
      "Epoch 186/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9598\n",
      "Epoch 187/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9584\n",
      "Epoch 188/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.9625\n",
      "Epoch 189/300\n",
      "7072/7072 [==============================] - 1s 154us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.96040s - loss: 0.0211 - mean_squared_err\n",
      "Epoch 190/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0309 - mean_squared_error: 0.0309 - acc: 0.9490\n",
      "Epoch 191/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0197 - mean_squared_error: 0.0197 - acc: 0.9675\n",
      "Epoch 192/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9542\n",
      "Epoch 193/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9632\n",
      "Epoch 194/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0226 - mean_squared_error: 0.0226 - acc: 0.9627\n",
      "Epoch 195/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.0191 - mean_squared_error: 0.0191 - acc: 0.9697\n",
      "Epoch 196/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0220 - mean_squared_error: 0.0220 - acc: 0.9639\n",
      "Epoch 197/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.9618\n",
      "Epoch 198/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9591\n",
      "Epoch 199/300\n",
      "7072/7072 [==============================] - 2s 226us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9645\n",
      "Epoch 200/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0266 - mean_squared_error: 0.0266 - acc: 0.9553\n",
      "Epoch 201/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.0240 - mean_squared_error: 0.0240 - acc: 0.9590\n",
      "Epoch 202/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0214 - mean_squared_error: 0.0214 - acc: 0.9621\n",
      "Epoch 203/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0194 - mean_squared_error: 0.0194 - acc: 0.96760s - loss: 0.0194 - mean_squared_error: 0.0194 - acc\n",
      "Epoch 204/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9634\n",
      "Epoch 205/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0229 - mean_squared_error: 0.0229 - acc: 0.96320s - loss: 0.0219 - mean_squared_error: 0.02\n",
      "Epoch 206/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.0189 - mean_squared_error: 0.0189 - acc: 0.9692\n",
      "Epoch 207/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.0205 - mean_squared_error: 0.0205 - acc: 0.9656\n",
      "Epoch 208/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.0194 - mean_squared_error: 0.0194 - acc: 0.9659\n",
      "Epoch 209/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9672 ETA: 0s - loss: 0.0142 - mean_squ\n",
      "Epoch 210/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0192 - mean_squared_error: 0.0192 - acc: 0.9659\n",
      "Epoch 211/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9432\n",
      "Epoch 212/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9499\n",
      "Epoch 213/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.9607\n",
      "Epoch 214/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9564\n",
      "Epoch 215/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9422\n",
      "Epoch 216/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9163\n",
      "Epoch 217/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9509\n",
      "Epoch 218/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0229 - mean_squared_error: 0.0229 - acc: 0.9610\n",
      "Epoch 219/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9645\n",
      "Epoch 220/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.0181 - mean_squared_error: 0.0181 - acc: 0.9683\n",
      "Epoch 221/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0193 - mean_squared_error: 0.0193 - acc: 0.9673\n",
      "Epoch 222/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0185 - mean_squared_error: 0.0185 - acc: 0.9696\n",
      "Epoch 223/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9566\n",
      "Epoch 224/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9550\n",
      "Epoch 225/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9596\n",
      "Epoch 226/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9673\n",
      "Epoch 227/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0217 - mean_squared_error: 0.0217 - acc: 0.9635\n",
      "Epoch 228/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.0221 - mean_squared_error: 0.0221 - acc: 0.9645\n",
      "Epoch 229/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0225 - mean_squared_error: 0.0225 - acc: 0.9632\n",
      "Epoch 230/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0176 - mean_squared_error: 0.0176 - acc: 0.9704\n",
      "Epoch 231/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9662\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0200 - mean_squared_error: 0.0200 - acc: 0.9673\n",
      "Epoch 233/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9638\n",
      "Epoch 234/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0202 - mean_squared_error: 0.0202 - acc: 0.9665\n",
      "Epoch 235/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0191 - mean_squared_error: 0.0191 - acc: 0.9692\n",
      "Epoch 236/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.0201 - mean_squared_error: 0.0201 - acc: 0.9665\n",
      "Epoch 237/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0192 - mean_squared_error: 0.0192 - acc: 0.9683\n",
      "Epoch 238/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.0226 - mean_squared_error: 0.0226 - acc: 0.9618\n",
      "Epoch 239/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9591\n",
      "Epoch 240/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.9550\n",
      "Epoch 241/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9515\n",
      "Epoch 242/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0253 - mean_squared_error: 0.0253 - acc: 0.9572\n",
      "Epoch 243/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.0265 - mean_squared_error: 0.0265 - acc: 0.9540\n",
      "Epoch 244/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9634\n",
      "Epoch 245/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.0272 - mean_squared_error: 0.0272 - acc: 0.95 - 1s 102us/step - loss: 0.0270 - mean_squared_error: 0.0270 - acc: 0.9529\n",
      "Epoch 246/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9630\n",
      "Epoch 247/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.0176 - mean_squared_error: 0.0176 - acc: 0.9700\n",
      "Epoch 248/300\n",
      "7072/7072 [==============================] - 2s 261us/step - loss: 0.0153 - mean_squared_error: 0.0153 - acc: 0.9755\n",
      "Epoch 249/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.0156 - mean_squared_error: 0.0156 - acc: 0.9747\n",
      "Epoch 250/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0183 - mean_squared_error: 0.0183 - acc: 0.9709\n",
      "Epoch 251/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.0204 - mean_squared_error: 0.0204 - acc: 0.9666\n",
      "Epoch 252/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0200 - mean_squared_error: 0.0200 - acc: 0.9673\n",
      "Epoch 253/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0180 - mean_squared_error: 0.0180 - acc: 0.9697\n",
      "Epoch 254/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0158 - mean_squared_error: 0.0158 - acc: 0.97380s - loss: 0.0173 - mean_squared_error: 0.0173 - a\n",
      "Epoch 255/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.95830s - loss: 0.0246 - mean_squared_error: 0.0246 - acc: 0.\n",
      "Epoch 256/300\n",
      "7072/7072 [==============================] - 1s 166us/step - loss: 0.0197 - mean_squared_error: 0.0197 - acc: 0.9663\n",
      "Epoch 257/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9562\n",
      "Epoch 258/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.0224 - mean_squared_error: 0.0224 - acc: 0.9622\n",
      "Epoch 259/300\n",
      "7072/7072 [==============================] - 2s 239us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9563\n",
      "Epoch 260/300\n",
      "7072/7072 [==============================] - 1s 161us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9591\n",
      "Epoch 261/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0215 - mean_squared_error: 0.0215 - acc: 0.9642\n",
      "Epoch 262/300\n",
      "7072/7072 [==============================] - 1s 180us/step - loss: 0.0216 - mean_squared_error: 0.0216 - acc: 0.9641\n",
      "Epoch 263/300\n",
      "7072/7072 [==============================] - 2s 217us/step - loss: 0.0187 - mean_squared_error: 0.0187 - acc: 0.9693\n",
      "Epoch 264/300\n",
      "7072/7072 [==============================] - 1s 160us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9560\n",
      "Epoch 265/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.0197 - mean_squared_error: 0.0197 - acc: 0.9678\n",
      "Epoch 266/300\n",
      "7072/7072 [==============================] - 1s 172us/step - loss: 0.0205 - mean_squared_error: 0.0205 - acc: 0.9658\n",
      "Epoch 267/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0204 - mean_squared_error: 0.0204 - acc: 0.9673\n",
      "Epoch 268/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.0203 - mean_squared_error: 0.0203 - acc: 0.9672\n",
      "Epoch 269/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9663\n",
      "Epoch 270/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9651\n",
      "Epoch 271/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0158 - mean_squared_error: 0.0158 - acc: 0.9734\n",
      "Epoch 272/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0160 - mean_squared_error: 0.0160 - acc: 0.9731\n",
      "Epoch 273/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9584\n",
      "Epoch 274/300\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.0149 - mean_squared_error: 0.0149 - acc: 0.9760\n",
      "Epoch 275/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0166 - mean_squared_error: 0.0166 - acc: 0.9731\n",
      "Epoch 276/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9546\n",
      "Epoch 277/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.0234 - mean_squared_error: 0.0234 - acc: 0.9637\n",
      "Epoch 278/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0228 - mean_squared_error: 0.0228 - acc: 0.9637\n",
      "Epoch 279/300\n",
      "7072/7072 [==============================] - 1s 151us/step - loss: 0.0183 - mean_squared_error: 0.0183 - acc: 0.9712\n",
      "Epoch 280/300\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.0156 - mean_squared_error: 0.0156 - acc: 0.9747\n",
      "Epoch 281/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.0162 - mean_squared_error: 0.0162 - acc: 0.97400s - loss: 0.0182 - mean_squared_error: 0.\n",
      "Epoch 282/300\n",
      "7072/7072 [==============================] - 2s 221us/step - loss: 0.0165 - mean_squared_error: 0.0165 - acc: 0.97340s - loss: 0.0168 - mean_squared_error: 0.0168 - a\n",
      "Epoch 283/300\n",
      "7072/7072 [==============================] - 1s 174us/step - loss: 0.0156 - mean_squared_error: 0.0156 - acc: 0.9753\n",
      "Epoch 284/300\n",
      "7072/7072 [==============================] - 1s 158us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9533\n",
      "Epoch 285/300\n",
      "7072/7072 [==============================] - 1s 174us/step - loss: 0.0391 - mean_squared_error: 0.0391 - acc: 0.9316\n",
      "Epoch 286/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.9485\n",
      "Epoch 287/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0249 - mean_squared_error: 0.0249 - acc: 0.9548\n",
      "Epoch 288/300\n",
      "7072/7072 [==============================] - 1s 160us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9532\n",
      "Epoch 289/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9648\n",
      "Epoch 290/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0202 - mean_squared_error: 0.0202 - acc: 0.9665\n",
      "Epoch 291/300\n",
      "7072/7072 [==============================] - 1s 167us/step - loss: 0.0302 - mean_squared_error: 0.0302 - acc: 0.9451\n",
      "Epoch 292/300\n",
      "7072/7072 [==============================] - 1s 202us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9556\n",
      "Epoch 293/300\n",
      "7072/7072 [==============================] - 1s 158us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9361\n",
      "Epoch 294/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9501\n",
      "Epoch 295/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.0231 - mean_squared_error: 0.0231 - acc: 0.9600\n",
      "Epoch 296/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9579\n",
      "Epoch 297/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0262 - mean_squared_error: 0.0262 - acc: 0.9539\n",
      "Epoch 298/300\n",
      "7072/7072 [==============================] - 1s 180us/step - loss: 0.0247 - mean_squared_error: 0.0247 - acc: 0.9552\n",
      "Epoch 299/300\n",
      "7072/7072 [==============================] - 1s 168us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9567\n",
      "Epoch 300/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.9649\n",
      "2526/2526 [==============================] - 1s 247us/step\n",
      "7072/7072 [==============================] - 1s 77us/step\n",
      "The Score is 0.986936\n",
      "current iteration fraction: 0.600000\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "(6062, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "6062/6062 [==============================] - 2s 410us/step - loss: 0.1833 - mean_squared_error: 0.1833 - acc: 0.5838\n",
      "Epoch 2/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.1562 - mean_squared_error: 0.1562 - acc: 0.6475\n",
      "Epoch 3/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.1410 - mean_squared_error: 0.1410 - acc: 0.69470s - loss: 0.1432 - mean_squared_error: 0.1432 - a\n",
      "Epoch 4/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.1335 - mean_squared_error: 0.1335 - acc: 0.7034\n",
      "Epoch 5/300\n",
      "6062/6062 [==============================] - 1s 163us/step - loss: 0.1170 - mean_squared_error: 0.1170 - acc: 0.7625\n",
      "Epoch 6/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0980 - mean_squared_error: 0.0980 - acc: 0.8251\n",
      "Epoch 7/300\n",
      "6062/6062 [==============================] - 1s 149us/step - loss: 0.0810 - mean_squared_error: 0.0810 - acc: 0.8596\n",
      "Epoch 8/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.0648 - mean_squared_error: 0.0648 - acc: 0.8936\n",
      "Epoch 9/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0576 - mean_squared_error: 0.0576 - acc: 0.9033\n",
      "Epoch 10/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.0528 - mean_squared_error: 0.0528 - acc: 0.9114\n",
      "Epoch 11/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.0462 - mean_squared_error: 0.0462 - acc: 0.9243\n",
      "Epoch 12/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0405 - mean_squared_error: 0.0405 - acc: 0.9334\n",
      "Epoch 13/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0460 - mean_squared_error: 0.0460 - acc: 0.9187\n",
      "Epoch 14/300\n",
      "6062/6062 [==============================] - 1s 93us/step - loss: 0.0452 - mean_squared_error: 0.0452 - acc: 0.9243\n",
      "Epoch 15/300\n",
      "6062/6062 [==============================] - 1s 93us/step - loss: 0.0474 - mean_squared_error: 0.0474 - acc: 0.9164\n",
      "Epoch 16/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.9429\n",
      "Epoch 17/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9431\n",
      "Epoch 18/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0384 - mean_squared_error: 0.0384 - acc: 0.9334\n",
      "Epoch 19/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0396 - mean_squared_error: 0.0396 - acc: 0.9310\n",
      "Epoch 20/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0352 - mean_squared_error: 0.0352 - acc: 0.9393\n",
      "Epoch 21/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0303 - mean_squared_error: 0.0303 - acc: 0.9505\n",
      "Epoch 22/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0340 - mean_squared_error: 0.0340 - acc: 0.9416\n",
      "Epoch 23/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0498 - mean_squared_error: 0.0498 - acc: 0.9068\n",
      "Epoch 24/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9337\n",
      "Epoch 25/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9347\n",
      "Epoch 26/300\n",
      "6062/6062 [==============================] - 1s 152us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9395\n",
      "Epoch 27/300\n",
      "6062/6062 [==============================] - 1s 171us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9454\n",
      "Epoch 28/300\n",
      "6062/6062 [==============================] - 1s 185us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9532\n",
      "Epoch 29/300\n",
      "6062/6062 [==============================] - 3s 565us/step - loss: 0.0334 - mean_squared_error: 0.0334 - acc: 0.94230s - loss: 0.0339 - mean_squared_error: 0.0339 - - ETA: 0s - loss: 0.0340 - mean_squared_e\n",
      "Epoch 30/300\n",
      "6062/6062 [==============================] - 1s 246us/step - loss: 0.0358 - mean_squared_error: 0.0358 - acc: 0.9391\n",
      "Epoch 31/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0353 - mean_squared_error: 0.0353 - acc: 0.9362\n",
      "Epoch 32/300\n",
      "6062/6062 [==============================] - 1s 163us/step - loss: 0.0407 - mean_squared_error: 0.0407 - acc: 0.9264\n",
      "Epoch 33/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9507\n",
      "Epoch 34/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0338 - mean_squared_error: 0.0338 - acc: 0.9376\n",
      "Epoch 35/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.9373\n",
      "Epoch 36/300\n",
      "6062/6062 [==============================] - 1s 132us/step - loss: 0.0616 - mean_squared_error: 0.0616 - acc: 0.8834\n",
      "Epoch 37/300\n",
      "6062/6062 [==============================] - 1s 140us/step - loss: 0.0412 - mean_squared_error: 0.0412 - acc: 0.9261\n",
      "Epoch 38/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0345 - mean_squared_error: 0.0345 - acc: 0.9370\n",
      "Epoch 39/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9522\n",
      "Epoch 40/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0320 - mean_squared_error: 0.0320 - acc: 0.9424\n",
      "Epoch 41/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.95030s - loss: 0.0218 - mean_squared_err\n",
      "Epoch 42/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9447\n",
      "Epoch 43/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9398\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0337 - mean_squared_error: 0.0337 - acc: 0.9396\n",
      "Epoch 45/300\n",
      "6062/6062 [==============================] - 1s 99us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9353\n",
      "Epoch 46/300\n",
      "6062/6062 [==============================] - 1s 93us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9289\n",
      "Epoch 47/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.0457 - mean_squared_error: 0.0457 - acc: 0.9154\n",
      "Epoch 48/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0388 - mean_squared_error: 0.0388 - acc: 0.9228\n",
      "Epoch 49/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0392 - mean_squared_error: 0.0392 - acc: 0.9259\n",
      "Epoch 50/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0281 - acc: 0.94 - 1s 147us/step - loss: 0.0282 - mean_squared_error: 0.0282 - acc: 0.9485\n",
      "Epoch 51/300\n",
      "6062/6062 [==============================] - 1s 141us/step - loss: 0.0342 - mean_squared_error: 0.0342 - acc: 0.9376\n",
      "Epoch 52/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0313 - mean_squared_error: 0.0313 - acc: 0.9457\n",
      "Epoch 53/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9517\n",
      "Epoch 54/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0261 - mean_squared_error: 0.0261 - acc: 0.9540\n",
      "Epoch 55/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.0306 - mean_squared_error: 0.0306 - acc: 0.9449\n",
      "Epoch 56/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0443 - mean_squared_error: 0.0443 - acc: 0.9187\n",
      "Epoch 57/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.0374 - mean_squared_error: 0.0374 - acc: 0.9301\n",
      "Epoch 58/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.0316 - mean_squared_error: 0.0316 - acc: 0.9424\n",
      "Epoch 59/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.0330 - mean_squared_error: 0.0330 - acc: 0.9395\n",
      "Epoch 60/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9444\n",
      "Epoch 61/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.9487\n",
      "Epoch 62/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9576\n",
      "Epoch 63/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0324 - mean_squared_error: 0.0324 - acc: 0.9403\n",
      "Epoch 64/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0436 - mean_squared_error: 0.0436 - acc: 0.9154\n",
      "Epoch 65/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9304\n",
      "Epoch 66/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9451\n",
      "Epoch 67/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.0271 - mean_squared_error: 0.0271 - acc: 0.9507\n",
      "Epoch 68/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9589\n",
      "Epoch 69/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0213 - mean_squared_error: 0.0213 - acc: 0.9632\n",
      "Epoch 70/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0256 - mean_squared_error: 0.0256 - acc: 0.9551\n",
      "Epoch 71/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9583\n",
      "Epoch 72/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0446 - mean_squared_error: 0.0446 - acc: 0.9152\n",
      "Epoch 73/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9579\n",
      "Epoch 74/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.0251 - mean_squared_error: 0.0251 - acc: 0.9565\n",
      "Epoch 75/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0260 - mean_squared_error: 0.0260 - acc: 0.9566\n",
      "Epoch 76/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9543\n",
      "Epoch 77/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0333 - mean_squared_error: 0.0333 - acc: 0.9408\n",
      "Epoch 78/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0377 - mean_squared_error: 0.0377 - acc: 0.9310\n",
      "Epoch 79/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0522 - mean_squared_error: 0.0522 - acc: 0.9043\n",
      "Epoch 80/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0327 - mean_squared_error: 0.0327 - acc: 0.9388\n",
      "Epoch 81/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0252 - mean_squared_error: 0.0252 - acc: 0.9565\n",
      "Epoch 82/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.9515\n",
      "Epoch 83/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9489\n",
      "Epoch 84/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0285 - mean_squared_error: 0.0285 - acc: 0.95020s - loss: 0.0255 - mean_squared_error: \n",
      "Epoch 85/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.0269 - mean_squared_error: 0.0269 - acc: 0.9510\n",
      "Epoch 86/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9489\n",
      "Epoch 87/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.0312 - mean_squared_error: 0.0312 - acc: 0.9429\n",
      "Epoch 88/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.95530s - loss: 0.0265 - mean_squared_error: 0.0265 - acc\n",
      "Epoch 89/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.0264 - mean_squared_error: 0.0264 - acc: 0.9550\n",
      "Epoch 90/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0276 - mean_squared_error: 0.0276 - acc: 0.9492\n",
      "Epoch 91/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.0273 - mean_squared_error: 0.0273 - acc: 0.9522\n",
      "Epoch 92/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9563\n",
      "Epoch 93/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.9588\n",
      "Epoch 94/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.0267 - mean_squared_error: 0.0267 - acc: 0.9536\n",
      "Epoch 95/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.0248 - mean_squared_error: 0.0248 - acc: 0.9560\n",
      "Epoch 96/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0361 - mean_squared_error: 0.0361 - acc: 0.9343\n",
      "Epoch 97/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.0579 - mean_squared_error: 0.0579 - acc: 0.8883\n",
      "Epoch 98/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9391\n",
      "Epoch 99/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0288 - mean_squared_error: 0.0288 - acc: 0.9477\n",
      "Epoch 100/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9475\n",
      "Epoch 101/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.0274 - mean_squared_error: 0.0274 - acc: 0.9530\n",
      "Epoch 102/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.0348 - mean_squared_error: 0.0348 - acc: 0.9357\n",
      "Epoch 103/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.0291 - mean_squared_error: 0.0291 - acc: 0.9470\n",
      "Epoch 104/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.0351 - mean_squared_error: 0.0351 - acc: 0.9314\n",
      "Epoch 105/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9282\n",
      "Epoch 106/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9459\n",
      "Epoch 107/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0295 - mean_squared_error: 0.0295 - acc: 0.9444\n",
      "Epoch 108/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0275 - mean_squared_error: 0.0275 - acc: 0.9487\n",
      "Epoch 109/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0297 - mean_squared_error: 0.0297 - acc: 0.9451\n",
      "Epoch 110/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0284 - mean_squared_error: 0.0284 - acc: 0.9487\n",
      "Epoch 111/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.0379 - mean_squared_error: 0.0379 - acc: 0.9297\n",
      "Epoch 112/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0419 - mean_squared_error: 0.0419 - acc: 0.9197\n",
      "Epoch 113/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9522\n",
      "Epoch 114/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9515\n",
      "Epoch 115/300\n",
      "6062/6062 [==============================] - 1s 100us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9568\n",
      "Epoch 116/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.9515\n",
      "Epoch 117/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.0238 - mean_squared_error: 0.0238 - acc: 0.9571\n",
      "Epoch 118/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.0289 - mean_squared_error: 0.0289 - acc: 0.9446\n",
      "Epoch 119/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0280 - mean_squared_error: 0.0280 - acc: 0.9490\n",
      "Epoch 120/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.0510 - mean_squared_error: 0.0510 - acc: 0.9043\n",
      "Epoch 121/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0369 - mean_squared_error: 0.0369 - acc: 0.9337\n",
      "Epoch 122/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0387 - mean_squared_error: 0.0387 - acc: 0.93060s - loss: 0.0356 - mean_squared_error: 0.0356 - acc: \n",
      "Epoch 123/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.0347 - mean_squared_error: 0.0347 - acc: 0.9371\n",
      "Epoch 124/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.0365 - mean_squared_error: 0.0365 - acc: 0.9360\n",
      "Epoch 125/300\n",
      "6062/6062 [==============================] - 1s 96us/step - loss: 0.0371 - mean_squared_error: 0.0371 - acc: 0.9337\n",
      "Epoch 126/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9441\n",
      "Epoch 127/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0287 - mean_squared_error: 0.0287 - acc: 0.9500\n",
      "Epoch 128/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9418\n",
      "Epoch 129/300\n",
      "6062/6062 [==============================] - 1s 101us/step - loss: 0.0420 - mean_squared_error: 0.0420 - acc: 0.9202\n",
      "Epoch 130/300\n",
      "6062/6062 [==============================] - 1s 94us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9423\n",
      "Epoch 131/300\n",
      "6062/6062 [==============================] - 1s 98us/step - loss: 0.0256 - mean_squared_error: 0.0256 - acc: 0.9571\n",
      "Epoch 132/300\n",
      "6062/6062 [==============================] - 1s 97us/step - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.9589\n",
      "Epoch 133/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0247 - mean_squared_error: 0.0247 - acc: 0.9571\n",
      "Epoch 134/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.0249 - mean_squared_error: 0.0249 - acc: 0.9576\n",
      "Epoch 135/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.0207 - mean_squared_error: 0.0207 - acc: 0.9644\n",
      "Epoch 136/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.0325 - mean_squared_error: 0.0325 - acc: 0.9358\n",
      "Epoch 137/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.0307 - mean_squared_error: 0.0307 - acc: 0.9424\n",
      "Epoch 138/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0308 - mean_squared_error: 0.0308 - acc: 0.9419\n",
      "Epoch 139/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.0293 - mean_squared_error: 0.0293 - acc: 0.9462\n",
      "Epoch 140/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.0234 - mean_squared_error: 0.0234 - acc: 0.9597\n",
      "Epoch 141/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.0250 - mean_squared_error: 0.0250 - acc: 0.9573\n",
      "Epoch 142/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9540\n",
      "Epoch 143/300\n",
      "6062/6062 [==============================] - 1s 192us/step - loss: 0.0242 - mean_squared_error: 0.0242 - acc: 0.95781s - loss: 0.0201 \n",
      "Epoch 144/300\n",
      "6062/6062 [==============================] - 2s 378us/step - loss: 0.0278 - mean_squared_error: 0.0278 - acc: 0.95180s - - ETA: 0s - loss: 0.0259 - mean_squared_error: 0.02\n",
      "Epoch 145/300\n",
      "6062/6062 [==============================] - 1s 229us/step - loss: 0.0454 - mean_squared_error: 0.0454 - acc: 0.91450s - loss: 0.0472 - mean_squared_error: 0.0472 - acc\n",
      "Epoch 146/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.0323 - mean_squared_error: 0.0323 - acc: 0.9419\n",
      "Epoch 147/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.0263 - mean_squared_error: 0.0263 - acc: 0.9522\n",
      "Epoch 148/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.0311 - mean_squared_error: 0.0311 - acc: 0.9466\n",
      "Epoch 149/300\n",
      "6062/6062 [==============================] - 1s 177us/step - loss: 0.0321 - mean_squared_error: 0.0321 - acc: 0.9447\n",
      "Epoch 150/300\n",
      "6062/6062 [==============================] - 2s 264us/step - loss: 0.0257 - mean_squared_error: 0.0257 - acc: 0.9560\n",
      "Epoch 151/300\n",
      "6062/6062 [==============================] - 1s 198us/step - loss: 0.0294 - mean_squared_error: 0.0294 - acc: 0.9497\n",
      "Epoch 152/300\n",
      "6062/6062 [==============================] - 1s 201us/step - loss: 0.0322 - mean_squared_error: 0.0322 - acc: 0.9442\n",
      "Epoch 153/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.0362 - mean_squared_error: 0.0362 - acc: 0.93452s - loss: 0.0356 - mean_squared_error: 0.0356 - acc: 0.94 - ETA: 2s - loss: 0.0347 - mean_squar\n",
      "Epoch 154/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0315 - mean_squared_error: 0.0315 - acc: 0.9451\n",
      "Epoch 155/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0301 - mean_squared_error: 0.0301 - acc: 0.94700s - loss: 0.0312 - mean_squared_error\n",
      "Epoch 156/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9576\n",
      "Epoch 157/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.0194 - mean_squared_error: 0.0194 - acc: 0.9678\n",
      "Epoch 158/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.0232 - mean_squared_error: 0.0232 - acc: 0.9589\n",
      "Epoch 159/300\n",
      "6062/6062 [==============================] - 1s 142us/step - loss: 0.0215 - mean_squared_error: 0.0215 - acc: 0.96340s - loss: 0.0145 - mean_squar\n",
      "Epoch 160/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.0224 - mean_squared_error: 0.0224 - acc: 0.9611\n",
      "Epoch 161/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.9596\n",
      "Epoch 162/300\n",
      "6062/6062 [==============================] - 1s 144us/step - loss: 0.0254 - mean_squared_error: 0.0254 - acc: 0.9560\n",
      "Epoch 163/300\n",
      "6062/6062 [==============================] - 1s 144us/step - loss: 0.0236 - mean_squared_error: 0.0236 - acc: 0.9596\n",
      "Epoch 164/300\n",
      "6062/6062 [==============================] - 1s 145us/step - loss: 0.0231 - mean_squared_error: 0.0231 - acc: 0.9617\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.0195 - mean_squared_error: 0.0195 - acc: 0.9690\n",
      "Epoch 166/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.0218 - mean_squared_error: 0.0218 - acc: 0.9634\n",
      "Epoch 167/300\n",
      "6062/6062 [==============================] - 1s 153us/step - loss: 0.0233 - mean_squared_error: 0.0233 - acc: 0.9597\n",
      "Epoch 168/300\n",
      "6062/6062 [==============================] - 1s 154us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.9665\n",
      "Epoch 169/300\n",
      "2112/6062 [=========>....................] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0237 - acc: 0.9588"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-25ceecb9f050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwriteDictToCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningCurveIterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsPCAEM.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 3)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetPCAEM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ICA<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "pca.fit(X_inputs)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "ica.fit(X_inputs)\n",
    "X_inputs = ica.transform(X_inputs)\n",
    "\n",
    "\n",
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsICA.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 2)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetICA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "ica = FastICA(n_components = 2)\n",
    "ica.fit(X_inputs)\n",
    "X_inputs = ica.transform(X_inputs)\n",
    "\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 213us/step - loss: 0.2366 - mean_squared_error: 0.2366 - acc: 0.3569\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.2112 - mean_squared_error: 0.2112 - acc: 0.4479\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.1863 - mean_squared_error: 0.1863 - acc: 0.5567\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.1725 - mean_squared_error: 0.1725 - acc: 0.59950s - loss: 0.1765 - mean_squar\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.1655 - mean_squared_error: 0.1655 - acc: 0.6228\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.1626 - mean_squared_error: 0.1626 - acc: 0.6300\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.1588 - mean_squared_error: 0.1588 - acc: 0.6441\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.1572 - mean_squared_error: 0.1572 - acc: 0.6421\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.1558 - mean_squared_error: 0.1558 - acc: 0.6480\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.1551 - mean_squared_error: 0.1551 - acc: 0.6488\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.1544 - mean_squared_error: 0.1544 - acc: 0.6499\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.1534 - mean_squared_error: 0.1534 - acc: 0.6517\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.1528 - mean_squared_error: 0.1528 - acc: 0.6483\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1514 - mean_squared_error: 0.1514 - acc: 0.65 - 1s 102us/step - loss: 0.1520 - mean_squared_error: 0.1520 - acc: 0.6533\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.1519 - mean_squared_error: 0.1519 - acc: 0.6550\n",
      "2526/2526 [==============================] - 0s 136us/step\n",
      "8083/8083 [==============================] - 0s 54us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1518 - mean_squared_error: 0.1518 - acc: 0.6517\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1508 - mean_squared_error: 0.1508 - acc: 0.6536\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.1514 - mean_squared_error: 0.1514 - acc: 0.6543\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.1507 - mean_squared_error: 0.1507 - acc: 0.6527\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1503 - mean_squared_error: 0.1503 - acc: 0.65 - 1s 179us/step - loss: 0.1503 - mean_squared_error: 0.1503 - acc: 0.6538\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6538\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.1505 - mean_squared_error: 0.1505 - acc: 0.6535\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.1499 - mean_squared_error: 0.1499 - acc: 0.6530\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.6548\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1499 - mean_squared_error: 0.1499 - acc: 0.6546\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6543\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.1496 - mean_squared_error: 0.1496 - acc: 0.6551\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6553\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.6551\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6543\n",
      "2526/2526 [==============================] - 0s 52us/step\n",
      "8083/8083 [==============================] - 0s 37us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6552\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6538\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6547\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6551\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6546\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1493 - mean_squared_error: 0.1493 - acc: 0.6547\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6558\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.6547\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6545\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1492 - mean_squared_error: 0.1492 - acc: 0.6542\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6543\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6540\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6548\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1485 - mean_squared_error: 0.1485 - acc: 0.6548\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 79us/step - loss: 0.1483 - mean_squared_error: 0.1483 - acc: 0.6542\n",
      "2526/2526 [==============================] - 0s 41us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6550\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.1478 - mean_squared_error: 0.1478 - acc: 0.6559\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6542\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6543\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6545\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6552\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6542\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6551\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1475 - mean_squared_error: 0.1475 - acc: 0.6554\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1476 - mean_squared_error: 0.1476 - acc: 0.6548\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.6548\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1477 - mean_squared_error: 0.1477 - acc: 0.6553\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1478 - mean_squared_error: 0.1478 - acc: 0.6561\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1474 - mean_squared_error: 0.1474 - acc: 0.6556\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1470 - mean_squared_error: 0.1470 - acc: 0.6554\n",
      "2526/2526 [==============================] - 0s 36us/step\n",
      "8083/8083 [==============================] - 0s 38us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1473 - mean_squared_error: 0.1473 - acc: 0.6545\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1469 - mean_squared_error: 0.1469 - acc: 0.6559\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1471 - mean_squared_error: 0.1471 - acc: 0.6551\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6561\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1468 - mean_squared_error: 0.1468 - acc: 0.6572\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.1470 - mean_squared_error: 0.1470 - acc: 0.6558\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6563\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.1469 - mean_squared_error: 0.1469 - acc: 0.6564\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1456 - mean_squared_error: 0.1456 - acc: 0.65 - 1s 148us/step - loss: 0.1461 - mean_squared_error: 0.1461 - acc: 0.6582\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.1461 - mean_squared_error: 0.1461 - acc: 0.6574\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6608\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6603\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1468 - mean_squared_error: 0.1468 - acc: 0.65 - 1s 115us/step - loss: 0.1463 - mean_squared_error: 0.1463 - acc: 0.6599\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.1456 - mean_squared_error: 0.1456 - acc: 0.6606\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.1454 - mean_squared_error: 0.1454 - acc: 0.6604\n",
      "2526/2526 [==============================] - 0s 53us/step\n",
      "8083/8083 [==============================] - 1s 66us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.1457 - mean_squared_error: 0.1457 - acc: 0.6630\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6600\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.1445 - mean_squared_error: 0.1445 - acc: 0.6626 0s - loss: 0.1446 - mean_squared_error: 0.1446 - acc: 0.66\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.1449 - mean_squared_error: 0.1449 - acc: 0.6656\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1444 - mean_squared_error: 0.1444 - acc: 0.6624 0s - loss: 0.1442 - mean_squared_error: \n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.1443 - mean_squared_error: 0.1443 - acc: 0.6635\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1447 - mean_squared_error: 0.1447 - acc: 0.6626\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.1438 - mean_squared_error: 0.1438 - acc: 0.6618\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.1446 - mean_squared_error: 0.1446 - acc: 0.6657\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.1442 - mean_squared_error: 0.1442 - acc: 0.6653\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.1435 - mean_squared_error: 0.1435 - acc: 0.66561s - loss: 0.1441 - mean_squared_error: 0.1441 - acc: 0.66 - ETA: 1s - loss: 0.1453 - \n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.1430 - mean_squared_error: 0.1430 - acc: 0.6746\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.1432 - mean_squared_error: 0.1432 - acc: 0.6692\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.1430 - mean_squared_error: 0.1430 - acc: 0.6662\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.1429 - mean_squared_error: 0.1429 - acc: 0.6708\n",
      "2526/2526 [==============================] - 0s 41us/step\n",
      "8083/8083 [==============================] - 0s 41us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1428 - mean_squared_error: 0.1428 - acc: 0.6715\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.1429 - mean_squared_error: 0.1429 - acc: 0.6735\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.1424 - mean_squared_error: 0.1424 - acc: 0.6679\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.1424 - mean_squared_error: 0.1424 - acc: 0.6652\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.1426 - mean_squared_error: 0.1426 - acc: 0.6749\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1414 - mean_squared_error: 0.1414 - acc: 0.6744\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.1413 - mean_squared_error: 0.1413 - acc: 0.6731\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.1413 - mean_squared_error: 0.1413 - acc: 0.6772\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.6791\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.1399 - mean_squared_error: 0.1399 - acc: 0.6858\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.1394 - mean_squared_error: 0.1394 - acc: 0.6837\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.1402 - mean_squared_error: 0.1402 - acc: 0.67470s - loss: 0.1407 - mean_squared_error\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.1400 - mean_squared_error: 0.1400 - acc: 0.6845\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.1399 - mean_squared_error: 0.1399 - acc: 0.6850\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.1388 - mean_squared_error: 0.1388 - acc: 0.6872\n",
      "2526/2526 [==============================] - 0s 54us/step\n",
      "8083/8083 [==============================] - 0s 46us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1378 - mean_squared_error: 0.1378 - acc: 0.6891\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.1385 - mean_squared_error: 0.1385 - acc: 0.6865\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.6893\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1376 - mean_squared_error: 0.1376 - acc: 0.6923\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1383 - mean_squared_error: 0.1383 - acc: 0.6845\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1380 - mean_squared_error: 0.1380 - acc: 0.6934\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 94us/step - loss: 0.1360 - mean_squared_error: 0.1360 - acc: 0.6918\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1363 - mean_squared_error: 0.1363 - acc: 0.6953\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1369 - mean_squared_error: 0.1369 - acc: 0.6955\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1361 - mean_squared_error: 0.1361 - acc: 0.6954\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1337 - mean_squared_error: 0.1337 - acc: 0.7012\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1361 - mean_squared_error: 0.1361 - acc: 0.6927\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.1355 - mean_squared_error: 0.1355 - acc: 0.6984\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.1335 - mean_squared_error: 0.1335 - acc: 0.7036\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1345 - mean_squared_error: 0.1345 - acc: 0.6984\n",
      "2526/2526 [==============================] - 0s 38us/step\n",
      "8083/8083 [==============================] - 0s 39us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.1329 - mean_squared_error: 0.1329 - acc: 0.7056\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1323 - mean_squared_error: 0.1323 - acc: 0.7068\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.1310 - mean_squared_error: 0.1310 - acc: 0.7111\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1313 - mean_squared_error: 0.1313 - acc: 0.7077\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1302 - mean_squared_error: 0.1302 - acc: 0.71 - 1s 82us/step - loss: 0.1300 - mean_squared_error: 0.1300 - acc: 0.7129\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1305 - mean_squared_error: 0.1305 - acc: 0.7052\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1295 - mean_squared_error: 0.1295 - acc: 0.7153\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1293 - mean_squared_error: 0.1293 - acc: 0.7105\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1291 - mean_squared_error: 0.1291 - acc: 0.7141\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1259 - mean_squared_error: 0.1259 - acc: 0.7173\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1266 - mean_squared_error: 0.1266 - acc: 0.7236\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1262 - mean_squared_error: 0.1262 - acc: 0.7223\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1258 - mean_squared_error: 0.1258 - acc: 0.7203\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.1260 - mean_squared_error: 0.1260 - acc: 0.7181\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1238 - mean_squared_error: 0.1238 - acc: 0.7279\n",
      "2526/2526 [==============================] - 0s 37us/step\n",
      "8083/8083 [==============================] - 0s 38us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.1239 - mean_squared_error: 0.1239 - acc: 0.7268\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.1244 - mean_squared_error: 0.1244 - acc: 0.72780s - loss: 0.1210 - mean_squar\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1224 - mean_squared_error: 0.1224 - acc: 0.7313\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1206 - mean_squared_error: 0.1206 - acc: 0.7366\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1200 - mean_squared_error: 0.1200 - acc: 0.7404\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 0.1197 - mean_squared_error: 0.1197 - acc: 0.7433\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1201 - mean_squared_error: 0.1201 - acc: 0.7357\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1165 - mean_squared_error: 0.1165 - acc: 0.7460\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1154 - mean_squared_error: 0.1154 - acc: 0.7495\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1175 - mean_squared_error: 0.1175 - acc: 0.7421\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.1170 - mean_squared_error: 0.1170 - acc: 0.7444\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1161 - mean_squared_error: 0.1161 - acc: 0.7458\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.1150 - mean_squared_error: 0.1150 - acc: 0.7510\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 82us/step - loss: 0.1137 - mean_squared_error: 0.1137 - acc: 0.7573\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1133 - mean_squared_error: 0.1133 - acc: 0.7527\n",
      "2526/2526 [==============================] - 0s 37us/step\n",
      "8083/8083 [==============================] - 0s 37us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1121 - mean_squared_error: 0.1121 - acc: 0.7590\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1121 - mean_squared_error: 0.1121 - acc: 0.7558\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.1125 - mean_squared_error: 0.1125 - acc: 0.7575\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.1126 - mean_squared_error: 0.1126 - acc: 0.7596\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.1102 - mean_squared_error: 0.1102 - acc: 0.7628\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.1107 - mean_squared_error: 0.1107 - acc: 0.7604\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.1086 - mean_squared_error: 0.1086 - acc: 0.7636\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1073 - mean_squared_error: 0.1073 - acc: 0.7699\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1067 - mean_squared_error: 0.1067 - acc: 0.7706\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1079 - mean_squared_error: 0.1079 - acc: 0.7714\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 79us/step - loss: 0.1079 - mean_squared_error: 0.1079 - acc: 0.7696\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.1073 - mean_squared_error: 0.1073 - acc: 0.7653\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.1070 - mean_squared_error: 0.1070 - acc: 0.7741\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.1067 - mean_squared_error: 0.1067 - acc: 0.7722\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.1052 - mean_squared_error: 0.1052 - acc: 0.7747\n",
      "2526/2526 [==============================] - ETA:  - 0s 40us/step\n",
      "8083/8083 [==============================] - 0s 37us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1051 - mean_squared_error: 0.1051 - acc: 0.7737\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1056 - mean_squared_error: 0.1056 - acc: 0.7724\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 86us/step - loss: 0.1038 - mean_squared_error: 0.1038 - acc: 0.7767\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1028 - mean_squared_error: 0.1028 - acc: 0.7781\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.1023 - mean_squared_error: 0.1023 - acc: 0.7821\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.1022 - mean_squared_error: 0.1022 - acc: 0.7814\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.1003 - mean_squared_error: 0.1003 - acc: 0.7846\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.1034 - mean_squared_error: 0.1034 - acc: 0.7755\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1022 - mean_squared_error: 0.1022 - acc: 0.78361s - loss: 0.1008 - mean_s\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.0995 - mean_squared_error: 0.0995 - acc: 0.7910\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 85us/step - loss: 0.1021 - mean_squared_error: 0.1021 - acc: 0.7809\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 80us/step - loss: 0.1012 - mean_squared_error: 0.1012 - acc: 0.7819\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 81us/step - loss: 0.0989 - mean_squared_error: 0.0989 - acc: 0.7903\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0986 - mean_squared_error: 0.0986 - acc: 0.7939 ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0996 - a - 1s 83us/step - loss: 0.0992 - mean_squared_error: 0.0992 - acc: 0.7922\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.0986 - mean_squared_error: 0.0986 - acc: 0.7927\n",
      "2526/2526 [==============================] - 0s 65us/step\n",
      "8083/8083 [==============================] - 1s 89us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0962 - mean_squared_error: 0.0962 - acc: 0.7935\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0981 - mean_squared_error: 0.0981 - acc: 0.7949\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0976 - mean_squared_error: 0.0976 - acc: 0.7907\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0977 - mean_squared_error: 0.0977 - acc: 0.79100s - loss: 0.0984 - mean_squared_error: \n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0958 - mean_squared_error: 0.0958 - acc: 0.7956\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0956 - mean_squared_error: 0.0956 - acc: 0.7952\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 97us/step - loss: 0.0949 - mean_squared_error: 0.0949 - acc: 0.7939\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0965 - mean_squared_error: 0.0965 - acc: 0.7934\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0936 - mean_squared_error: 0.0936 - acc: 0.8025\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0931 - mean_squared_error: 0.0931 - acc: 0.8000\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0949 - mean_squared_error: 0.0949 - acc: 0.7976\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0966 - mean_squared_error: 0.0966 - acc: 0.7950\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0927 - mean_squared_error: 0.0927 - acc: 0.8045\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0937 - mean_squared_error: 0.0937 - acc: 0.8000\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0927 - mean_squared_error: 0.0927 - acc: 0.8023\n",
      "2526/2526 [==============================] - 0s 40us/step\n",
      "8083/8083 [==============================] - 0s 41us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 92us/step - loss: 0.0915 - mean_squared_error: 0.0915 - acc: 0.8074\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0958 - mean_squared_error: 0.0958 - acc: 0.7950\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.0929 - mean_squared_error: 0.0929 - acc: 0.8009\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0939 - mean_squared_error: 0.0939 - acc: 0.8008\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0907 - mean_squared_error: 0.0907 - acc: 0.8096\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0888 - mean_squared_error: 0.0888 - acc: 0.8159\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0913 - mean_squared_error: 0.0913 - acc: 0.8068\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0903 - mean_squared_error: 0.0903 - acc: 0.80810s - loss: 0.0898 - mean_squared_error: 0.0898 - acc: 0.\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0894 - mean_squared_error: 0.0894 - acc: 0.8076\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0896 - mean_squared_error: 0.0896 - acc: 0.8087\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0897 - mean_squared_error: 0.0897 - acc: 0.8077\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0905 - mean_squared_error: 0.0905 - acc: 0.8095\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0886 - mean_squared_error: 0.0886 - acc: 0.8184\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0859 - mean_squared_error: 0.0859 - acc: 0.8189\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.0880 - mean_squared_error: 0.0880 - acc: 0.81262s - loss: 0\n",
      "2526/2526 [==============================] - 0s 41us/step\n",
      "8083/8083 [==============================] - 1s 76us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0884 - mean_squared_error: 0.0884 - acc: 0.8153\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.0865 - mean_squared_error: 0.0865 - acc: 0.8190\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0869 - mean_squared_error: 0.0869 - acc: 0.8144\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.0882 - mean_squared_error: 0.0882 - acc: 0.8145\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0859 - mean_squared_error: 0.0859 - acc: 0.8216\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0843 - mean_squared_error: 0.0843 - acc: 0.82122s - loss: 0.0807 - mean_squar\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0866 - mean_squared_error: 0.0866 - acc: 0.8152\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0834 - mean_squared_error: 0.0834 - acc: 0.8263\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0876 - mean_squared_error: 0.0876 - acc: 0.8126\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0874 - mean_squared_error: 0.0874 - acc: 0.8170\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0854 - mean_squared_error: 0.0854 - acc: 0.8185\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0846 - mean_squared_error: 0.0846 - acc: 0.8218\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0843 - mean_squared_error: 0.0843 - acc: 0.8221\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.0824 - mean_squared_error: 0.0824 - acc: 0.8269\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 103us/step - loss: 0.0821 - mean_squared_error: 0.0821 - acc: 0.8273\n",
      "2526/2526 [==============================] - 0s 56us/step\n",
      "8083/8083 [==============================] - 0s 47us/step\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0855 - mean_squared_error: 0.0855 - acc: 0.8163\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.0836 - mean_squared_error: 0.0836 - acc: 0.8230\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0823 - mean_squared_error: 0.0823 - acc: 0.8270\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0846 - mean_squared_error: 0.0846 - acc: 0.8204\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0814 - mean_squared_error: 0.0814 - acc: 0.8317\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0803 - mean_squared_error: 0.0803 - acc: 0.8308\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0807 - mean_squared_error: 0.0807 - acc: 0.82880s - loss: 0.0804 - mean_squared_error: \n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0815 - mean_squared_error: 0.0815 - acc: 0.8320\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0822 - mean_squared_error: 0.0822 - acc: 0.8290\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 84us/step - loss: 0.0800 - mean_squared_error: 0.0800 - acc: 0.8347\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.0797 - mean_squared_error: 0.0797 - acc: 0.8353\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0809 - mean_squared_error: 0.0809 - acc: 0.8242\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 179us/step - loss: 0.0794 - mean_squared_error: 0.0794 - acc: 0.83210s - loss: 0.075\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0792 - mean_squared_error: 0.0792 - acc: 0.8372\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0778 - mean_squared_error: 0.0778 - acc: 0.8390\n",
      "2526/2526 [==============================] - 0s 48us/step\n",
      "8083/8083 [==============================] - 0s 56us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0772 - mean_squared_error: 0.0772 - acc: 0.8414\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.0779 - mean_squared_error: 0.0779 - acc: 0.8363\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 101us/step - loss: 0.0794 - mean_squared_error: 0.0794 - acc: 0.83030s - loss: 0.0800 - mean_squared_e\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0767 - mean_squared_error: 0.0767 - acc: 0.8381\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0788 - mean_squared_error: 0.0788 - acc: 0.8353\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0782 - mean_squared_error: 0.0782 - acc: 0.8382\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.0772 - mean_squared_error: 0.0772 - acc: 0.8364\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0776 - mean_squared_error: 0.0776 - acc: 0.8393\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 89us/step - loss: 0.0758 - mean_squared_error: 0.0758 - acc: 0.8399\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 88us/step - loss: 0.0757 - mean_squared_error: 0.0757 - acc: 0.8425\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.0780 - mean_squared_error: 0.0780 - acc: 0.8360\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0750 - mean_squared_error: 0.0750 - acc: 0.8415\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.0782 - mean_squared_error: 0.0782 - acc: 0.8367\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.0774 - acc: 0.83 - 1s 108us/step - loss: 0.0777 - mean_squared_error: 0.0777 - acc: 0.8377\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0754 - mean_squared_error: 0.0754 - acc: 0.8397\n",
      "2526/2526 [==============================] - 0s 51us/step\n",
      "8083/8083 [==============================] - 0s 52us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.0764 - mean_squared_error: 0.0764 - acc: 0.8364\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0738 - mean_squared_error: 0.0738 - acc: 0.8461\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.0744 - mean_squared_error: 0.0744 - acc: 0.8442\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0763 - mean_squared_error: 0.0763 - acc: 0.8415 0s - loss: 0.0748 - mean_squared_error: 0.07\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0765 - mean_squared_error: 0.0765 - acc: 0.83670s - loss: 0.0815 - mean_squared_e\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0758 - mean_squared_error: 0.0758 - acc: 0.8413\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.0750 - mean_squared_error: 0.0750 - acc: 0.84180s - loss: 0.0749 - mean_squared\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.0753 - mean_squared_error: 0.0753 - acc: 0.8407\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0741 - mean_squared_error: 0.0741 - acc: 0.8452\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 93us/step - loss: 0.0750 - mean_squared_error: 0.0750 - acc: 0.8454\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 90us/step - loss: 0.0725 - mean_squared_error: 0.0725 - acc: 0.8498\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 83us/step - loss: 0.0748 - mean_squared_error: 0.0748 - acc: 0.8409\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 87us/step - loss: 0.0717 - mean_squared_error: 0.0717 - acc: 0.8496\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0691 - mean_squared_error: 0.0691 - acc: 0.8555\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0739 - mean_squared_error: 0.0739 - acc: 0.84710s - loss: 0.0788 - mean_squared\n",
      "2526/2526 [==============================] - 0s 44us/step\n",
      "8083/8083 [==============================] - 0s 54us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0713 - mean_squared_error: 0.0713 - acc: 0.8523\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.0722 - mean_squared_error: 0.0722 - acc: 0.8508\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.0736 - mean_squared_error: 0.0736 - acc: 0.8449\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.0734 - mean_squared_error: 0.0734 - acc: 0.8461\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.0730 - mean_squared_error: 0.0730 - acc: 0.8442\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.0726 - mean_squared_error: 0.0726 - acc: 0.8491\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 102us/step - loss: 0.0712 - mean_squared_error: 0.0712 - acc: 0.8522\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 91us/step - loss: 0.0714 - mean_squared_error: 0.0714 - acc: 0.8486\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.0713 - mean_squared_error: 0.0713 - acc: 0.8507\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.0708 - mean_squared_error: 0.0708 - acc: 0.8522\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 95us/step - loss: 0.0692 - mean_squared_error: 0.0692 - acc: 0.8566\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 96us/step - loss: 0.0700 - mean_squared_error: 0.0700 - acc: 0.8512\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0711 - mean_squared_error: 0.0711 - acc: 0.8506\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.0728 - mean_squared_error: 0.0728 - acc: 0.8460\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0692 - mean_squared_error: 0.0692 - acc: 0.8535\n",
      "2526/2526 [==============================] - 0s 58us/step\n",
      "8083/8083 [==============================] - 0s 43us/step\n",
      "2526/2526 [==============================] - 0s 49us/step\n",
      "8083/8083 [==============================] - 0s 54us/step\n",
      "The Score is 0.975059\n",
      "current iteration fraction: 0.700000\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 2s 259us/step - loss: 0.2434 - mean_squared_error: 0.2434 - acc: 0.3464\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2189 - mean_squared_error: 0.2189 - acc: 0.41350s - loss: 0.2217 - mean_squared_error: 0.2217 - acc - ETA: 0s - loss: 0.2206 - mean_squared_error: 0.2206 - a\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.2000 - mean_squared_error: 0.2000 - acc: 0.5059\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1818 - mean_squared_error: 0.1818 - acc: 0.5686\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 89us/step - loss: 0.1713 - mean_squared_error: 0.1713 - acc: 0.6003\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - 1s 85us/step - loss: 0.1681 - mean_squared_error: 0.1681 - acc: 0.6158\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 1s 86us/step - loss: 0.1625 - mean_squared_error: 0.1625 - acc: 0.6305\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1607 - mean_squared_error: 0.1607 - acc: 0.6393\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1587 - mean_squared_error: 0.1587 - acc: 0.6373\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1577 - mean_squared_error: 0.1577 - acc: 0.6452\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1555 - mean_squared_error: 0.1555 - acc: 0.64380s - loss: 0.1578 - mean_squared_error\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1555 - mean_squared_error: 0.1555 - acc: 0.6431\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1547 - mean_squared_error: 0.1547 - acc: 0.6466\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1532 - mean_squared_error: 0.1532 - acc: 0.64830s - loss: 0.1527 - mean_squared_error: 0.1527 - acc: 0.\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1524 - mean_squared_error: 0.1524 - acc: 0.6482\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.1534 - mean_squared_error: 0.1534 - acc: 0.6499\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1521 - mean_squared_error: 0.1521 - acc: 0.6529\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.1524 - mean_squared_error: 0.1524 - acc: 0.6490\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1514 - mean_squared_error: 0.1514 - acc: 0.6541\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1515 - mean_squared_error: 0.1515 - acc: 0.65120s - loss: 0.1505 - mean_squared_error: 0.\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 91us/step - loss: 0.1506 - mean_squared_error: 0.1506 - acc: 0.6514\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1513 - mean_squared_error: 0.1513 - acc: 0.6521\n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.65 - 1s 102us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6531\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1506 - mean_squared_error: 0.1506 - acc: 0.6537\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1506 - mean_squared_error: 0.1506 - acc: 0.6521\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6530\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1505 - mean_squared_error: 0.1505 - acc: 0.6534\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6543\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.1507 - mean_squared_error: 0.1507 - acc: 0.6534\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1492 - mean_squared_error: 0.1492 - acc: 0.65370s - loss: 0.1507 - mean_squared_error: 0.1507 - acc: 0. - ETA: 0s - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.65\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.65270s - loss: 0.1500 - mean_squared_error: 0.1500 - acc: \n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6526\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6526\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.6529\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - 1s 160us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6536\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.1497 - mean_squared_error: 0.1497 - acc: 0.6534\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6540\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6546\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1497 - mean_squared_error: 0.1497 - acc: 0.6534\n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.65270s - loss: 0.1497 - mean_squared_error: 0.1497 - acc: 0.65\n",
      "Epoch 41/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1496 - mean_squared_error: 0.1496 - acc: 0.6533\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6533\n",
      "Epoch 43/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.1496 - mean_squared_error: 0.1496 - acc: 0.6534\n",
      "Epoch 44/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6530\n",
      "Epoch 45/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6533\n",
      "Epoch 46/300\n",
      "7072/7072 [==============================] - 2s 229us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.65440s - loss: 0.1487 - mean_squared_error: 0.1487 - acc: \n",
      "Epoch 47/300\n",
      "7072/7072 [==============================] - 1s 172us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.65341s - loss: 0.1480 - mean_s\n",
      "Epoch 48/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6537\n",
      "Epoch 49/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6523\n",
      "Epoch 50/300\n",
      "7072/7072 [==============================] - 2s 285us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.65330s - loss: 0.1499 - mean\n",
      "Epoch 51/300\n",
      "7072/7072 [==============================] - 5s 641us/step - loss: 0.1493 - mean_squared_error: 0.1493 - acc: 0.6540: 0s - loss: 0.1496 - mean_squared_error: 0.1496 - acc\n",
      "Epoch 52/300\n",
      "7072/7072 [==============================] - 2s 332us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6533\n",
      "Epoch 53/300\n",
      "7072/7072 [==============================] - 2s 259us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6526\n",
      "Epoch 54/300\n",
      "7072/7072 [==============================] - 2s 291us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6530\n",
      "Epoch 55/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1493 - mean_squared_error: 0.1493 - acc: 0.6533\n",
      "Epoch 56/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1492 - mean_squared_error: 0.1492 - acc: 0.6530\n",
      "Epoch 57/300\n",
      "7072/7072 [==============================] - 1s 183us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6536\n",
      "Epoch 58/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6534\n",
      "Epoch 59/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1477 - mean_squared_error: 0.1477 - acc: 0.6536\n",
      "Epoch 60/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1483 - mean_squared_error: 0.1483 - acc: 0.6529\n",
      "Epoch 61/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6530\n",
      "Epoch 62/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.6534\n",
      "Epoch 63/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1482 - mean_squared_error: 0.1482 - acc: 0.6538\n",
      "Epoch 64/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6553\n",
      "Epoch 65/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6543\n",
      "Epoch 66/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6555\n",
      "Epoch 67/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6543\n",
      "Epoch 68/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.6537\n",
      "Epoch 69/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.1475 - mean_squared_error: 0.1475 - acc: 0.6546\n",
      "Epoch 70/300\n",
      "7072/7072 [==============================] - 1s 159us/step - loss: 0.1473 - mean_squared_error: 0.1473 - acc: 0.65470s - loss: 0.1476 - mean_squared_error: 0.1476 - acc: 0.\n",
      "Epoch 71/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1470 - mean_squared_error: 0.1470 - acc: 0.6548\n",
      "Epoch 72/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1475 - mean_squared_error: 0.1475 - acc: 0.6541\n",
      "Epoch 73/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6575\n",
      "Epoch 74/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.6550\n",
      "Epoch 75/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1470 - mean_squared_error: 0.1470 - acc: 0.6541\n",
      "Epoch 76/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.1476 - mean_squared_error: 0.1476 - acc: 0.6540\n",
      "Epoch 77/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.1472 - mean_squared_error: 0.1472 - acc: 0.6533\n",
      "Epoch 78/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1470 - mean_squared_error: 0.1470 - acc: 0.6564\n",
      "Epoch 79/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1465 - mean_squared_error: 0.1465 - acc: 0.6537 0s - loss: 0.1459 - mean_squared_error: \n",
      "Epoch 80/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.1465 - mean_squared_error: 0.1465 - acc: 0.6564\n",
      "Epoch 81/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6588 0s - loss: 0.1459 - mean_squared_error: 0.1459 - acc: 0.\n",
      "Epoch 82/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.1464 - mean_squared_error: 0.1464 - acc: 0.6575 0s - loss: 0.1483 - mean_squared_err\n",
      "Epoch 83/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6601\n",
      "Epoch 84/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1459 - mean_squared_error: 0.1459 - acc: 0.6581\n",
      "Epoch 85/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6567\n",
      "Epoch 86/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1463 - mean_squared_error: 0.1463 - acc: 0.6558 0s - loss: 0.1471 - mean_squared_error: 0.1471 - acc: \n",
      "Epoch 87/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.1458 - mean_squared_error: 0.1458 - acc: 0.6572\n",
      "Epoch 88/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1457 - mean_squared_error: 0.1457 - acc: 0.6598\n",
      "Epoch 89/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1463 - mean_squared_error: 0.1463 - acc: 0.6602\n",
      "Epoch 90/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1451 - mean_squared_error: 0.1451 - acc: 0.6579\n",
      "Epoch 91/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6613 0s - loss: 0.1540 - mean_squared_e\n",
      "Epoch 92/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.1451 - mean_squared_error: 0.1451 - acc: 0.6588\n",
      "Epoch 93/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1444 - mean_squared_error: 0.1444 - acc: 0.6632\n",
      "Epoch 94/300\n",
      "7072/7072 [==============================] - 1s 95us/step - loss: 0.1437 - mean_squared_error: 0.1437 - acc: 0.6636\n",
      "Epoch 95/300\n",
      "7072/7072 [==============================] - 1s 94us/step - loss: 0.1438 - mean_squared_error: 0.1438 - acc: 0.6645\n",
      "Epoch 96/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1441 - mean_squared_error: 0.1441 - acc: 0.6657\n",
      "Epoch 97/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1444 - mean_squared_error: 0.1444 - acc: 0.6667\n",
      "Epoch 98/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1449 - mean_squared_error: 0.1449 - acc: 0.6669\n",
      "Epoch 99/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.1435 - mean_squared_error: 0.1435 - acc: 0.6661\n",
      "Epoch 100/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1437 - mean_squared_error: 0.1437 - acc: 0.6653\n",
      "Epoch 101/300\n",
      "7072/7072 [==============================] - 1s 203us/step - loss: 0.1443 - mean_squared_error: 0.1443 - acc: 0.6663\n",
      "Epoch 102/300\n",
      "7072/7072 [==============================] - 1s 167us/step - loss: 0.1435 - mean_squared_error: 0.1435 - acc: 0.6708\n",
      "Epoch 103/300\n",
      "7072/7072 [==============================] - 1s 195us/step - loss: 0.1428 - mean_squared_error: 0.1428 - acc: 0.66700s - loss: 0.1424 - mean_squared_error: 0.1424 - acc: 0.66 - ETA: 0s - loss: 0.1426 - mean_squared_error: 0.1426 - acc: 0.66\n",
      "Epoch 104/300\n",
      "7072/7072 [==============================] - 1s 156us/step - loss: 0.1431 - mean_squared_error: 0.1431 - acc: 0.6686\n",
      "Epoch 105/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.1421 - mean_squared_error: 0.1421 - acc: 0.6712\n",
      "Epoch 106/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.1423 - mean_squared_error: 0.1423 - acc: 0.6773\n",
      "Epoch 107/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1416 - mean_squared_error: 0.1416 - acc: 0.6743\n",
      "Epoch 108/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1410 - mean_squared_error: 0.1410 - acc: 0.6766\n",
      "Epoch 109/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.1420 - mean_squared_error: 0.1420 - acc: 0.6770\n",
      "Epoch 110/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.6792\n",
      "Epoch 111/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1415 - mean_squared_error: 0.1415 - acc: 0.6760\n",
      "Epoch 112/300\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.6804\n",
      "Epoch 113/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.1406 - mean_squared_error: 0.1406 - acc: 0.6794\n",
      "Epoch 114/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.1413 - mean_squared_error: 0.1413 - acc: 0.6783\n",
      "Epoch 115/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1398 - mean_squared_error: 0.1398 - acc: 0.6770\n",
      "Epoch 116/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1389 - mean_squared_error: 0.1389 - acc: 0.68300s - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.65 - ETA: 0s - loss: 0.1456 - mean_squar\n",
      "Epoch 117/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1380 - mean_squared_error: 0.1380 - acc: 0.6875\n",
      "Epoch 118/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1392 - mean_squared_error: 0.1392 - acc: 0.68830s - loss: 0.1390 - mean_squared_error: 0.1390 - acc - ETA: 0s - loss: 0.1382 - mean_squared_err\n",
      "Epoch 119/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1388 - mean_squared_error: 0.1388 - acc: 0.6833\n",
      "Epoch 120/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.6852\n",
      "Epoch 121/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1395 - mean_squared_error: 0.1395 - acc: 0.6840\n",
      "Epoch 122/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1373 - mean_squared_error: 0.1373 - acc: 0.6913\n",
      "Epoch 123/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1390 - mean_squared_error: 0.1390 - acc: 0.6797\n",
      "Epoch 124/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1379 - mean_squared_error: 0.1379 - acc: 0.6838\n",
      "Epoch 125/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1379 - mean_squared_error: 0.1379 - acc: 0.6902\n",
      "Epoch 126/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.1378 - mean_squared_error: 0.1378 - acc: 0.6889\n",
      "Epoch 127/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1367 - mean_squared_error: 0.1367 - acc: 0.6834\n",
      "Epoch 128/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.1368 - mean_squared_error: 0.1368 - acc: 0.6861\n",
      "Epoch 129/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1347 - mean_squared_error: 0.1347 - acc: 0.6956\n",
      "Epoch 130/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1354 - mean_squared_error: 0.1354 - acc: 0.6923\n",
      "Epoch 131/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1347 - mean_squared_error: 0.1347 - acc: 0.7001\n",
      "Epoch 132/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.1347 - mean_squared_error: 0.1347 - acc: 0.6920\n",
      "Epoch 133/300\n",
      "7072/7072 [==============================] - 2s 226us/step - loss: 0.1350 - mean_squared_error: 0.1350 - acc: 0.6975\n",
      "Epoch 134/300\n",
      "7072/7072 [==============================] - 1s 156us/step - loss: 0.1337 - mean_squared_error: 0.1337 - acc: 0.68690s - loss: 0.1339 - mean_squared_error: 0.1339\n",
      "Epoch 135/300\n",
      "7072/7072 [==============================] - 2s 278us/step - loss: 0.1326 - mean_squared_error: 0.1326 - acc: 0.7063\n",
      "Epoch 136/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.1335 - mean_squared_error: 0.1335 - acc: 0.6974\n",
      "Epoch 137/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1331 - mean_squared_error: 0.1331 - acc: 0.6985\n",
      "Epoch 138/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.1321 - mean_squared_error: 0.1321 - acc: 0.7087\n",
      "Epoch 139/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1298 - mean_squared_error: 0.1298 - acc: 0.7103\n",
      "Epoch 140/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1294 - mean_squared_error: 0.1294 - acc: 0.7131\n",
      "Epoch 141/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1308 - mean_squared_error: 0.1308 - acc: 0.7124\n",
      "Epoch 142/300\n",
      "7072/7072 [==============================] - 2s 286us/step - loss: 0.1270 - mean_squared_error: 0.1270 - acc: 0.7185\n",
      "Epoch 143/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1305 - mean_squared_error: 0.1305 - acc: 0.7086\n",
      "Epoch 144/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1297 - mean_squared_error: 0.1297 - acc: 0.7203\n",
      "Epoch 145/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1285 - mean_squared_error: 0.1285 - acc: 0.7183\n",
      "Epoch 146/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.1287 - mean_squared_error: 0.1287 - acc: 0.7120\n",
      "Epoch 147/300\n",
      "7072/7072 [==============================] - 5s 700us/step - loss: 0.1281 - mean_squared_error: 0.1281 - acc: 0.7213TA: 0s - loss: 0.1284 - mean_squared_error: 0.1284 - acc - ETA: 0s - loss: 0.1284 - mean\n",
      "Epoch 148/300\n",
      "7072/7072 [==============================] - 6s 821us/step - loss: 0.1282 - mean_squared_error: 0.1282 - acc: 0.71356s - loss: 0.1236 - mean_squared_error: 0.1236 - ETA - ETA: 3s - loss: 0.1268 - mean_squared_error: 0.1268 - acc: 0. - ETA:  - ETA: 0s - loss: 0.1283 - mean_squared_error: 0.1283 - acc\n",
      "Epoch 149/300\n",
      "7072/7072 [==============================] - 1s 161us/step - loss: 0.1270 - mean_squared_error: 0.1270 - acc: 0.72442s - loss: 0.1341 \n",
      "Epoch 150/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1263 - mean_squared_error: 0.1263 - acc: 0.7250\n",
      "Epoch 151/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1243 - mean_squared_error: 0.1243 - acc: 0.7227\n",
      "Epoch 152/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1261 - mean_squared_error: 0.1261 - acc: 0.7180\n",
      "Epoch 153/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1229 - mean_squared_error: 0.1229 - acc: 0.7301\n",
      "Epoch 154/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1241 - mean_squared_error: 0.1241 - acc: 0.7320\n",
      "Epoch 155/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1238 - mean_squared_error: 0.1238 - acc: 0.7255\n",
      "Epoch 156/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1217 - mean_squared_error: 0.1217 - acc: 0.7322\n",
      "Epoch 157/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1209 - mean_squared_error: 0.1209 - acc: 0.7342\n",
      "Epoch 158/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1211 - mean_squared_error: 0.1211 - acc: 0.73270s - loss: 0.1199 - mean_squ\n",
      "Epoch 159/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1214 - mean_squared_error: 0.1214 - acc: 0.7339\n",
      "Epoch 160/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1218 - mean_squared_error: 0.1218 - acc: 0.7370\n",
      "Epoch 161/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.1197 - mean_squared_error: 0.1197 - acc: 0.7390\n",
      "Epoch 162/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1195 - mean_squared_error: 0.1195 - acc: 0.73 - 1s 132us/step - loss: 0.1192 - mean_squared_error: 0.1192 - acc: 0.7367\n",
      "Epoch 163/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1189 - mean_squared_error: 0.1189 - acc: 0.7404\n",
      "Epoch 164/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1194 - mean_squared_error: 0.1194 - acc: 0.7350\n",
      "Epoch 165/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1193 - mean_squared_error: 0.1193 - acc: 0.7394\n",
      "Epoch 166/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1171 - mean_squared_error: 0.1171 - acc: 0.7514\n",
      "Epoch 167/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.1152 - mean_squared_error: 0.1152 - acc: 0.7542\n",
      "Epoch 168/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.1149 - mean_squared_error: 0.1149 - acc: 0.7527\n",
      "Epoch 169/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.1133 - mean_squared_error: 0.1133 - acc: 0.7582\n",
      "Epoch 170/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.1137 - mean_squared_error: 0.1137 - acc: 0.7564\n",
      "Epoch 171/300\n",
      "7072/7072 [==============================] - 1s 158us/step - loss: 0.1143 - mean_squared_error: 0.1143 - acc: 0.7514\n",
      "Epoch 172/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.1120 - mean_squared_error: 0.1120 - acc: 0.76240s - loss: 0.1121 - mean_squared_error: 0.1121 - acc: \n",
      "Epoch 173/300\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.1132 - mean_squared_error: 0.1132 - acc: 0.7571\n",
      "Epoch 174/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.1139 - mean_squared_error: 0.1139 - acc: 0.7548\n",
      "Epoch 175/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.1150 - mean_squared_error: 0.1150 - acc: 0.7559\n",
      "Epoch 176/300\n",
      "7072/7072 [==============================] - 1s 155us/step - loss: 0.1096 - mean_squared_error: 0.1096 - acc: 0.7691\n",
      "Epoch 177/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.1100 - mean_squared_error: 0.1100 - acc: 0.7640\n",
      "Epoch 178/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.1138 - mean_squared_error: 0.1138 - acc: 0.75240s - loss: 0.1137 - mean_squared_error: 0.1137 - acc: 0.75\n",
      "Epoch 179/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.1098 - mean_squared_error: 0.1098 - acc: 0.76631s - loss: 0.1191 - mean_squ\n",
      "Epoch 180/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.1109 - mean_squared_error: 0.1109 - acc: 0.7609\n",
      "Epoch 181/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.1109 - mean_squared_error: 0.1109 - acc: 0.7651\n",
      "Epoch 182/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1088 - mean_squared_error: 0.1088 - acc: 0.7640\n",
      "Epoch 183/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.1090 - mean_squared_error: 0.1090 - acc: 0.7660\n",
      "Epoch 184/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1073 - mean_squared_error: 0.1073 - acc: 0.7694\n",
      "Epoch 185/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1086 - mean_squared_error: 0.1086 - acc: 0.7689\n",
      "Epoch 186/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.1078 - mean_squared_error: 0.1078 - acc: 0.7712\n",
      "Epoch 187/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1050 - mean_squared_error: 0.1050 - acc: 0.7794\n",
      "Epoch 188/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1056 - mean_squared_error: 0.1056 - acc: 0.77111s - loss: 0.1047 - mean_squ\n",
      "Epoch 189/300\n",
      "7072/7072 [==============================] - 1s 155us/step - loss: 0.1063 - mean_squared_error: 0.1063 - acc: 0.7688\n",
      "Epoch 190/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1048 - mean_squared_error: 0.1048 - acc: 0.7801\n",
      "Epoch 191/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1037 - mean_squared_error: 0.1037 - acc: 0.7759\n",
      "Epoch 192/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1048 - mean_squared_error: 0.1048 - acc: 0.7757\n",
      "Epoch 193/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1027 - mean_squared_error: 0.1027 - acc: 0.7807\n",
      "Epoch 194/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1043 - mean_squared_error: 0.1043 - acc: 0.7780\n",
      "Epoch 195/300\n",
      "7072/7072 [==============================] - 1s 173us/step - loss: 0.1045 - mean_squared_error: 0.1045 - acc: 0.7714\n",
      "Epoch 196/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1034 - mean_squared_error: 0.1034 - acc: 0.7796\n",
      "Epoch 197/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1011 - mean_squared_error: 0.1011 - acc: 0.7824\n",
      "Epoch 198/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.1014 - mean_squared_error: 0.1014 - acc: 0.7873\n",
      "Epoch 199/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1019 - mean_squared_error: 0.1019 - acc: 0.78100s - loss: 0.1041 - mean_squared_error: 0.\n",
      "Epoch 200/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1025 - mean_squared_error: 0.1025 - acc: 0.7837\n",
      "Epoch 201/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.0988 - mean_squared_error: 0.0988 - acc: 0.7903\n",
      "Epoch 202/300\n",
      "7072/7072 [==============================] - 1s 207us/step - loss: 0.1013 - mean_squared_error: 0.1013 - acc: 0.7808\n",
      "Epoch 203/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.0999 - mean_squared_error: 0.0999 - acc: 0.7886\n",
      "Epoch 204/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.1004 - mean_squared_error: 0.1004 - acc: 0.7855\n",
      "Epoch 205/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.1003 - mean_squared_error: 0.1003 - acc: 0.7870\n",
      "Epoch 206/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.0977 - mean_squared_error: 0.0977 - acc: 0.79270s - loss: 0.0985 - mean_squared_error: \n",
      "Epoch 207/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1003 - mean_squared_error: 0.1003 - acc: 0.7865\n",
      "Epoch 208/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0994 - mean_squared_error: 0.0994 - acc: 0.7824\n",
      "Epoch 209/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.0952 - mean_squared_error: 0.0952 - acc: 0.79680s - loss: 0.0955 - mean_squared_error: 0.0955 -\n",
      "Epoch 210/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.0989 - mean_squared_error: 0.0989 - acc: 0.7909\n",
      "Epoch 211/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0974 - mean_squared_error: 0.0974 - acc: 0.7910\n",
      "Epoch 212/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0949 - mean_squared_error: 0.0949 - acc: 0.8029\n",
      "Epoch 213/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.0960 - mean_squared_error: 0.0960 - acc: 0.8003\n",
      "Epoch 214/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0962 - mean_squared_error: 0.0962 - acc: 0.7936\n",
      "Epoch 215/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0980 - mean_squared_error: 0.0980 - acc: 0.7886\n",
      "Epoch 216/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.0944 - mean_squared_error: 0.0944 - acc: 0.8022\n",
      "Epoch 217/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.0941 - mean_squared_error: 0.0941 - acc: 0.8039\n",
      "Epoch 218/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0967 - mean_squared_error: 0.0967 - acc: 0.79410s - loss: 0.0979 - mean_squared_error: \n",
      "Epoch 219/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0939 - mean_squared_error: 0.0939 - acc: 0.8032\n",
      "Epoch 220/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0959 - mean_squared_error: 0.0959 - acc: 0.7962\n",
      "Epoch 221/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0951 - mean_squared_error: 0.0951 - acc: 0.80090s - loss: 0.0944 - mean_squared\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0931 - mean_squared_error: 0.0931 - acc: 0.8053\n",
      "Epoch 223/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0969 - mean_squared_error: 0.0969 - acc: 0.7909\n",
      "Epoch 224/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0934 - mean_squared_error: 0.0934 - acc: 0.8057\n",
      "Epoch 225/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0916 - mean_squared_error: 0.0916 - acc: 0.8050\n",
      "Epoch 226/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.0935 - mean_squared_error: 0.0935 - acc: 0.8010\n",
      "Epoch 227/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.0928 - mean_squared_error: 0.0928 - acc: 0.8025\n",
      "Epoch 228/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0920 - mean_squared_error: 0.0920 - acc: 0.8071\n",
      "Epoch 229/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0894 - mean_squared_error: 0.0894 - acc: 0.8094\n",
      "Epoch 230/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0931 - mean_squared_error: 0.0931 - acc: 0.8019\n",
      "Epoch 231/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0892 - mean_squared_error: 0.0892 - acc: 0.8109\n",
      "Epoch 232/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0932 - mean_squared_error: 0.0932 - acc: 0.8042\n",
      "Epoch 233/300\n",
      "7072/7072 [==============================] - 1s 193us/step - loss: 0.0893 - mean_squared_error: 0.0893 - acc: 0.8152\n",
      "Epoch 234/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.0897 - mean_squared_error: 0.0897 - acc: 0.8107\n",
      "Epoch 235/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0901 - mean_squared_error: 0.0901 - acc: 0.8080\n",
      "Epoch 236/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0905 - mean_squared_error: 0.0905 - acc: 0.8070\n",
      "Epoch 237/300\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.0881 - mean_squared_error: 0.0881 - acc: 0.8150\n",
      "Epoch 238/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0880 - mean_squared_error: 0.0880 - acc: 0.8166\n",
      "Epoch 239/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0891 - mean_squared_error: 0.0891 - acc: 0.8136\n",
      "Epoch 240/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0891 - mean_squared_error: 0.0891 - acc: 0.8146\n",
      "Epoch 241/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.0866 - mean_squared_error: 0.0866 - acc: 0.81480s - loss: 0.0874 - mean_squar\n",
      "Epoch 242/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0864 - mean_squared_error: 0.0864 - acc: 0.8172\n",
      "Epoch 243/300\n",
      "7072/7072 [==============================] - 1s 155us/step - loss: 0.0890 - mean_squared_error: 0.0890 - acc: 0.8167\n",
      "Epoch 244/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.0863 - mean_squared_error: 0.0863 - acc: 0.8173\n",
      "Epoch 245/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0872 - mean_squared_error: 0.0872 - acc: 0.8133\n",
      "Epoch 246/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0873 - mean_squared_error: 0.0873 - acc: 0.8165\n",
      "Epoch 247/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0857 - mean_squared_error: 0.0857 - acc: 0.8183\n",
      "Epoch 248/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0864 - mean_squared_error: 0.0864 - acc: 0.8172\n",
      "Epoch 249/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0857 - mean_squared_error: 0.0857 - acc: 0.82081s - loss: 0.0885 - mean_squared\n",
      "Epoch 250/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.0863 - mean_squared_error: 0.0863 - acc: 0.81790s - loss: 0.0856 - mean_squared\n",
      "Epoch 251/300\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.0845 - mean_squared_error: 0.0845 - acc: 0.8237\n",
      "Epoch 252/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.0865 - mean_squared_error: 0.0865 - acc: 0.8174\n",
      "Epoch 253/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0849 - mean_squared_error: 0.0849 - acc: 0.8197\n",
      "Epoch 254/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0850 - mean_squared_error: 0.0850 - acc: 0.8215\n",
      "Epoch 255/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0840 - mean_squared_error: 0.0840 - acc: 0.8249\n",
      "Epoch 256/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0862 - mean_squared_error: 0.0862 - acc: 0.8153\n",
      "Epoch 257/300\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.0844 - mean_squared_error: 0.0844 - acc: 0.8228\n",
      "Epoch 258/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.0825 - mean_squared_error: 0.0825 - acc: 0.82650s - loss: 0.0804 - mean_squared_error: \n",
      "Epoch 259/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.0802 - mean_squared_error: 0.0802 - acc: 0.83360s - loss: 0.0812 - mean_squared_error: 0.0812 - a\n",
      "Epoch 260/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.0833 - mean_squared_error: 0.0833 - acc: 0.8221\n",
      "Epoch 261/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.0851 - mean_squared_error: 0.0851 - acc: 0.8194\n",
      "Epoch 262/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.0856 - mean_squared_error: 0.0856 - acc: 0.8186\n",
      "Epoch 263/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.0809 - mean_squared_error: 0.0809 - acc: 0.8296\n",
      "Epoch 264/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0822 - mean_squared_error: 0.0822 - acc: 0.8265\n",
      "Epoch 265/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.0811 - mean_squared_error: 0.0811 - acc: 0.8312\n",
      "Epoch 266/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.0805 - mean_squared_error: 0.0805 - acc: 0.83130s - loss: 0.0801 - mean_squared_error: 0.0801 - acc\n",
      "Epoch 267/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.0819 - mean_squared_error: 0.0819 - acc: 0.8296\n",
      "Epoch 268/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0809 - mean_squared_error: 0.0809 - acc: 0.8279\n",
      "Epoch 269/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.0807 - mean_squared_error: 0.0807 - acc: 0.8307\n",
      "Epoch 270/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0795 - mean_squared_error: 0.0795 - acc: 0.8358\n",
      "Epoch 271/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.0799 - mean_squared_error: 0.0799 - acc: 0.8354\n",
      "Epoch 272/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.0795 - mean_squared_error: 0.0795 - acc: 0.8350\n",
      "Epoch 273/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.0807 - mean_squared_error: 0.0807 - acc: 0.8313\n",
      "Epoch 274/300\n",
      "7072/7072 [==============================] - 4s 525us/step - loss: 0.0784 - mean_squared_error: 0.0784 - acc: 0.83672s - loss: 0.0818 - mean_squared - E\n",
      "Epoch 275/300\n",
      "7072/7072 [==============================] - 4s 521us/step - loss: 0.0781 - mean_squared_error: 0.0781 - acc: 0.83822s - loss: 0.0776 - mean_squared_error: 0.0776 - acc - ETA: 2s - loss: 0.0786 - mean_squared_error: 0.0786 - acc: \n",
      "Epoch 276/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.0793 - mean_squared_error: 0.0793 - acc: 0.8350\n",
      "Epoch 277/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.0793 - mean_squared_error: 0.0793 - acc: 0.8354\n",
      "Epoch 278/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0776 - mean_squared_error: 0.0776 - acc: 0.8360\n",
      "Epoch 279/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0793 - mean_squared_error: 0.0793 - acc: 0.8320\n",
      "Epoch 280/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.0797 - mean_squared_error: 0.0797 - acc: 0.8367\n",
      "Epoch 281/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.0798 - mean_squared_error: 0.0798 - acc: 0.8310\n",
      "Epoch 282/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0795 - mean_squared_error: 0.0795 - acc: 0.8316\n",
      "Epoch 283/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.0789 - mean_squared_error: 0.0789 - acc: 0.8353\n",
      "Epoch 284/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.0793 - mean_squared_error: 0.0793 - acc: 0.8322\n",
      "Epoch 285/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.0766 - mean_squared_error: 0.0766 - acc: 0.8401\n",
      "Epoch 286/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.0744 - mean_squared_error: 0.0744 - acc: 0.84690s - loss: 0.0743 - mean_squ\n",
      "Epoch 287/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.0769 - mean_squared_error: 0.0769 - acc: 0.8381\n",
      "Epoch 288/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0755 - mean_squared_error: 0.0755 - acc: 0.8395\n",
      "Epoch 289/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.0772 - mean_squared_error: 0.0772 - acc: 0.8354\n",
      "Epoch 290/300\n",
      "7072/7072 [==============================] - 1s 193us/step - loss: 0.0761 - mean_squared_error: 0.0761 - acc: 0.8412\n",
      "Epoch 291/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.0759 - mean_squared_error: 0.0759 - acc: 0.84020s - loss: 0.0672 - mean_squ\n",
      "Epoch 292/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.0739 - mean_squared_error: 0.0739 - acc: 0.8445\n",
      "Epoch 293/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.0771 - mean_squared_error: 0.0771 - acc: 0.84160s - loss: 0.0780 - mean_squared_error: 0.\n",
      "Epoch 294/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.0736 - mean_squared_error: 0.0736 - acc: 0.8487\n",
      "Epoch 295/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0756 - mean_squared_error: 0.0756 - acc: 0.8384\n",
      "Epoch 296/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0734 - mean_squared_error: 0.0734 - acc: 0.8438\n",
      "Epoch 297/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.0749 - mean_squared_error: 0.0749 - acc: 0.8412 0s - loss: 0.0751 - mean_squared_error: 0.0751 - acc\n",
      "Epoch 298/300\n",
      "7072/7072 [==============================] - 1s 96us/step - loss: 0.0758 - mean_squared_error: 0.0758 - acc: 0.8367\n",
      "Epoch 299/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.0765 - mean_squared_error: 0.0765 - acc: 0.8398\n",
      "Epoch 300/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.0721 - mean_squared_error: 0.0721 - acc: 0.8493\n",
      "2526/2526 [==============================] - 0s 189us/step\n",
      "7072/7072 [==============================] - 0s 61us/step\n",
      "The Score is 0.960412\n",
      "current iteration fraction: 0.600000\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(6062, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "6062/6062 [==============================] - 2s 313us/step - loss: 0.2434 - mean_squared_error: 0.2434 - acc: 0.3596\n",
      "Epoch 2/300\n",
      "6062/6062 [==============================] - 1s 154us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.4056\n",
      "Epoch 3/300\n",
      "6062/6062 [==============================] - 1s 158us/step - loss: 0.2058 - mean_squared_error: 0.2058 - acc: 0.48560s - loss: 0.2072 - mean_squared_error: 0.2072 - acc: 0.\n",
      "Epoch 4/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.1896 - mean_squared_error: 0.1896 - acc: 0.53 - 1s 129us/step - loss: 0.1895 - mean_squared_error: 0.1895 - acc: 0.5383\n",
      "Epoch 5/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.1783 - mean_squared_error: 0.1783 - acc: 0.5818\n",
      "Epoch 6/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.1712 - mean_squared_error: 0.1712 - acc: 0.6054\n",
      "Epoch 7/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.1671 - mean_squared_error: 0.1671 - acc: 0.6130\n",
      "Epoch 8/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.1640 - mean_squared_error: 0.1640 - acc: 0.6239\n",
      "Epoch 9/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.1626 - mean_squared_error: 0.1626 - acc: 0.6234\n",
      "Epoch 10/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.1603 - mean_squared_error: 0.1603 - acc: 0.6303\n",
      "Epoch 11/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.1595 - mean_squared_error: 0.1595 - acc: 0.63 - 1s 102us/step - loss: 0.1601 - mean_squared_error: 0.1601 - acc: 0.6336\n",
      "Epoch 12/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.1579 - mean_squared_error: 0.1579 - acc: 0.6348\n",
      "Epoch 13/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.1563 - mean_squared_error: 0.1563 - acc: 0.63920s - loss: 0.1566 - mean_squared_error: 0.1566 - acc: 0.63\n",
      "Epoch 14/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.1570 - mean_squared_error: 0.1570 - acc: 0.64370s - loss: 0.1572 - mean_squared_error: 0.1572 - acc: 0.64\n",
      "Epoch 15/300\n",
      "6062/6062 [==============================] - 1s 175us/step - loss: 0.1557 - mean_squared_error: 0.1557 - acc: 0.6425\n",
      "Epoch 16/300\n",
      "6062/6062 [==============================] - 1s 171us/step - loss: 0.1546 - mean_squared_error: 0.1546 - acc: 0.6483\n",
      "Epoch 17/300\n",
      "6062/6062 [==============================] - 1s 165us/step - loss: 0.1537 - mean_squared_error: 0.1537 - acc: 0.6447\n",
      "Epoch 18/300\n",
      "6062/6062 [==============================] - 1s 153us/step - loss: 0.1523 - mean_squared_error: 0.1523 - acc: 0.6496\n",
      "Epoch 19/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.1522 - mean_squared_error: 0.1522 - acc: 0.6496\n",
      "Epoch 20/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.1526 - mean_squared_error: 0.1526 - acc: 0.6480\n",
      "Epoch 21/300\n",
      "6062/6062 [==============================] - 1s 153us/step - loss: 0.1525 - mean_squared_error: 0.1525 - acc: 0.6448\n",
      "Epoch 22/300\n",
      "6062/6062 [==============================] - 1s 141us/step - loss: 0.1521 - mean_squared_error: 0.1521 - acc: 0.6476\n",
      "Epoch 23/300\n",
      "6062/6062 [==============================] - 1s 172us/step - loss: 0.1525 - mean_squared_error: 0.1525 - acc: 0.6467\n",
      "Epoch 24/300\n",
      "6062/6062 [==============================] - 1s 140us/step - loss: 0.1515 - mean_squared_error: 0.1515 - acc: 0.64800s - loss: 0.1532 - mean_squ\n",
      "Epoch 25/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.1519 - mean_squared_error: 0.1519 - acc: 0.6488\n",
      "Epoch 26/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.1517 - mean_squared_error: 0.1517 - acc: 0.6475\n",
      "Epoch 27/300\n",
      "6062/6062 [==============================] - 1s 102us/step - loss: 0.1513 - mean_squared_error: 0.1513 - acc: 0.6500\n",
      "Epoch 28/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.1516 - mean_squared_error: 0.1516 - acc: 0.6496\n",
      "Epoch 29/300\n",
      "6062/6062 [==============================] - 1s 155us/step - loss: 0.1502 - mean_squared_error: 0.1502 - acc: 0.6514\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.1508 - mean_squared_error: 0.1508 - acc: 0.6511\n",
      "Epoch 31/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.1509 - mean_squared_error: 0.1509 - acc: 0.65010s - loss: 0.1548 - mean_squared_err\n",
      "Epoch 32/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.1505 - mean_squared_error: 0.1505 - acc: 0.6496\n",
      "Epoch 33/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.1503 - mean_squared_error: 0.1503 - acc: 0.6511\n",
      "Epoch 34/300\n",
      "6062/6062 [==============================] - 1s 145us/step - loss: 0.1503 - mean_squared_error: 0.1503 - acc: 0.6498\n",
      "Epoch 35/300\n",
      "6062/6062 [==============================] - 1s 173us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6509\n",
      "Epoch 36/300\n",
      "6062/6062 [==============================] - 1s 221us/step - loss: 0.1503 - mean_squared_error: 0.1503 - acc: 0.6504\n",
      "Epoch 37/300\n",
      "6062/6062 [==============================] - 1s 154us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6519\n",
      "Epoch 38/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.1495 - mean_squared_error: 0.1495 - acc: 0.6503\n",
      "Epoch 39/300\n",
      "6062/6062 [==============================] - 1s 197us/step - loss: 0.1496 - mean_squared_error: 0.1496 - acc: 0.6523\n",
      "Epoch 40/300\n",
      "6062/6062 [==============================] - 1s 213us/step - loss: 0.1500 - mean_squared_error: 0.1500 - acc: 0.6514\n",
      "Epoch 41/300\n",
      "6062/6062 [==============================] - 1s 232us/step - loss: 0.1502 - mean_squared_error: 0.1502 - acc: 0.6503\n",
      "Epoch 42/300\n",
      "6062/6062 [==============================] - 1s 212us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6511\n",
      "Epoch 43/300\n",
      "6062/6062 [==============================] - 2s 264us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6509\n",
      "Epoch 44/300\n",
      "6062/6062 [==============================] - 1s 218us/step - loss: 0.1499 - mean_squared_error: 0.1499 - acc: 0.65040s - loss: 0.1506 - mean_squared_error: 0.\n",
      "Epoch 45/300\n",
      "6062/6062 [==============================] - 1s 210us/step - loss: 0.1501 - mean_squared_error: 0.1501 - acc: 0.6513\n",
      "Epoch 46/300\n",
      "6062/6062 [==============================] - 1s 145us/step - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.6516\n",
      "Epoch 47/300\n",
      "6062/6062 [==============================] - 1s 148us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6509\n",
      "Epoch 48/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.1497 - mean_squared_error: 0.1497 - acc: 0.6509\n",
      "Epoch 49/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.1497 - mean_squared_error: 0.1497 - acc: 0.6504\n",
      "Epoch 50/300\n",
      "6062/6062 [==============================] - 1s 143us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6506\n",
      "Epoch 51/300\n",
      "6062/6062 [==============================] - 1s 153us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.65210s - loss: 0.1492 - mean_squared_error: \n",
      "Epoch 52/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6511\n",
      "Epoch 53/300\n",
      "6062/6062 [==============================] - 1s 161us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6514\n",
      "Epoch 54/300\n",
      "6062/6062 [==============================] - 2s 324us/step - loss: 0.1488 - mean_squared_error: 0.1488 - acc: 0.6509\n",
      "Epoch 55/300\n",
      "6062/6062 [==============================] - 1s 227us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6513\n",
      "Epoch 56/300\n",
      "6062/6062 [==============================] - 2s 273us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.6509\n",
      "Epoch 57/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.65 - 1s 138us/step - loss: 0.1493 - mean_squared_error: 0.1493 - acc: 0.6509\n",
      "Epoch 58/300\n",
      "6062/6062 [==============================] - 2s 266us/step - loss: 0.1494 - mean_squared_error: 0.1494 - acc: 0.6511\n",
      "Epoch 59/300\n",
      "6062/6062 [==============================] - 1s 221us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6513\n",
      "Epoch 60/300\n",
      "6062/6062 [==============================] - 1s 209us/step - loss: 0.1490 - mean_squared_error: 0.1490 - acc: 0.6518\n",
      "Epoch 61/300\n",
      "6062/6062 [==============================] - 1s 167us/step - loss: 0.1492 - mean_squared_error: 0.1492 - acc: 0.6508\n",
      "Epoch 62/300\n",
      "6062/6062 [==============================] - 1s 164us/step - loss: 0.1488 - mean_squared_error: 0.1488 - acc: 0.6506\n",
      "Epoch 63/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.1487 - mean_squared_error: 0.1487 - acc: 0.6514\n",
      "Epoch 64/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6513\n",
      "Epoch 65/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6511\n",
      "Epoch 66/300\n",
      "6062/6062 [==============================] - 1s 170us/step - loss: 0.1492 - mean_squared_error: 0.1492 - acc: 0.6513\n",
      "Epoch 67/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.1488 - mean_squared_error: 0.1488 - acc: 0.6519\n",
      "Epoch 68/300\n",
      "6062/6062 [==============================] - 1s 132us/step - loss: 0.1485 - mean_squared_error: 0.1485 - acc: 0.6511\n",
      "Epoch 69/300\n",
      "6062/6062 [==============================] - 1s 164us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6509\n",
      "Epoch 70/300\n",
      "6062/6062 [==============================] - 1s 165us/step - loss: 0.1482 - mean_squared_error: 0.1482 - acc: 0.6514\n",
      "Epoch 71/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.1489 - mean_squared_error: 0.1489 - acc: 0.6503\n",
      "Epoch 72/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6503\n",
      "Epoch 73/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6518\n",
      "Epoch 74/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.1477 - mean_squared_error: 0.1477 - acc: 0.6503\n",
      "Epoch 75/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6519\n",
      "Epoch 76/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6519\n",
      "Epoch 77/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.1484 - mean_squared_error: 0.1484 - acc: 0.6523\n",
      "Epoch 78/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.1477 - mean_squared_error: 0.1477 - acc: 0.6541\n",
      "Epoch 79/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.65320s - loss: 0.1511 - mean_squared_e\n",
      "Epoch 80/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.1485 - mean_squared_error: 0.1485 - acc: 0.6514\n",
      "Epoch 81/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.1479 - mean_squared_error: 0.1479 - acc: 0.6534\n",
      "Epoch 82/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.1485 - mean_squared_error: 0.1485 - acc: 0.6504\n",
      "Epoch 83/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.1481 - mean_squared_error: 0.1481 - acc: 0.6519\n",
      "Epoch 84/300\n",
      "6062/6062 [==============================] - 1s 152us/step - loss: 0.1480 - mean_squared_error: 0.1480 - acc: 0.65280s - loss: 0.1473 - mean_squared_e\n",
      "Epoch 85/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.1474 - mean_squared_error: 0.1474 - acc: 0.65230s - loss: 0.1504 - mean_squared_error: \n",
      "Epoch 86/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.1472 - mean_squared_error: 0.1472 - acc: 0.6511\n",
      "Epoch 87/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.1476 - mean_squared_error: 0.1476 - acc: 0.6491\n",
      "Epoch 88/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.1474 - mean_squared_error: 0.1474 - acc: 0.65180s - loss: 0.1474 - mean_squared_error: 0.1474 - ETA: 0s - loss: 0.1488 - mean_squared_error: 0.1488 - a\n",
      "Epoch 89/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.1467 - mean_squared_error: 0.1467 - acc: 0.65410s - loss: 0.1483 - mean_squared_err\n",
      "Epoch 90/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.1469 - mean_squared_error: 0.1469 - acc: 0.6536\n",
      "Epoch 91/300\n",
      "6062/6062 [==============================] - 1s 104us/step - loss: 0.1467 - mean_squared_error: 0.1467 - acc: 0.6546\n",
      "Epoch 92/300\n",
      "6062/6062 [==============================] - 1s 106us/step - loss: 0.1469 - mean_squared_error: 0.1469 - acc: 0.6529\n",
      "Epoch 93/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.1465 - mean_squared_error: 0.1465 - acc: 0.6516\n",
      "Epoch 94/300\n",
      "6062/6062 [==============================] - 1s 103us/step - loss: 0.1457 - mean_squared_error: 0.1457 - acc: 0.6590\n",
      "Epoch 95/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.1468 - mean_squared_error: 0.1468 - acc: 0.6528\n",
      "Epoch 96/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.1456 - mean_squared_error: 0.1456 - acc: 0.6569\n",
      "Epoch 97/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.1464 - mean_squared_error: 0.1464 - acc: 0.6537\n",
      "Epoch 98/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6592\n",
      "Epoch 99/300\n",
      "6062/6062 [==============================] - 1s 105us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6556\n",
      "Epoch 100/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.1460 - mean_squared_error: 0.1460 - acc: 0.6608\n",
      "Epoch 101/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6585\n",
      "Epoch 102/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.1456 - mean_squared_error: 0.1456 - acc: 0.6607\n",
      "Epoch 103/300\n",
      "6062/6062 [==============================] - 1s 153us/step - loss: 0.1464 - mean_squared_error: 0.1464 - acc: 0.6557\n",
      "Epoch 104/300\n",
      "6062/6062 [==============================] - 1s 154us/step - loss: 0.1451 - mean_squared_error: 0.1451 - acc: 0.6592\n",
      "Epoch 105/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.1456 - mean_squared_error: 0.1456 - acc: 0.6584\n",
      "Epoch 106/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.1445 - mean_squared_error: 0.1445 - acc: 0.6638\n",
      "Epoch 107/300\n",
      "6062/6062 [==============================] - 1s 141us/step - loss: 0.1449 - mean_squared_error: 0.1449 - acc: 0.6598\n",
      "Epoch 108/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.1452 - mean_squared_error: 0.1452 - acc: 0.6650\n",
      "Epoch 109/300\n",
      "6062/6062 [==============================] - ETA: 0s - loss: 0.1449 - mean_squared_error: 0.1449 - acc: 0.66 - 1s 167us/step - loss: 0.1450 - mean_squared_error: 0.1450 - acc: 0.6605\n",
      "Epoch 110/300\n",
      "6062/6062 [==============================] - 1s 147us/step - loss: 0.1450 - mean_squared_error: 0.1450 - acc: 0.66030s - loss: 0.1457 - mean_squared_error: 0.14\n",
      "Epoch 111/300\n",
      "4768/6062 [======================>.......] - ETA: 0s - loss: 0.1444 - mean_squared_error: 0.1444 - acc: 0.6623"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5911b5dd34b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwriteDictToCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningCurveIterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsICAK_means.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 3)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetICAK_Means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation Maximizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "ica = FastICA(n_components = 2)\n",
    "ica.fit(X_inputs)\n",
    "X_inputs = ica.transform(X_inputs)\n",
    "\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X_inputs)\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 3s 363us/step - loss: 0.2319 - mean_squared_error: 0.2319 - acc: 0.3663\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.2114 - mean_squared_error: 0.2114 - acc: 0.4476\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.1864 - mean_squared_error: 0.1864 - acc: 0.5557\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1713 - mean_squared_error: 0.1713 - acc: 0.60 - 1s 183us/step - loss: 0.1710 - mean_squared_error: 0.1710 - acc: 0.6052\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.1620 - mean_squared_error: 0.1620 - acc: 0.6269\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 0.1577 - mean_squared_error: 0.1577 - acc: 0.6412\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.1534 - mean_squared_error: 0.1534 - acc: 0.6598\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.1526 - mean_squared_error: 0.1526 - acc: 0.6609\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 250us/step - loss: 0.1498 - mean_squared_error: 0.1498 - acc: 0.6589\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 273us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6632\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 298us/step - loss: 0.1485 - mean_squared_error: 0.1485 - acc: 0.6637\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 304us/step - loss: 0.1474 - mean_squared_error: 0.1474 - acc: 0.6641\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 300us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6693\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 230us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6704\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.1446 - mean_squared_error: 0.1446 - acc: 0.6728\n",
      "2526/2526 [==============================] - 2s 731us/step\n",
      "8083/8083 [==============================] - 1s 101us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.1444 - mean_squared_error: 0.1444 - acc: 0.6700\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.1440 - mean_squared_error: 0.1440 - acc: 0.6687\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 201us/step - loss: 0.1430 - mean_squared_error: 0.1430 - acc: 0.6764\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.1421 - mean_squared_error: 0.1421 - acc: 0.6743\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.1423 - mean_squared_error: 0.1423 - acc: 0.6793\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.1421 - mean_squared_error: 0.1421 - acc: 0.6777\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.1422 - mean_squared_error: 0.1422 - acc: 0.6771\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.1413 - mean_squared_error: 0.1413 - acc: 0.6816\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1402 - mean_squared_error: 0.1402 - acc: 0.6833\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.1416 - mean_squared_error: 0.1416 - acc: 0.6750\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.1405 - mean_squared_error: 0.1405 - acc: 0.6865\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.1408 - mean_squared_error: 0.1408 - acc: 0.6827\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1405 - mean_squared_error: 0.1405 - acc: 0.6843\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1405 - mean_squared_error: 0.1405 - acc: 0.6827\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.1402 - mean_squared_error: 0.1402 - acc: 0.6818\n",
      "2526/2526 [==============================] - 0s 65us/step\n",
      "8083/8083 [==============================] - 1s 66us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.1393 - mean_squared_error: 0.1393 - acc: 0.6892\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.1393 - mean_squared_error: 0.1393 - acc: 0.6881\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.1394 - mean_squared_error: 0.1394 - acc: 0.6876\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.1385 - mean_squared_error: 0.1385 - acc: 0.6932\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.1392 - mean_squared_error: 0.1392 - acc: 0.6892\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.1393 - mean_squared_error: 0.1393 - acc: 0.68840s - loss: 0.1398 - mean_squared_error\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1390 - mean_squared_error: 0.1390 - acc: 0.6869\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.1387 - mean_squared_error: 0.1387 - acc: 0.6959\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.1388 - mean_squared_error: 0.1388 - acc: 0.6866\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.1385 - mean_squared_error: 0.1385 - acc: 0.6954\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.6921\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.1377 - mean_squared_error: 0.1377 - acc: 0.6932\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1376 - mean_squared_error: 0.1376 - acc: 0.6965\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.1377 - mean_squared_error: 0.1377 - acc: 0.6960\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1374 - mean_squared_error: 0.1374 - acc: 0.6983\n",
      "2526/2526 [==============================] - 0s 76us/step\n",
      "8083/8083 [==============================] - 1s 71us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1374 - mean_squared_error: 0.1374 - acc: 0.6892\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.1373 - mean_squared_error: 0.1373 - acc: 0.69710s - loss: 0.1388 - mean_s\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1377 - mean_squared_error: 0.1377 - acc: 0.6929\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.1370 - mean_squared_error: 0.1370 - acc: 0.6936\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.1368 - mean_squared_error: 0.1368 - acc: 0.7036\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1375 - mean_squared_error: 0.1375 - acc: 0.6973\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1361 - mean_squared_error: 0.1361 - acc: 0.7030\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.1358 - mean_squared_error: 0.1358 - acc: 0.7028\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.1359 - mean_squared_error: 0.1359 - acc: 0.7018\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.1355 - mean_squared_error: 0.1355 - acc: 0.7067\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.1350 - mean_squared_error: 0.1350 - acc: 0.70380s - loss: 0.1322 - mean_squ\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.1346 - mean_squared_error: 0.1346 - acc: 0.7122\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1350 - mean_squared_error: 0.1350 - acc: 0.7035\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.1350 - mean_squared_error: 0.1350 - acc: 0.7100\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.1351 - mean_squared_error: 0.1351 - acc: 0.7042\n",
      "2526/2526 [==============================] - 0s 62us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.1347 - mean_squared_error: 0.1347 - acc: 0.7101\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.1342 - mean_squared_error: 0.1342 - acc: 0.7135\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.1345 - mean_squared_error: 0.1345 - acc: 0.7117\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.1329 - mean_squared_error: 0.1329 - acc: 0.7112\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.1327 - mean_squared_error: 0.1327 - acc: 0.7164\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.1333 - mean_squared_error: 0.1333 - acc: 0.7250\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.1324 - mean_squared_error: 0.1324 - acc: 0.72030s - loss: 0.1343 - mean_s\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.1333 - mean_squared_error: 0.1333 - acc: 0.7141\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1319 - mean_squared_error: 0.1319 - acc: 0.7219\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.1333 - mean_squared_error: 0.1333 - acc: 0.7138\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.1317 - mean_squared_error: 0.1317 - acc: 0.7199\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.1321 - mean_squared_error: 0.1321 - acc: 0.7194\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.1313 - mean_squared_error: 0.1313 - acc: 0.7164\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.1308 - mean_squared_error: 0.1308 - acc: 0.7235\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.1298 - mean_squared_error: 0.1298 - acc: 0.7291\n",
      "2526/2526 [==============================] - 0s 69us/step\n",
      "8083/8083 [==============================] - 1s 69us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 268us/step - loss: 0.1308 - mean_squared_error: 0.1308 - acc: 0.7157\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.1309 - mean_squared_error: 0.1309 - acc: 0.72511s - loss: 0.1330 - \n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.1295 - mean_squared_error: 0.1295 - acc: 0.7219\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.1296 - mean_squared_error: 0.1296 - acc: 0.7244\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.1285 - mean_squared_error: 0.1285 - acc: 0.7229\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 215us/step - loss: 0.1293 - mean_squared_error: 0.1293 - acc: 0.7261\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 217us/step - loss: 0.1278 - mean_squared_error: 0.1278 - acc: 0.7308\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 280us/step - loss: 0.1273 - mean_squared_error: 0.1273 - acc: 0.73152s\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 214us/step - loss: 0.1271 - mean_squared_error: 0.1271 - acc: 0.7354\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 204us/step - loss: 0.1271 - mean_squared_error: 0.1271 - acc: 0.7333\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 0.1281 - mean_squared_error: 0.1281 - acc: 0.7313\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.1266 - mean_squared_error: 0.1266 - acc: 0.72891s - loss: 0.1308 - mean_s\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.1267 - mean_squared_error: 0.1267 - acc: 0.7344\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.1265 - mean_squared_error: 0.1265 - acc: 0.7314\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.1258 - mean_squared_error: 0.1258 - acc: 0.73521s - loss: 0.1257 - mean_squared_error - ETA: 0s - loss: 0.1246 - mean_squared\n",
      "2526/2526 [==============================] - 0s 129us/step\n",
      "8083/8083 [==============================] - 1s 109us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.1256 - mean_squared_error: 0.1256 - acc: 0.7338\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.1250 - mean_squared_error: 0.1250 - acc: 0.7333\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.1236 - mean_squared_error: 0.1236 - acc: 0.7387\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.1250 - mean_squared_error: 0.1250 - acc: 0.7381\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.1233 - mean_squared_error: 0.1233 - acc: 0.7388\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.1236 - mean_squared_error: 0.1236 - acc: 0.7377\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.1218 - mean_squared_error: 0.1218 - acc: 0.7385\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.1233 - mean_squared_error: 0.1233 - acc: 0.73910s - loss: 0.1206 - me\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1213 - mean_squared_error: 0.1213 - acc: 0.74 - 2s 190us/step - loss: 0.1215 - mean_squared_error: 0.1215 - acc: 0.7424\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.1219 - mean_squared_error: 0.1219 - acc: 0.7416\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 234us/step - loss: 0.1202 - mean_squared_error: 0.1202 - acc: 0.7465\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.1206 - mean_squared_error: 0.1206 - acc: 0.74 - 1s 182us/step - loss: 0.1207 - mean_squared_error: 0.1207 - acc: 0.7451\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.1211 - mean_squared_error: 0.1211 - acc: 0.7427\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.1211 - mean_squared_error: 0.1211 - acc: 0.7439\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.1184 - mean_squared_error: 0.1184 - acc: 0.7486\n",
      "2526/2526 [==============================] - 0s 84us/step\n",
      "8083/8083 [==============================] - 1s 89us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 207us/step - loss: 0.1185 - mean_squared_error: 0.1185 - acc: 0.7515\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.1190 - mean_squared_error: 0.1190 - acc: 0.7455\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 194us/step - loss: 0.1203 - mean_squared_error: 0.1203 - acc: 0.74380s - loss: 0.1190 - mean_squar\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.1166 - mean_squared_error: 0.1166 - acc: 0.75260s - loss: 0.1165 - mean_squared_e\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.1183 - mean_squared_error: 0.1183 - acc: 0.7455\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 192us/step - loss: 0.1189 - mean_squared_error: 0.1189 - acc: 0.7458\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.1163 - mean_squared_error: 0.1163 - acc: 0.7560\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 199us/step - loss: 0.1171 - mean_squared_error: 0.1171 - acc: 0.7496\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.1160 - mean_squared_error: 0.1160 - acc: 0.7521\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.1161 - mean_squared_error: 0.1161 - acc: 0.7554\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.1159 - mean_squared_error: 0.1159 - acc: 0.7531\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.1142 - mean_squared_error: 0.1142 - acc: 0.7583\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 193us/step - loss: 0.1163 - mean_squared_error: 0.1163 - acc: 0.7511\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.1130 - mean_squared_error: 0.1130 - acc: 0.7600\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.1124 - mean_squared_error: 0.1124 - acc: 0.7604\n",
      "2526/2526 [==============================] - 0s 106us/step\n",
      "8083/8083 [==============================] - 1s 131us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 194us/step - loss: 0.1111 - mean_squared_error: 0.1111 - acc: 0.7669\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 193us/step - loss: 0.1128 - mean_squared_error: 0.1128 - acc: 0.7563\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.1119 - mean_squared_error: 0.1119 - acc: 0.7638\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.1114 - mean_squared_error: 0.1114 - acc: 0.7628\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.1113 - mean_squared_error: 0.1113 - acc: 0.7609\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 226us/step - loss: 0.1139 - mean_squared_error: 0.1139 - acc: 0.7539\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.1128 - mean_squared_error: 0.1128 - acc: 0.7574\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.1117 - mean_squared_error: 0.1117 - acc: 0.76301s - loss: 0.109\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.1089 - mean_squared_error: 0.1089 - acc: 0.7684\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.1088 - mean_squared_error: 0.1088 - acc: 0.7746\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.1111 - mean_squared_error: 0.1111 - acc: 0.7644\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.1090 - mean_squared_error: 0.1090 - acc: 0.7701\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.1090 - mean_squared_error: 0.1090 - acc: 0.7705\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 303us/step - loss: 0.1105 - mean_squared_error: 0.1105 - acc: 0.7658\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1065 - mean_squared_error: 0.1065 - acc: 0.7738\n",
      "2526/2526 [==============================] - 0s 78us/step\n",
      "8083/8083 [==============================] - 1s 79us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.1072 - mean_squared_error: 0.1072 - acc: 0.7736\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.1076 - mean_squared_error: 0.1076 - acc: 0.7802\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 298us/step - loss: 0.1071 - mean_squared_error: 0.1071 - acc: 0.7738\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 3s 388us/step - loss: 0.1057 - mean_squared_error: 0.1057 - acc: 0.77661s - loss: 0.1070 - mean - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.1065 -\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 3s 319us/step - loss: 0.1070 - mean_squared_error: 0.1070 - acc: 0.7721\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 266us/step - loss: 0.1076 - mean_squared_error: 0.1076 - acc: 0.7683\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 210us/step - loss: 0.1038 - mean_squared_error: 0.1038 - acc: 0.78111s\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1039 - mean_squared_error: 0.1039 - acc: 0.7794\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.1065 - mean_squared_error: 0.1065 - acc: 0.7750\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.1042 - mean_squared_error: 0.1042 - acc: 0.78300s - loss: 0.1023 - mean_squared\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.1058 - mean_squared_error: 0.1058 - acc: 0.77400s - loss: 0.1049 - mean_squared_error: 0.1049 - acc\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1057 - mean_squared_error: 0.1057 - acc: 0.7745\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.1032 - mean_squared_error: 0.1032 - acc: 0.7808\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.1023 - mean_squared_error: 0.1023 - acc: 0.7844\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.1029 - mean_squared_error: 0.1029 - acc: 0.7804\n",
      "2526/2526 [==============================] - 0s 97us/step\n",
      "8083/8083 [==============================] - 1s 85us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.1021 - mean_squared_error: 0.1021 - acc: 0.7840\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.1037 - mean_squared_error: 0.1037 - acc: 0.7783\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.1005 - mean_squared_error: 0.1005 - acc: 0.79040s - loss: 0.1011 - mean_squared_error: 0.1011\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.1003 - mean_squared_error: 0.1003 - acc: 0.7907\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.1023 - mean_squared_error: 0.1023 - acc: 0.7840\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.1018 - mean_squared_error: 0.1018 - acc: 0.7896\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.1014 - mean_squared_error: 0.1014 - acc: 0.78090s - loss: 0.1035 - mean_squared_err\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.0987 - mean_squared_error: 0.0987 - acc: 0.7930\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.0982 - mean_squared_error: 0.0982 - acc: 0.7955\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.0989 - mean_squared_error: 0.0989 - acc: 0.7919\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0975 - mean_squared_error: 0.0975 - acc: 0.7931\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.0984 - mean_squared_error: 0.0984 - acc: 0.7924\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 286us/step - loss: 0.0984 - mean_squared_error: 0.0984 - acc: 0.7919\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 238us/step - loss: 0.0952 - mean_squared_error: 0.0952 - acc: 0.7992\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 219us/step - loss: 0.0969 - mean_squared_error: 0.0969 - acc: 0.7892\n",
      "2526/2526 [==============================] - 0s 143us/step\n",
      "8083/8083 [==============================] - 1s 136us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0965 - mean_squared_error: 0.0965 - acc: 0.7956\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.0951 - mean_squared_error: 0.0951 - acc: 0.8028\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.0963 - mean_squared_error: 0.0963 - acc: 0.7948\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.0951 - mean_squared_error: 0.0951 - acc: 0.8013\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.0942 - mean_squared_error: 0.0942 - acc: 0.80 - 2s 197us/step - loss: 0.0940 - mean_squared_error: 0.0940 - acc: 0.8058\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 0.0953 - mean_squared_error: 0.0953 - acc: 0.79910s - loss: 0.0954 - mean_s\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.0940 - mean_squared_error: 0.0940 - acc: 0.7976\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.0950 - mean_squared_error: 0.0950 - acc: 0.79810s - loss: 0.0944 - mean_squared_error: 0.0944 - acc\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.0947 - mean_squared_error: 0.0947 - acc: 0.8003\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.0965 - mean_squared_error: 0.0965 - acc: 0.7965\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.0963 - mean_squared_error: 0.0963 - acc: 0.7933\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.0914 - mean_squared_error: 0.0914 - acc: 0.8079\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 0.0928 - mean_squared_error: 0.0928 - acc: 0.8053\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.0939 - mean_squared_error: 0.0939 - acc: 0.80350s - loss: 0.0934 - mean_squared_error: 0.09\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.0920 - mean_squared_error: 0.0920 - acc: 0.8061\n",
      "2526/2526 [==============================] - 0s 97us/step\n",
      "8083/8083 [==============================] - 1s 76us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0925 - mean_squared_error: 0.0925 - acc: 0.8050\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.0919 - mean_squared_error: 0.0919 - acc: 0.8054\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.0915 - mean_squared_error: 0.0915 - acc: 0.80500s - loss: 0.0901 - mean_squared_error: 0.0901 - acc\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.0914 - mean_squared_error: 0.0914 - acc: 0.8051\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 2s 188us/step - loss: 0.0926 - mean_squared_error: 0.0926 - acc: 0.8009\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.0903 - mean_squared_error: 0.0903 - acc: 0.8100\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.0925 - mean_squared_error: 0.0925 - acc: 0.7985\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.0894 - mean_squared_error: 0.0894 - acc: 0.8126\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.0910 - mean_squared_error: 0.0910 - acc: 0.8034\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 0.0901 - mean_squared_error: 0.0901 - acc: 0.8080\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.0885 - mean_squared_error: 0.0885 - acc: 0.8155\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0885 - mean_squared_error: 0.0885 - acc: 0.8142\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.0891 - mean_squared_error: 0.0891 - acc: 0.81410s - loss: 0.0888 - mean_squared_error: 0.0888 - acc: 0.\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.0906 - mean_squared_error: 0.0906 - acc: 0.8089\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.0882 - mean_squared_error: 0.0882 - acc: 0.8201\n",
      "2526/2526 [==============================] - 0s 76us/step\n",
      "8083/8083 [==============================] - 1s 124us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.0880 - mean_squared_error: 0.0880 - acc: 0.8139\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.0873 - mean_squared_error: 0.0873 - acc: 0.8168\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 188us/step - loss: 0.0873 - mean_squared_error: 0.0873 - acc: 0.8178\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0873 - mean_squared_error: 0.0873 - acc: 0.81710s - loss: 0.0881 - mean_squared_error: 0.0881 - acc\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.0858 - mean_squared_error: 0.0858 - acc: 0.82100s - loss: 0.0862 - mean_squared_error: 0.0862 -\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.0861 - mean_squared_error: 0.0861 - acc: 0.8207\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.0876 - mean_squared_error: 0.0876 - acc: 0.8171\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.0865 - mean_squared_error: 0.0865 - acc: 0.8190\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 177us/step - loss: 0.0858 - mean_squared_error: 0.0858 - acc: 0.8222\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.0857 - mean_squared_error: 0.0857 - acc: 0.8211\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0855 - mean_squared_error: 0.0855 - acc: 0.8191\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.0848 - mean_squared_error: 0.0848 - acc: 0.8233\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 199us/step - loss: 0.0840 - mean_squared_error: 0.0840 - acc: 0.82182s - l\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.0855 - mean_squared_error: 0.0855 - acc: 0.81931s - los\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.0867 - mean_squared_error: 0.0867 - acc: 0.8179\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "8083/8083 [==============================] - 1s 84us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0849 - mean_squared_error: 0.0849 - acc: 0.8190\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.0818 - mean_squared_error: 0.0818 - acc: 0.8261\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.0819 - mean_squared_error: 0.0819 - acc: 0.8308\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.0836 - mean_squared_error: 0.0836 - acc: 0.8205\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.0816 - mean_squared_error: 0.0816 - acc: 0.8282\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.0811 - mean_squared_error: 0.0811 - acc: 0.8316\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.0802 - mean_squared_error: 0.0802 - acc: 0.83130s - loss: 0.0796 - mean_squared_error: 0.07\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.0801 - mean_squared_error: 0.0801 - acc: 0.8335\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.0812 - mean_squared_error: 0.0812 - acc: 0.8253\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.0829 - mean_squared_error: 0.0829 - acc: 0.8288\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.0797 - mean_squared_error: 0.0797 - acc: 0.8356\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 179us/step - loss: 0.0803 - mean_squared_error: 0.0803 - acc: 0.8324\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.0817 - mean_squared_error: 0.0817 - acc: 0.8280\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.0796 - mean_squared_error: 0.0796 - acc: 0.8294\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0788 - mean_squared_error: 0.0788 - acc: 0.8335\n",
      "2526/2526 [==============================] - 0s 106us/step\n",
      "8083/8083 [==============================] - 1s 119us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0798 - mean_squared_error: 0.0798 - acc: 0.8325\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.0804 - mean_squared_error: 0.0804 - acc: 0.83340s - loss: 0.0807 - mean_squared_error: 0.0807 - acc: 0.83\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.0793 - mean_squared_error: 0.0793 - acc: 0.8308\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0810 - mean_squared_error: 0.0810 - acc: 0.8289\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.0767 - mean_squared_error: 0.0767 - acc: 0.8386\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.0767 - mean_squared_error: 0.0767 - acc: 0.83970s - loss: 0.0769 - mean_squared_error: 0.\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.0766 - mean_squared_error: 0.0766 - acc: 0.8368\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0778 - mean_squared_error: 0.0778 - acc: 0.83690s - loss: 0.0780 - mean_squared_error: 0.0780 - acc: 0.\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.0784 - mean_squared_error: 0.0784 - acc: 0.83611s - loss: 0.0796 - mean_squared_error: 0. - ETA: 0s - loss: 0.0761 - mean_squared_err\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.0772 - mean_squared_error: 0.0772 - acc: 0.8379\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0783 - mean_squared_error: 0.0783 - acc: 0.8340\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 208us/step - loss: 0.0787 - mean_squared_error: 0.0787 - acc: 0.83060s - loss: 0.0784 - mean_squared_error: 0.0784 - a\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.0791 - mean_squared_error: 0.0791 - acc: 0.8317\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0766 - mean_squared_error: 0.0766 - acc: 0.84080s - loss: 0.0755 - mean_squared_e\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0769 - mean_squared_error: 0.0769 - acc: 0.8367\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "8083/8083 [==============================] - 1s 108us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.0729 - mean_squared_error: 0.0729 - acc: 0.8454\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.0741 - mean_squared_error: 0.0741 - acc: 0.8439\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.0764 - mean_squared_error: 0.0764 - acc: 0.8392\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.0729 - mean_squared_error: 0.0729 - acc: 0.84930s - loss: 0.0737 - mean_squared_error: \n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.0759 - mean_squared_error: 0.0759 - acc: 0.8405\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.0761 - mean_squared_error: 0.0761 - acc: 0.8390\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.0742 - mean_squared_error: 0.0742 - acc: 0.8473\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.0749 - mean_squared_error: 0.0749 - acc: 0.8425\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.0740 - mean_squared_error: 0.0740 - acc: 0.8473\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.0751 - mean_squared_error: 0.0751 - acc: 0.8398\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.0733 - mean_squared_error: 0.0733 - acc: 0.8454\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 3s 329us/step - loss: 0.0720 - mean_squared_error: 0.0720 - acc: 0.8484\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 237us/step - loss: 0.0750 - mean_squared_error: 0.0750 - acc: 0.8446\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 3s 353us/step - loss: 0.0731 - mean_squared_error: 0.0731 - acc: 0.8450\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 271us/step - loss: 0.0735 - mean_squared_error: 0.0735 - acc: 0.8433\n",
      "2526/2526 [==============================] - 0s 178us/step\n",
      "8083/8083 [==============================] - 1s 156us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 254us/step - loss: 0.0747 - mean_squared_error: 0.0747 - acc: 0.84520s - loss: 0.0768 - mean_squ\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 246us/step - loss: 0.0736 - mean_squared_error: 0.0736 - acc: 0.8481\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0712 - mean_squared_error: 0.0712 - acc: 0.8515\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0701 - mean_squared_error: 0.0701 - acc: 0.8550\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.0717 - mean_squared_error: 0.0717 - acc: 0.8489\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0703 - mean_squared_error: 0.0703 - acc: 0.8550\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0705 - mean_squared_error: 0.0705 - acc: 0.8491\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.0736 - mean_squared_error: 0.0736 - acc: 0.8481\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.0704 - mean_squared_error: 0.0704 - acc: 0.8513\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0708 - mean_squared_error: 0.0708 - acc: 0.8488\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.0696 - mean_squared_error: 0.0696 - acc: 0.8519\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.0708 - mean_squared_error: 0.0708 - acc: 0.8539\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.0698 - mean_squared_error: 0.0698 - acc: 0.8524\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.0690 - mean_squared_error: 0.0690 - acc: 0.8577\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.0705 - mean_squared_error: 0.0705 - acc: 0.8518\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "8083/8083 [==============================] - 1s 81us/step \n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.0702 - mean_squared_error: 0.0702 - acc: 0.8514\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.0703 - mean_squared_error: 0.0703 - acc: 0.8554\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0679 - mean_squared_error: 0.0679 - acc: 0.8592\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0687 - mean_squared_error: 0.0687 - acc: 0.8616\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0710 - mean_squared_error: 0.0710 - acc: 0.84891s - loss: 0.0739 - mean\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.0675 - mean_squared_error: 0.0675 - acc: 0.8591\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.0695 - mean_squared_error: 0.0695 - acc: 0.8583\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.0661 - mean_squared_error: 0.0661 - acc: 0.8632\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.0678 - mean_squared_error: 0.0678 - acc: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0690 - mean_squared_error: 0.0690 - acc: 0.8556\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.0703 - mean_squared_error: 0.0703 - acc: 0.8523\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.0671 - mean_squared_error: 0.0671 - acc: 0.8623\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.0676 - mean_squared_error: 0.0676 - acc: 0.8569\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.0666 - mean_squared_error: 0.0666 - acc: 0.86110s - loss: 0.0671 - mean_squared_error: 0.0671 - acc\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.0689 - mean_squared_error: 0.0689 - acc: 0.85220s - loss: 0.0695 - mean_squared_err\n",
      "2526/2526 [==============================] - 0s 71us/step\n",
      "8083/8083 [==============================] - 1s 100us/step\n",
      "2526/2526 [==============================] - 0s 116us/step\n",
      "8083/8083 [==============================] - 1s 123us/step\n",
      "The Score is 0.958828\n",
      "current iteration fraction: 0.700000\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 5s 710us/step - loss: 0.2417 - mean_squared_error: 0.2417 - acc: 0.3481\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.2198 - mean_squared_error: 0.2198 - acc: 0.4078\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2025 - mean_squared_error: 0.2025 - acc: 0.4976\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1833 - mean_squared_error: 0.1833 - acc: 0.5631\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1728 - mean_squared_error: 0.1728 - acc: 0.5998\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - 2s 273us/step - loss: 0.1655 - mean_squared_error: 0.1655 - acc: 0.6234\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 2s 253us/step - loss: 0.1606 - mean_squared_error: 0.1606 - acc: 0.6278\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.1568 - mean_squared_error: 0.1568 - acc: 0.6447\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1553 - mean_squared_error: 0.1553 - acc: 0.65000s - loss: 0.1549 - mean_squared_error\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1525 - mean_squared_error: 0.1525 - acc: 0.6486\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 161us/step - loss: 0.1520 - mean_squared_error: 0.1520 - acc: 0.6611\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 198us/step - loss: 0.1488 - mean_squared_error: 0.1488 - acc: 0.6606\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.1491 - mean_squared_error: 0.1491 - acc: 0.6630\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.1486 - mean_squared_error: 0.1486 - acc: 0.6643\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1473 - mean_squared_error: 0.1473 - acc: 0.6628\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1462 - mean_squared_error: 0.1462 - acc: 0.6669\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.1466 - mean_squared_error: 0.1466 - acc: 0.6673\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 152us/step - loss: 0.1455 - mean_squared_error: 0.1455 - acc: 0.6628\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.1450 - mean_squared_error: 0.1450 - acc: 0.6775\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1443 - mean_squared_error: 0.1443 - acc: 0.6697\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.1445 - mean_squared_error: 0.1445 - acc: 0.6752\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1432 - mean_squared_error: 0.1432 - acc: 0.6719\n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.1435 - mean_squared_error: 0.1435 - acc: 0.6749\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 1s 177us/step - loss: 0.1434 - mean_squared_error: 0.1434 - acc: 0.6729\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1429 - mean_squared_error: 0.1429 - acc: 0.6792\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1421 - mean_squared_error: 0.1421 - acc: 0.6728\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.1424 - mean_squared_error: 0.1424 - acc: 0.6756\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.1423 - mean_squared_error: 0.1423 - acc: 0.6763\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 152us/step - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.6816\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 160us/step - loss: 0.1423 - mean_squared_error: 0.1423 - acc: 0.6823\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.1414 - mean_squared_error: 0.1414 - acc: 0.6759\n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.1408 - mean_squared_error: 0.1408 - acc: 0.6862\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 152us/step - loss: 0.1408 - mean_squared_error: 0.1408 - acc: 0.6799\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 174us/step - loss: 0.1416 - mean_squared_error: 0.1416 - acc: 0.6814\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1409 - mean_squared_error: 0.1409 - acc: 0.67 - 1s 186us/step - loss: 0.1410 - mean_squared_error: 0.1410 - acc: 0.6785\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.1411 - mean_squared_error: 0.1411 - acc: 0.6851\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 200us/step - loss: 0.1403 - mean_squared_error: 0.1403 - acc: 0.6861\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.1406 - mean_squared_error: 0.1406 - acc: 0.6859\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 2s 249us/step - loss: 0.1407 - mean_squared_error: 0.1407 - acc: 0.68621s - loss: 0.1414 - mean_squared_error: 0.1414 - acc: 0. - ETA: 1s - loss: 0.1418 - mean_squared_error: 0.1418 - acc - ETA: 1s - loss: 0.1404 - mean_squar\n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 1s 181us/step - loss: 0.1401 - mean_squared_error: 0.1401 - acc: 0.6871\n",
      "Epoch 41/300\n",
      "7072/7072 [==============================] - 1s 156us/step - loss: 0.1404 - mean_squared_error: 0.1404 - acc: 0.6855\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 1s 203us/step - loss: 0.1401 - mean_squared_error: 0.1401 - acc: 0.6889\n",
      "Epoch 43/300\n",
      "7072/7072 [==============================] - 2s 243us/step - loss: 0.1396 - mean_squared_error: 0.1396 - acc: 0.6924\n",
      "Epoch 44/300\n",
      "7072/7072 [==============================] - 2s 271us/step - loss: 0.1393 - mean_squared_error: 0.1393 - acc: 0.6885\n",
      "Epoch 45/300\n",
      "7072/7072 [==============================] - 1s 205us/step - loss: 0.1395 - mean_squared_error: 0.1395 - acc: 0.6875\n",
      "Epoch 46/300\n",
      "7072/7072 [==============================] - 1s 154us/step - loss: 0.1386 - mean_squared_error: 0.1386 - acc: 0.68791s - loss: 0.1371 - mean_squared\n",
      "Epoch 47/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1389 - mean_squared_error: 0.1389 - acc: 0.6876\n",
      "Epoch 48/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1394 - mean_squared_error: 0.1394 - acc: 0.6941\n",
      "Epoch 49/300\n",
      "7072/7072 [==============================] - 1s 154us/step - loss: 0.1389 - mean_squared_error: 0.1389 - acc: 0.6929\n",
      "Epoch 50/300\n",
      "7072/7072 [==============================] - 1s 198us/step - loss: 0.1388 - mean_squared_error: 0.1388 - acc: 0.6999\n",
      "Epoch 51/300\n",
      "7072/7072 [==============================] - 1s 176us/step - loss: 0.1380 - mean_squared_error: 0.1380 - acc: 0.6967\n",
      "Epoch 52/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.6932\n",
      "Epoch 53/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1379 - mean_squared_error: 0.1379 - acc: 0.6975\n",
      "Epoch 54/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1382 - mean_squared_error: 0.1382 - acc: 0.6971\n",
      "Epoch 55/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1379 - mean_squared_error: 0.1379 - acc: 0.6978\n",
      "Epoch 56/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1378 - mean_squared_error: 0.1378 - acc: 0.7009\n",
      "Epoch 57/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.1377 - mean_squared_error: 0.1377 - acc: 0.7002\n",
      "Epoch 58/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.1376 - mean_squared_error: 0.1376 - acc: 0.6988\n",
      "Epoch 59/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.1372 - mean_squared_error: 0.1372 - acc: 0.6965\n",
      "Epoch 60/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.1372 - mean_squared_error: 0.1372 - acc: 0.7028\n",
      "Epoch 61/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1380 - mean_squared_error: 0.1380 - acc: 0.6978\n",
      "Epoch 62/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1363 - mean_squared_error: 0.1363 - acc: 0.7035\n",
      "Epoch 63/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1363 - mean_squared_error: 0.1363 - acc: 0.7036\n",
      "Epoch 64/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1367 - mean_squared_error: 0.1367 - acc: 0.7033\n",
      "Epoch 65/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1355 - mean_squared_error: 0.1355 - acc: 0.7005\n",
      "Epoch 66/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1360 - mean_squared_error: 0.1360 - acc: 0.7072\n",
      "Epoch 67/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1353 - mean_squared_error: 0.1353 - acc: 0.7072\n",
      "Epoch 68/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1351 - mean_squared_error: 0.1351 - acc: 0.7033\n",
      "Epoch 69/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1356 - mean_squared_error: 0.1356 - acc: 0.70250s - loss: 0.1363 - mean_squared_error: 0.1363 -\n",
      "Epoch 70/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1369 - mean_squared_error: 0.1369 - acc: 0.7026\n",
      "Epoch 71/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1344 - mean_squared_error: 0.1344 - acc: 0.7077\n",
      "Epoch 72/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1341 - mean_squared_error: 0.1341 - acc: 0.7098\n",
      "Epoch 73/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1347 - mean_squared_error: 0.1347 - acc: 0.7128\n",
      "Epoch 74/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1350 - mean_squared_error: 0.1350 - acc: 0.7103\n",
      "Epoch 75/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1342 - mean_squared_error: 0.1342 - acc: 0.7097\n",
      "Epoch 76/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1341 - mean_squared_error: 0.1341 - acc: 0.7096\n",
      "Epoch 77/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.1337 - mean_squared_error: 0.1337 - acc: 0.7118\n",
      "Epoch 78/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.1340 - mean_squared_error: 0.1340 - acc: 0.71620s - loss: 0.1333 - mean_squared_e\n",
      "Epoch 79/300\n",
      "7072/7072 [==============================] - 1s 192us/step - loss: 0.1338 - mean_squared_error: 0.1338 - acc: 0.71711s - loss: 0.1\n",
      "Epoch 80/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.1329 - mean_squared_error: 0.1329 - acc: 0.7163\n",
      "Epoch 81/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1332 - mean_squared_error: 0.1332 - acc: 0.7152\n",
      "Epoch 82/300\n",
      "7072/7072 [==============================] - 1s 182us/step - loss: 0.1345 - mean_squared_error: 0.1345 - acc: 0.7127\n",
      "Epoch 83/300\n",
      "7072/7072 [==============================] - 1s 169us/step - loss: 0.1327 - mean_squared_error: 0.1327 - acc: 0.7139\n",
      "Epoch 84/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1326 - mean_squared_error: 0.1326 - acc: 0.71 - 1s 125us/step - loss: 0.1325 - mean_squared_error: 0.1325 - acc: 0.7139\n",
      "Epoch 85/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.1323 - mean_squared_error: 0.1323 - acc: 0.7168\n",
      "Epoch 86/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1319 - mean_squared_error: 0.1319 - acc: 0.7173\n",
      "Epoch 87/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.1322 - mean_squared_error: 0.1322 - acc: 0.7202\n",
      "Epoch 88/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1316 - mean_squared_error: 0.1316 - acc: 0.7146\n",
      "Epoch 89/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.1309 - mean_squared_error: 0.1309 - acc: 0.7195\n",
      "Epoch 90/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1313 - mean_squared_error: 0.1313 - acc: 0.7202\n",
      "Epoch 91/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.1301 - mean_squared_error: 0.1301 - acc: 0.7247\n",
      "Epoch 92/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1311 - mean_squared_error: 0.1311 - acc: 0.7251\n",
      "Epoch 93/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.1320 - mean_squared_error: 0.1320 - acc: 0.7238\n",
      "Epoch 94/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.1303 - mean_squared_error: 0.1303 - acc: 0.7180\n",
      "Epoch 95/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1285 - mean_squared_error: 0.1285 - acc: 0.7309\n",
      "Epoch 96/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1286 - mean_squared_error: 0.1286 - acc: 0.7299\n",
      "Epoch 97/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1273 - mean_squared_error: 0.1273 - acc: 0.7258\n",
      "Epoch 98/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1294 - mean_squared_error: 0.1294 - acc: 0.7255\n",
      "Epoch 99/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1277 - mean_squared_error: 0.1277 - acc: 0.7274\n",
      "Epoch 100/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1266 - mean_squared_error: 0.1266 - acc: 0.7305\n",
      "Epoch 101/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1270 - mean_squared_error: 0.1270 - acc: 0.7299\n",
      "Epoch 102/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1262 - mean_squared_error: 0.1262 - acc: 0.7274\n",
      "Epoch 103/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1253 - mean_squared_error: 0.1253 - acc: 0.7326\n",
      "Epoch 104/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.1272 - mean_squared_error: 0.1272 - acc: 0.7306\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1263 - mean_squared_error: 0.1263 - acc: 0.7308\n",
      "Epoch 106/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1260 - mean_squared_error: 0.1260 - acc: 0.7363\n",
      "Epoch 107/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.1251 - mean_squared_error: 0.1251 - acc: 0.7320\n",
      "Epoch 108/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.1262 - mean_squared_error: 0.1262 - acc: 0.7311\n",
      "Epoch 109/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1240 - mean_squared_error: 0.1240 - acc: 0.7364\n",
      "Epoch 110/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1257 - mean_squared_error: 0.1257 - acc: 0.7361\n",
      "Epoch 111/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1231 - mean_squared_error: 0.1231 - acc: 0.7391\n",
      "Epoch 112/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.1236 - mean_squared_error: 0.1236 - acc: 0.7400\n",
      "Epoch 113/300\n",
      "7072/7072 [==============================] - 1s 178us/step - loss: 0.1236 - mean_squared_error: 0.1236 - acc: 0.7377\n",
      "Epoch 114/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1230 - mean_squared_error: 0.1230 - acc: 0.7359\n",
      "Epoch 115/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1228 - mean_squared_error: 0.1228 - acc: 0.7417\n",
      "Epoch 116/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1210 - mean_squared_error: 0.1210 - acc: 0.7435\n",
      "Epoch 117/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1205 - mean_squared_error: 0.1205 - acc: 0.7446\n",
      "Epoch 118/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1215 - mean_squared_error: 0.1215 - acc: 0.7451\n",
      "Epoch 119/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.1210 - mean_squared_error: 0.1210 - acc: 0.7395\n",
      "Epoch 120/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1200 - mean_squared_error: 0.1200 - acc: 0.7477\n",
      "Epoch 121/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1205 - mean_squared_error: 0.1205 - acc: 0.7414\n",
      "Epoch 122/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1206 - mean_squared_error: 0.1206 - acc: 0.74 - 1s 102us/step - loss: 0.1204 - mean_squared_error: 0.1204 - acc: 0.7408\n",
      "Epoch 123/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1178 - mean_squared_error: 0.1178 - acc: 0.7552\n",
      "Epoch 124/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.1188 - mean_squared_error: 0.1188 - acc: 0.7472\n",
      "Epoch 125/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1187 - mean_squared_error: 0.1187 - acc: 0.7449\n",
      "Epoch 126/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.1186 - mean_squared_error: 0.1186 - acc: 0.7500\n",
      "Epoch 127/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1190 - mean_squared_error: 0.1190 - acc: 0.7428\n",
      "Epoch 128/300\n",
      "7072/7072 [==============================] - 1s 159us/step - loss: 0.1174 - mean_squared_error: 0.1174 - acc: 0.7467\n",
      "Epoch 129/300\n",
      "7072/7072 [==============================] - 1s 155us/step - loss: 0.1190 - mean_squared_error: 0.1190 - acc: 0.7435\n",
      "Epoch 130/300\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.1190 - mean_squared_error: 0.1190 - acc: 0.7441\n",
      "Epoch 131/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1167 - mean_squared_error: 0.1167 - acc: 0.7527\n",
      "Epoch 132/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1150 - mean_squared_error: 0.1150 - acc: 0.7571\n",
      "Epoch 133/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1147 - mean_squared_error: 0.1147 - acc: 0.7554\n",
      "Epoch 134/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.1151 - mean_squared_error: 0.1151 - acc: 0.75270s - loss: 0.1145 - mean_squared_error: 0.1145 - acc: 0.\n",
      "Epoch 135/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.1158 - mean_squared_error: 0.1158 - acc: 0.7482\n",
      "Epoch 136/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.1143 - mean_squared_error: 0.1143 - acc: 0.7511\n",
      "Epoch 137/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.1142 - mean_squared_error: 0.1142 - acc: 0.7571\n",
      "Epoch 138/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1122 - mean_squared_error: 0.1122 - acc: 0.7579\n",
      "Epoch 139/300\n",
      "7072/7072 [==============================] - 1s 102us/step - loss: 0.1138 - mean_squared_error: 0.1138 - acc: 0.7551\n",
      "Epoch 140/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1130 - mean_squared_error: 0.1130 - acc: 0.7599\n",
      "Epoch 141/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1155 - mean_squared_error: 0.1155 - acc: 0.7527\n",
      "Epoch 142/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.1137 - acc: 0.7605 ETA: 0s - loss: 0.1146 - mean_squared_error: 0.1146 - a - 1s 102us/step - loss: 0.1137 - mean_squared_error: 0.1137 - acc: 0.7589\n",
      "Epoch 143/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1112 - mean_squared_error: 0.1112 - acc: 0.7586\n",
      "Epoch 144/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1092 - mean_squared_error: 0.1092 - acc: 0.7708\n",
      "Epoch 145/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1118 - mean_squared_error: 0.1118 - acc: 0.7634\n",
      "Epoch 146/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1093 - mean_squared_error: 0.1093 - acc: 0.7718\n",
      "Epoch 147/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1105 - mean_squared_error: 0.1105 - acc: 0.7640\n",
      "Epoch 148/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1109 - mean_squared_error: 0.1109 - acc: 0.7599\n",
      "Epoch 149/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.1105 - mean_squared_error: 0.1105 - acc: 0.7664\n",
      "Epoch 150/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.1112 - mean_squared_error: 0.1112 - acc: 0.7623\n",
      "Epoch 151/300\n",
      "7072/7072 [==============================] - 1s 179us/step - loss: 0.1089 - mean_squared_error: 0.1089 - acc: 0.7677\n",
      "Epoch 152/300\n",
      "7072/7072 [==============================] - 1s 182us/step - loss: 0.1103 - mean_squared_error: 0.1103 - acc: 0.7670\n",
      "Epoch 153/300\n",
      "7072/7072 [==============================] - 2s 352us/step - loss: 0.1095 - mean_squared_error: 0.1095 - acc: 0.76680s - loss: 0.1110 - mean_squ\n",
      "Epoch 154/300\n",
      "7072/7072 [==============================] - 2s 337us/step - loss: 0.1083 - mean_squared_error: 0.1083 - acc: 0.7685\n",
      "Epoch 155/300\n",
      "7072/7072 [==============================] - 2s 242us/step - loss: 0.1068 - mean_squared_error: 0.1068 - acc: 0.7711\n",
      "Epoch 156/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.1058 - mean_squared_error: 0.1058 - acc: 0.77521s - loss: 0.1087 - mean_squared_error: 0.1087 - acc - ETA: 0s - loss: 0.1051 - mean_squared_e\n",
      "Epoch 157/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.1096 - mean_squared_error: 0.1096 - acc: 0.7641\n",
      "Epoch 158/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.1075 - mean_squared_error: 0.1075 - acc: 0.77080s - loss: 0.1042 - mean_squared_error: 0.\n",
      "Epoch 159/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1064 - mean_squared_error: 0.1064 - acc: 0.7769\n",
      "Epoch 160/300\n",
      "7072/7072 [==============================] - 1s 100us/step - loss: 0.1061 - mean_squared_error: 0.1061 - acc: 0.7740\n",
      "Epoch 161/300\n",
      "7072/7072 [==============================] - 1s 99us/step - loss: 0.1054 - mean_squared_error: 0.1054 - acc: 0.7756\n",
      "Epoch 162/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1080 - mean_squared_error: 0.1080 - acc: 0.7668\n",
      "Epoch 163/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1047 - mean_squared_error: 0.1047 - acc: 0.7704\n",
      "Epoch 164/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1070 - mean_squared_error: 0.1070 - acc: 0.7685\n",
      "Epoch 165/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.1062 - mean_squared_error: 0.1062 - acc: 0.7725\n",
      "Epoch 166/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1021 - mean_squared_error: 0.1021 - acc: 0.78100s - loss: 0.1022 - mean_squared_error: 0.1022 -\n",
      "Epoch 167/300\n",
      "7072/7072 [==============================] - 2s 238us/step - loss: 0.1024 - mean_squared_error: 0.1024 - acc: 0.7827\n",
      "Epoch 168/300\n",
      "7072/7072 [==============================] - 2s 221us/step - loss: 0.1047 - mean_squared_error: 0.1047 - acc: 0.7746\n",
      "Epoch 169/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.1047 - mean_squared_error: 0.1047 - acc: 0.7783\n",
      "Epoch 170/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.1041 - mean_squared_error: 0.1041 - acc: 0.7780\n",
      "Epoch 171/300\n",
      "7072/7072 [==============================] - 1s 165us/step - loss: 0.1041 - mean_squared_error: 0.1041 - acc: 0.7759\n",
      "Epoch 172/300\n",
      "  32/7072 [..............................] - ETA: 1s - loss: 0.1130 - mean_squared_error: 0.1130 - acc: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-cfd7ec4fb820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwriteDictToCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningCurveIterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsICAEM.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 3)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetICAEM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random Projection<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.89767587e-04 1.90483172e-03 1.97641859e-02 2.00037059e-02\n",
      " 1.16939058e-01 1.18141878e-01 1.51948319e-01 1.65005274e-01\n",
      " 4.06002980e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "length = len(X_inputs.columns)\n",
    "rp = GaussianRandomProjection(n_components = len(X_inputs.columns))\n",
    "rp.fit(X_inputs)\n",
    "X_inputs = rp.transform(X_inputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances/(sum(variances))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 265us/step - loss: 0.2388 - mean_squared_error: 0.2388 - acc: 0.3384\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2281 - mean_squared_error: 0.2281 - acc: 0.3332\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2258 - mean_squared_error: 0.2258 - acc: 0.3349\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2250 - mean_squared_error: 0.2250 - acc: 0.3307\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3415\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.34010s - loss: 0.2229 - mean_s\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3306\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3428\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3454\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3350\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.34100s - loss: 0.2232 - mean_squared_error: 0.22 - ETA: 0s - loss: 0.2231 - mean_squared_error: 0.2231 - acc\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3354\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3420\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3405\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3373\n",
      "2526/2526 [==============================] - 0s 182us/step\n",
      "8083/8083 [==============================] - 1s 68us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3405\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3407\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3429\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3374\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.33901s - loss: 0.2232 - \n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3371\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3411\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3278\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34240s - loss: 0.2225 - mean_squared_error: 0.2225 - acc\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3443\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3365\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3395\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3374\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34490s - loss: 0.2225 - mean_squared_error: \n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3384\n",
      "2526/2526 [==============================] - 0s 72us/step\n",
      "8083/8083 [==============================] - 1s 74us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34500s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3412\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34470s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3429\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3413\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3382\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.33280s - loss: 0.2225 - mean_s\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3373\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3371\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3429\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3454\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3338\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3381\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3453\n",
      "2526/2526 [==============================] - 0s 61us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3387\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3410\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33 - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3353\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34380s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3504\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3444\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33690s - loss: 0.2223 - mean_squared\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3406\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3449\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3345\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3427\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3342\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "2526/2526 [==============================] - 0s 68us/step\n",
      "8083/8083 [==============================] - 0s 60us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3402\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3459\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3474\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3512\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3385\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3420\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3436\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3424\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "2526/2526 [==============================] - 0s 65us/step\n",
      "8083/8083 [==============================] - 0s 60us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34110s - loss: 0.2222 - mean_squared_error: 0.2222 - a\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3403\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3481\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3424\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3454\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34 - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33730s - loss: 0.2222 - mean_squared_error: \n",
      "2526/2526 [==============================] - ETA:  - 0s 77us/step\n",
      "8083/8083 [==============================] - 1s 67us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3412\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3401\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3427\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3485\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3473\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3431\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3446\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3386\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3463\n",
      "2526/2526 [==============================] - 0s 63us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3427\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34381s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33 - ETA: 0s - loss: 0.2223 - mean_squ\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3379\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3427\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3431\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3457\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "2526/2526 [==============================] - 0s 66us/step\n",
      "8083/8083 [==============================] - 0s 55us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34490s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: \n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3441\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34 - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3397\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3371\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3441\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3402\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3446\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34520s - loss: 0.2216 - mean_s\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3412\n",
      "2526/2526 [==============================] - ETA:  - 0s 60us/step\n",
      "8083/8083 [==============================] - 1s 65us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3433\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34501s - loss: 0.2223 - mean_s\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34530s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3460\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34480s - loss: 0.2221 - mean_squared_error: 0.22\n",
      "2526/2526 [==============================] - 0s 71us/step\n",
      "8083/8083 [==============================] - 1s 81us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34410s - loss: 0.2220 - mean_squared_e\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3436\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34310s - loss: 0.2221 - mean_squared_error: 0.22\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3426\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3453\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34810s - loss: 0.2224 - mean_s\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3467\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34220s - loss: 0.2224 - mean_squar\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3457\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "2526/2526 [==============================] - 0s 77us/step\n",
      "8083/8083 [==============================] - 0s 48us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34390s - loss: 0.2221 - me\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3431\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33 - ETA: 0s - loss: 0.2223 - mean_s\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34340s - loss: 0.2222 - mean_squared_error: 0.2222 - acc\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3433\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3455\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3457\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3412\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3439\n",
      "2526/2526 [==============================] - 0s 61us/step\n",
      "8083/8083 [==============================] - 1s 69us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34600s - loss: 0.2221 - mean_s\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3427\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3433\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34500s - loss: 0.2223 - mean_squared\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34360s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: \n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3441\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34480s - loss: 0.2222 - mean_squar\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3453\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3457\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "2526/2526 [==============================] - 0s 68us/step \n",
      "8083/8083 [==============================] - 1s 64us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2219 - mean\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3455\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34480s - loss: 0.2221 - mean_squared_error: 0.2221 -\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34520s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3439\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "2526/2526 [==============================] - 0s 58us/step\n",
      "8083/8083 [==============================] - 1s 65us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3457\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34 - 1s 129us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3464\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34390s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2221 - mean_squared_e\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34470s - loss: 0.2218 - mean_squared_error: 0.2218 - acc: 0.35 - ETA: 0s - loss: 0.2219 - mean_s\n",
      "2526/2526 [==============================] - 0s 81us/step\n",
      "8083/8083 [==============================] - 1s 63us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3437\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3462\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3460\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34490s - loss: 0.2221 - mean_squared_error: 0.2221 -\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34550s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34 - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3442\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34470s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "2526/2526 [==============================] - 0s 65us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3453\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34460s - loss: 0.2218 - me\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "2526/2526 [==============================] - 0s 63us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34490s - loss: 0.2222 - mean\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3441\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34430s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34 - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34460s - loss: 0.2222 - mean_squared\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34470s - loss: 0.2221 - mean_squared_e\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34500s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3443\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3441\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "2526/2526 [==============================] - 0s 59us/step\n",
      "8083/8083 [==============================] - 0s 60us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3452\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3473\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3436\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3447\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3453\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2221 - mean_squared_error: 0.22\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3439\n",
      "2526/2526 [==============================] - 0s 68us/step\n",
      "8083/8083 [==============================] - 0s 59us/step\n",
      "2526/2526 [==============================] - 0s 65us/step\n",
      "8083/8083 [==============================] - 0s 61us/step\n",
      "The Score is 0.336896\n",
      "current iteration fraction: 0.700000\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 2s 237us/step - loss: 0.2388 - mean_squared_error: 0.2388 - acc: 0.3391\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2297 - mean_squared_error: 0.2297 - acc: 0.3334\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.2262 - mean_squared_error: 0.2262 - acc: 0.3377\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2249 - mean_squared_error: 0.2249 - acc: 0.3419\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2250 - mean_squared_error: 0.2250 - acc: 0.3271\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3247\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3305\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 137us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.33530s - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3404\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3374\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3316\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3285\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3347\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.33100s - loss: 0.2231 - mean_squared_error: 0.2231 - a\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3364\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3398\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3225\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3406\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3355\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3302\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3313\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3358\n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.33170s - loss: 0.2229 - mean_squar\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3371\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3418\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3306\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3406\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3292\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3324\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3357\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33670s - loss: 0.2224 - mean_squared_error: 0.2224\n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3389\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3401\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3381\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3326\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3306\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3384\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.33720s - loss: 0.2224 - mean_squared_error: 0.2224 - - ETA: 0s - loss: 0.2225 - mean_squared_error: 0.2225 - acc: \n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3285\n",
      "Epoch 41/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3282\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3415\n",
      "Epoch 43/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3363\n",
      "Epoch 44/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34330s - loss: 0.2223 - mean_squared_error\n",
      "Epoch 45/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3413\n",
      "Epoch 46/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33140s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 47/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3295\n",
      "Epoch 48/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3313\n",
      "Epoch 49/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3473\n",
      "Epoch 50/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3385\n",
      "Epoch 51/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33 - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3364\n",
      "Epoch 52/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3334\n",
      "Epoch 53/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3353\n",
      "Epoch 54/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 55/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 56/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3480\n",
      "Epoch 57/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3351\n",
      "Epoch 58/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 59/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3360\n",
      "Epoch 60/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3409\n",
      "Epoch 61/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3346\n",
      "Epoch 62/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3358\n",
      "Epoch 63/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3361\n",
      "Epoch 64/300\n",
      "7072/7072 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3371\n",
      "Epoch 65/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3341\n",
      "Epoch 66/300\n",
      "7072/7072 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3324\n",
      "Epoch 67/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 68/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3254\n",
      "Epoch 69/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 70/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3320\n",
      "Epoch 71/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3272\n",
      "Epoch 72/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 73/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 74/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3249\n",
      "Epoch 75/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 76/300\n",
      "7072/7072 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3412\n",
      "Epoch 77/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 78/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 79/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 80/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 81/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3457\n",
      "Epoch 82/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 83/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3351\n",
      "Epoch 84/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3367\n",
      "Epoch 85/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 86/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 87/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 88/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3438\n",
      "Epoch 89/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 90/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 91/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3293 ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3282\n",
      "Epoch 92/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3350\n",
      "Epoch 93/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3310\n",
      "Epoch 94/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 95/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3343\n",
      "Epoch 96/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3358\n",
      "Epoch 97/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3298\n",
      "Epoch 98/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3329\n",
      "Epoch 99/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 100/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3346\n",
      "Epoch 101/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 102/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3317\n",
      "Epoch 103/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3350\n",
      "Epoch 104/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 105/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 106/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 107/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 108/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3399\n",
      "Epoch 109/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3330\n",
      "Epoch 110/300\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3423\n",
      "Epoch 111/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3360\n",
      "Epoch 112/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3425\n",
      "Epoch 113/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 114/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 115/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3364\n",
      "Epoch 116/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 117/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3358\n",
      "Epoch 118/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3363\n",
      "Epoch 119/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 120/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3368\n",
      "Epoch 121/300\n",
      "7072/7072 [==============================] - 1s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 122/300\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 123/300\n",
      "7072/7072 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3298\n",
      "Epoch 124/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 125/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 126/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3380\n",
      "Epoch 127/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 128/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3279\n",
      "Epoch 129/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33360s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 130/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3344\n",
      "Epoch 131/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3317\n",
      "Epoch 132/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 133/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3276\n",
      "Epoch 134/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34260s - loss: 0.2221 - mean\n",
      "Epoch 135/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 136/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 137/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3298\n",
      "Epoch 138/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 139/300\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 140/300\n",
      "7072/7072 [==============================] - 1s 157us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3371\n",
      "Epoch 141/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3300\n",
      "Epoch 142/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3404\n",
      "Epoch 143/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 144/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3327\n",
      "Epoch 145/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 146/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 147/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3357\n",
      "Epoch 148/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 149/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3368\n",
      "Epoch 150/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 151/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 152/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 153/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 154/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 155/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3324\n",
      "Epoch 156/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3327\n",
      "Epoch 157/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33400s - loss: 0.2222 - mean_squared_error: 0.2222 - acc\n",
      "Epoch 158/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3348\n",
      "Epoch 159/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 160/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 161/300\n",
      "7072/7072 [==============================] - 1s 105us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 162/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3334\n",
      "Epoch 163/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 164/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3423\n",
      "Epoch 165/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3450\n",
      "Epoch 166/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33430s - loss: 0.2223 - mean_squared_e\n",
      "Epoch 167/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3357\n",
      "Epoch 168/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 169/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3443\n",
      "Epoch 170/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3343\n",
      "Epoch 171/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3380\n",
      "Epoch 172/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3357\n",
      "Epoch 173/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3364\n",
      "Epoch 174/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3367\n",
      "Epoch 175/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3348\n",
      "Epoch 176/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3454\n",
      "Epoch 177/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3360\n",
      "Epoch 178/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33 - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 179/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3326\n",
      "Epoch 180/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3367\n",
      "Epoch 181/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 182/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 183/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3340\n",
      "Epoch 184/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3292\n",
      "Epoch 185/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3303\n",
      "Epoch 186/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 187/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3374\n",
      "Epoch 188/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 189/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3419\n",
      "Epoch 190/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3300\n",
      "Epoch 191/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3326\n",
      "Epoch 192/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3341\n",
      "Epoch 193/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3340\n",
      "Epoch 194/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3374\n",
      "Epoch 195/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 196/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3380\n",
      "Epoch 197/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3339\n",
      "Epoch 198/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 199/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3368\n",
      "Epoch 200/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 201/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33460s - loss: 0.2222 - mean_squared_err\n",
      "Epoch 202/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 203/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 204/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 205/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 206/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33850s - loss: 0.2222 - mean_squared_error: 0.2222\n",
      "Epoch 207/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 208/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 209/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33440s - loss: 0.2220 - mean_squar\n",
      "Epoch 210/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 211/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 212/300\n",
      "7072/7072 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33 - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3323\n",
      "Epoch 213/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3380\n",
      "Epoch 214/300\n",
      "7072/7072 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33460s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 215/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 216/300\n",
      "7072/7072 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 217/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 218/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33020s - loss: 0.2222 - mean_squared_error: 0.2222 - acc:  - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 220/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3306\n",
      "Epoch 221/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 222/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3271\n",
      "Epoch 223/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 224/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 225/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3326\n",
      "Epoch 226/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 227/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3312\n",
      "Epoch 228/300\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3360\n",
      "Epoch 229/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3344\n",
      "Epoch 230/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3334\n",
      "Epoch 231/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 232/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 233/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 234/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3374\n",
      "Epoch 235/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 236/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33370s - loss: 0.2221 - mean_squared_error: 0.2221\n",
      "Epoch 237/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 238/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 239/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3343\n",
      "Epoch 240/300\n",
      "7072/7072 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3329\n",
      "Epoch 241/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 242/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 243/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33360s - loss: 0.2222 - mean_squared_error: \n",
      "Epoch 244/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3285\n",
      "Epoch 245/300\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 246/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 247/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3307\n",
      "Epoch 248/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3269\n",
      "Epoch 249/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3336\n",
      "Epoch 250/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3365\n",
      "Epoch 251/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 252/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 253/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 254/300\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 255/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33990s - loss: 0.2222 - mean_squared_err\n",
      "Epoch 256/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3340\n",
      "Epoch 257/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3316\n",
      "Epoch 258/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34020s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: \n",
      "Epoch 259/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 260/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3354\n",
      "Epoch 261/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3323\n",
      "Epoch 262/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3334\n",
      "Epoch 263/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 264/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33940s - loss: 0.2221 - mean_squared\n",
      "Epoch 265/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 266/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3346\n",
      "Epoch 267/300\n",
      "7072/7072 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3416\n",
      "Epoch 268/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3364\n",
      "Epoch 269/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3339\n",
      "Epoch 270/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3438\n",
      "Epoch 271/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33740s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33\n",
      "Epoch 272/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 273/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 274/300\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 275/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 276/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 277/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33680s - loss: 0.2222 - mean_squared_error: 0.2222 - a - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 278/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33920s - loss: 0.2220 - mean_squared_error: 0.2220 - acc - ETA: 0s - loss: 0.2224 - mean_squared_err\n",
      "Epoch 279/300\n",
      "7072/7072 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 280/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "Epoch 281/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3406\n",
      "Epoch 282/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 283/300\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3340\n",
      "Epoch 284/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 285/300\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33850s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33\n",
      "Epoch 286/300\n",
      "7072/7072 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3261\n",
      "Epoch 287/300\n",
      "7072/7072 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 288/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 289/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3339\n",
      "Epoch 290/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3364\n",
      "Epoch 291/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 292/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3354\n",
      "Epoch 293/300\n",
      "7072/7072 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 294/300\n",
      "7072/7072 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33770s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 295/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3360\n",
      "Epoch 296/300\n",
      "7072/7072 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33480s - loss: 0.2222 - mean_squ\n",
      "Epoch 297/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3350\n",
      "Epoch 298/300\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3473\n",
      "Epoch 299/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 300/300\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3358\n",
      "2526/2526 [==============================] - 0s 176us/step\n",
      "7072/7072 [==============================] - 0s 63us/step\n",
      "The Score is 0.351940\n",
      "current iteration fraction: 0.600000\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "(6062, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "6062/6062 [==============================] - 2s 367us/step - loss: 0.2442 - mean_squared_error: 0.2442 - acc: 0.3364\n",
      "Epoch 2/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.2316 - mean_squared_error: 0.2316 - acc: 0.35150s - loss: 0.2325 - mean_squared_error: 0.23\n",
      "Epoch 3/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2281 - mean_squared_error: 0.2281 - acc: 0.3415\n",
      "Epoch 4/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2265 - mean_squared_error: 0.2265 - acc: 0.3402\n",
      "Epoch 5/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.2258 - mean_squared_error: 0.2258 - acc: 0.3360\n",
      "Epoch 6/300\n",
      "6062/6062 [==============================] - 1s 156us/step - loss: 0.2249 - mean_squared_error: 0.2249 - acc: 0.3312\n",
      "Epoch 7/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3299\n",
      "Epoch 8/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3296\n",
      "Epoch 9/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3525\n",
      "Epoch 10/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3514\n",
      "Epoch 11/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3382\n",
      "Epoch 12/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3377\n",
      "Epoch 13/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3405\n",
      "Epoch 14/300\n",
      "6062/6062 [==============================] - 1s 139us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3502\n",
      "Epoch 15/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3365\n",
      "Epoch 16/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3321\n",
      "Epoch 17/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3331\n",
      "Epoch 18/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3377\n",
      "Epoch 19/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3446\n",
      "Epoch 20/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3448\n",
      "Epoch 21/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3395\n",
      "Epoch 22/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3350\n",
      "Epoch 23/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3340\n",
      "Epoch 24/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3360\n",
      "Epoch 25/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.33060s - loss: 0.2226 - mean_squared_error: 0.2226 - acc: \n",
      "Epoch 26/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3397\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3512\n",
      "Epoch 28/300\n",
      "6062/6062 [==============================] - 1s 113us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3474\n",
      "Epoch 29/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3406\n",
      "Epoch 30/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3458\n",
      "Epoch 31/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.33450s - loss: 0.2229 - mean_squared_error\n",
      "Epoch 32/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3479\n",
      "Epoch 33/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3403\n",
      "Epoch 34/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3438\n",
      "Epoch 35/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.33170s - loss: 0.2227 - mean_squared_e\n",
      "Epoch 36/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3406\n",
      "Epoch 37/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3340\n",
      "Epoch 38/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3395\n",
      "Epoch 39/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3438\n",
      "Epoch 40/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3402\n",
      "Epoch 41/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3413\n",
      "Epoch 42/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3439\n",
      "Epoch 43/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3314\n",
      "Epoch 44/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3461\n",
      "Epoch 45/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34590s - loss: 0.2223 - mean_squared_error: 0.2223 - a\n",
      "Epoch 46/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3360\n",
      "Epoch 47/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3383\n",
      "Epoch 48/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3418\n",
      "Epoch 49/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 50/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3385\n",
      "Epoch 51/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 52/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3354\n",
      "Epoch 53/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3354\n",
      "Epoch 54/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3509\n",
      "Epoch 55/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3362\n",
      "Epoch 56/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3459\n",
      "Epoch 57/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3423\n",
      "Epoch 58/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3413\n",
      "Epoch 59/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3502\n",
      "Epoch 60/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3423\n",
      "Epoch 61/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3423\n",
      "Epoch 62/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 63/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3458\n",
      "Epoch 64/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3400\n",
      "Epoch 65/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3522\n",
      "Epoch 66/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3448\n",
      "Epoch 67/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3439\n",
      "Epoch 68/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 69/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3397\n",
      "Epoch 70/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3479\n",
      "Epoch 71/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3532\n",
      "Epoch 72/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 73/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3484\n",
      "Epoch 74/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3380\n",
      "Epoch 75/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 76/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 77/300\n",
      "6062/6062 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3466\n",
      "Epoch 78/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3507\n",
      "Epoch 79/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34280s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34\n",
      "Epoch 80/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3504\n",
      "Epoch 81/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3430\n",
      "Epoch 82/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3494\n",
      "Epoch 83/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 84/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3489\n",
      "Epoch 85/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3515\n",
      "Epoch 86/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3336\n",
      "Epoch 87/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34180s - loss: 0.2224 - mean_squared_error: 0.2224\n",
      "Epoch 88/300\n",
      "6062/6062 [==============================] - 1s 149us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 89/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3507\n",
      "Epoch 90/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3502\n",
      "Epoch 91/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 92/300\n",
      "6062/6062 [==============================] - 1s 151us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 93/300\n",
      "6062/6062 [==============================] - 1s 164us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3454\n",
      "Epoch 94/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3453\n",
      "Epoch 95/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 96/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 97/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 98/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3479\n",
      "Epoch 99/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3433\n",
      "Epoch 100/300\n",
      "6062/6062 [==============================] - 1s 137us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 101/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 102/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3496\n",
      "Epoch 103/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3500\n",
      "Epoch 104/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3436\n",
      "Epoch 105/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34860s - loss: 0.2219 - mean_squared_error\n",
      "Epoch 106/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3431\n",
      "Epoch 107/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3435\n",
      "Epoch 108/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3436\n",
      "Epoch 109/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3466\n",
      "Epoch 110/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3439\n",
      "Epoch 111/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 112/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 113/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3477\n",
      "Epoch 114/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34210s - loss: 0.2224 - mean_squared_err\n",
      "Epoch 115/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 116/300\n",
      "6062/6062 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 117/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3342\n",
      "Epoch 118/300\n",
      "6062/6062 [==============================] - 1s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3481\n",
      "Epoch 119/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3324\n",
      "Epoch 120/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3403\n",
      "Epoch 121/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3344\n",
      "Epoch 122/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3431\n",
      "Epoch 123/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3491\n",
      "Epoch 124/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 125/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 126/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3352\n",
      "Epoch 127/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 128/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34260s - loss: 0.2222 - mean_squared_error: 0.2222 - acc\n",
      "Epoch 129/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 130/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 131/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 132/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 133/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 134/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3487\n",
      "Epoch 135/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 136/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 137/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 138/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34740s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 139/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3486\n",
      "Epoch 140/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34770s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 141/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 142/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3453\n",
      "Epoch 143/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 144/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 145/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3494\n",
      "Epoch 146/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3496\n",
      "Epoch 147/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3431\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3492\n",
      "Epoch 149/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 150/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 151/300\n",
      "6062/6062 [==============================] - 1s 107us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 152/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3487\n",
      "Epoch 153/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3463\n",
      "Epoch 154/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3451\n",
      "Epoch 155/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 156/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34590s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.\n",
      "Epoch 157/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 158/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34590s - loss: 0.2222 - mean_squared_error: 0.2222\n",
      "Epoch 159/300\n",
      "6062/6062 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3469\n",
      "Epoch 160/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 161/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3469\n",
      "Epoch 162/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3456\n",
      "Epoch 163/300\n",
      "6062/6062 [==============================] - 1s 136us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3487\n",
      "Epoch 164/300\n",
      "6062/6062 [==============================] - 1s 141us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34970s - loss: 0.2219 - mean_squared_error: 0.2219 - acc - ETA: 0s - loss: 0.2222 - mean_squared_error - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 165/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3487\n",
      "Epoch 166/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34870s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 167/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 168/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3466\n",
      "Epoch 169/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 170/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 171/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 172/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 173/300\n",
      "6062/6062 [==============================] - 1s 109us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3484\n",
      "Epoch 174/300\n",
      "6062/6062 [==============================] - 1s 168us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 175/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 176/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3484\n",
      "Epoch 177/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 178/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 179/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 180/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 181/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 182/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 183/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 184/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 185/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 186/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 187/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 188/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 189/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 190/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 191/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3494\n",
      "Epoch 192/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3435\n",
      "Epoch 193/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34820s - loss: 0.2221 - mean_squared_e\n",
      "Epoch 194/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 195/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3496\n",
      "Epoch 196/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 197/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3497\n",
      "Epoch 198/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3538\n",
      "Epoch 199/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 200/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3504\n",
      "Epoch 201/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34580s - loss: 0.2221 - mean_squared_error: 0.2221 - acc - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc\n",
      "Epoch 202/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 203/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 204/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3484\n",
      "Epoch 205/300\n",
      "6062/6062 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 206/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 207/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 208/300\n",
      "6062/6062 [==============================] - 1s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 209/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3484\n",
      "Epoch 210/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3491\n",
      "Epoch 211/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 212/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34760s - loss: 0.2221 - mean_squared_err\n",
      "Epoch 213/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 214/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 215/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 216/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 217/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 218/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3487\n",
      "Epoch 219/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 220/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3464\n",
      "Epoch 221/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 222/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34920s - loss: 0.2221 - mean_squared_error: 0.2221 -\n",
      "Epoch 223/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3464\n",
      "Epoch 224/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 225/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 226/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 227/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3492\n",
      "Epoch 228/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 229/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 230/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 231/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 232/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 233/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3435\n",
      "Epoch 234/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 235/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 236/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3459\n",
      "Epoch 237/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 238/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 239/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34910s - loss: 0.2218 - mean_squared_e\n",
      "Epoch 240/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3461\n",
      "Epoch 241/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34790s - loss: 0.2221 - mean_squared_err\n",
      "Epoch 242/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3454\n",
      "Epoch 243/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 244/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 245/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3449\n",
      "Epoch 246/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 247/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3469\n",
      "Epoch 248/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 249/300\n",
      "6062/6062 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 250/300\n",
      "6062/6062 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3464\n",
      "Epoch 251/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3481\n",
      "Epoch 252/300\n",
      "6062/6062 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34330s - loss: 0.2220 - mean_squared_error: 0.\n",
      "Epoch 253/300\n",
      "6062/6062 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34870s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: \n",
      "Epoch 254/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3532\n",
      "Epoch 255/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 256/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3382\n",
      "Epoch 257/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3439\n",
      "Epoch 258/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3481\n",
      "Epoch 259/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 260/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3486\n",
      "Epoch 261/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 262/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34080s - loss: 0.2219 - mean_squared\n",
      "Epoch 263/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34610s - loss: 0.2220 - mean_squared_e\n",
      "Epoch 264/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 265/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 266/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "Epoch 267/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3458\n",
      "Epoch 268/300\n",
      "6062/6062 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3463\n",
      "Epoch 269/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3489\n",
      "Epoch 270/300\n",
      "6062/6062 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 271/300\n",
      "6062/6062 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3446\n",
      "Epoch 272/300\n",
      "6062/6062 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3463\n",
      "Epoch 273/300\n",
      "6062/6062 [==============================] - 1s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 274/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3471\n",
      "Epoch 275/300\n",
      "6062/6062 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3476\n",
      "Epoch 276/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 277/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3481\n",
      "Epoch 278/300\n",
      "6062/6062 [==============================] - 1s 146us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3451\n",
      "Epoch 279/300\n",
      "6062/6062 [==============================] - 1s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3433\n",
      "Epoch 280/300\n",
      "6062/6062 [==============================] - 1s 145us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3479\n",
      "Epoch 281/300\n",
      "6062/6062 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3504\n",
      "Epoch 282/300\n",
      "6062/6062 [==============================] - 1s 150us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 283/300\n",
      "6062/6062 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3474\n",
      "Epoch 284/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3459\n",
      "Epoch 285/300\n",
      "6062/6062 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3439\n",
      "Epoch 286/300\n",
      "6062/6062 [==============================] - 1s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3474\n",
      "Epoch 287/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3471\n",
      "Epoch 288/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3420\n",
      "Epoch 289/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 290/300\n",
      "6062/6062 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3463\n",
      "Epoch 291/300\n",
      "6062/6062 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3469\n",
      "Epoch 292/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3456\n",
      "Epoch 293/300\n",
      "6062/6062 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34460s - loss: 0.2225 - mean_squared_error\n",
      "Epoch 294/300\n",
      "6062/6062 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 295/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34860s - loss: 0.2224 - mean_squared_error\n",
      "Epoch 296/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3416\n",
      "Epoch 297/300\n",
      "6062/6062 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3436\n",
      "Epoch 298/300\n",
      "6062/6062 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3405\n",
      "Epoch 299/300\n",
      "6062/6062 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34560s - loss: 0.2222 - mean_squared_error: 0.2222 -\n",
      "Epoch 300/300\n",
      "6062/6062 [==============================] - 1s 117us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3451\n",
      "2526/2526 [==============================] - 1s 206us/step\n",
      "6062/6062 [==============================] - 0s 63us/step\n",
      "The Score is 0.336500\n",
      "current iteration fraction: 0.500000\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "(5052, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "5052/5052 [==============================] - 2s 310us/step - loss: 0.2467 - mean_squared_error: 0.2467 - acc: 0.3371\n",
      "Epoch 2/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2321 - mean_squared_error: 0.2321 - acc: 0.3331\n",
      "Epoch 3/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2277 - mean_squared_error: 0.2277 - acc: 0.3369\n",
      "Epoch 4/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2259 - mean_squared_error: 0.2259 - acc: 0.3345\n",
      "Epoch 5/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2250 - mean_squared_error: 0.2250 - acc: 0.3383\n",
      "Epoch 6/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2248 - mean_squared_error: 0.2248 - acc: 0.3379\n",
      "Epoch 7/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3314\n",
      "Epoch 8/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.33850s - loss: 0.2247 - mean_squared_error: \n",
      "Epoch 9/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3371\n",
      "Epoch 10/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3452\n",
      "Epoch 11/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3339\n",
      "Epoch 12/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3329\n",
      "Epoch 13/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3375\n",
      "Epoch 14/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3353\n",
      "Epoch 15/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3325\n",
      "Epoch 16/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3434\n",
      "Epoch 17/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3329\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5052/5052 [==============================] - 1s 139us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3264\n",
      "Epoch 19/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3276\n",
      "Epoch 20/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3367\n",
      "Epoch 21/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.33970s - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.34\n",
      "Epoch 22/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.35110s - loss: 0.2225 - mean_squared_error: \n",
      "Epoch 23/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3268\n",
      "Epoch 24/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3333\n",
      "Epoch 25/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3335\n",
      "Epoch 26/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3369\n",
      "Epoch 27/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.33160s - loss: 0.2224 - mean_squared_error: 0.2224 - a - ETA: 0s - loss: 0.2225 - mean_squared_error: 0.2225\n",
      "Epoch 28/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3405\n",
      "Epoch 29/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3405\n",
      "Epoch 30/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3369\n",
      "Epoch 31/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3446\n",
      "Epoch 32/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3379\n",
      "Epoch 33/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3385\n",
      "Epoch 34/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3418\n",
      "Epoch 35/300\n",
      "5052/5052 [==============================] - 1s 152us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3393\n",
      "Epoch 36/300\n",
      "5052/5052 [==============================] - 1s 144us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3333\n",
      "Epoch 37/300\n",
      "5052/5052 [==============================] - 1s 139us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3288\n",
      "Epoch 38/300\n",
      "5052/5052 [==============================] - 1s 140us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34860s - loss: 0.2222 - mean_squared_error: 0.2222 -\n",
      "Epoch 39/300\n",
      "5052/5052 [==============================] - 1s 146us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3329\n",
      "Epoch 40/300\n",
      "5052/5052 [==============================] - 1s 155us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3478\n",
      "Epoch 41/300\n",
      "5052/5052 [==============================] - 1s 146us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3359\n",
      "Epoch 42/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3446\n",
      "Epoch 43/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3401\n",
      "Epoch 44/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3365\n",
      "Epoch 45/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3442\n",
      "Epoch 46/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3316\n",
      "Epoch 47/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3355\n",
      "Epoch 48/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3399\n",
      "Epoch 49/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3335\n",
      "Epoch 50/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3409\n",
      "Epoch 51/300\n",
      "5052/5052 [==============================] - 1s 154us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3292\n",
      "Epoch 52/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3401\n",
      "Epoch 53/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34620s - loss: 0.2222 - mean_squared_error: 0.2222 - a\n",
      "Epoch 54/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3403\n",
      "Epoch 55/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3409\n",
      "Epoch 56/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34620s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 57/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3329\n",
      "Epoch 58/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3280\n",
      "Epoch 59/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3411\n",
      "Epoch 60/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34440s - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34\n",
      "Epoch 61/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3460\n",
      "Epoch 62/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3409\n",
      "Epoch 63/300\n",
      "5052/5052 [==============================] - 1s 147us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3331\n",
      "Epoch 64/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3377\n",
      "Epoch 65/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3409\n",
      "Epoch 66/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.33490s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 67/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3466\n",
      "Epoch 68/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3327\n",
      "Epoch 69/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 70/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3401\n",
      "Epoch 71/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3256\n",
      "Epoch 72/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34440s - loss: 0.2222 - mean_squared_error: 0.2222 - a\n",
      "Epoch 73/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3458\n",
      "Epoch 74/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3319\n",
      "Epoch 75/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3288\n",
      "Epoch 76/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3331\n",
      "Epoch 77/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3486\n",
      "Epoch 78/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3286\n",
      "Epoch 79/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 80/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 81/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3351\n",
      "Epoch 82/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 83/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3379\n",
      "Epoch 84/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 85/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3347\n",
      "Epoch 86/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3413\n",
      "Epoch 87/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3416\n",
      "Epoch 88/300\n",
      "5052/5052 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3343\n",
      "Epoch 89/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3399\n",
      "Epoch 90/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 91/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3393\n",
      "Epoch 92/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 93/300\n",
      "5052/5052 [==============================] - 1s 156us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 94/300\n",
      "5052/5052 [==============================] - 1s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3504\n",
      "Epoch 95/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3468\n",
      "Epoch 96/300\n",
      "5052/5052 [==============================] - 1s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3399\n",
      "Epoch 97/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3414\n",
      "Epoch 98/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 99/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3335\n",
      "Epoch 100/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 101/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3379\n",
      "Epoch 102/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 103/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3302\n",
      "Epoch 104/300\n",
      "5052/5052 [==============================] - 1s 159us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3357\n",
      "Epoch 105/300\n",
      "5052/5052 [==============================] - 1s 182us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3456\n",
      "Epoch 106/300\n",
      "5052/5052 [==============================] - 1s 170us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3363\n",
      "Epoch 107/300\n",
      "5052/5052 [==============================] - 1s 161us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 108/300\n",
      "5052/5052 [==============================] - 1s 147us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34073s - loss: 0.2222 - mean_squared_e\n",
      "Epoch 109/300\n",
      "5052/5052 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3345\n",
      "Epoch 110/300\n",
      "5052/5052 [==============================] - 1s 143us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3420\n",
      "Epoch 111/300\n",
      "5052/5052 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 112/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 113/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 114/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3399\n",
      "Epoch 115/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 116/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 117/300\n",
      "5052/5052 [==============================] - 1s 148us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3414\n",
      "Epoch 118/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3308\n",
      "Epoch 119/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3369\n",
      "Epoch 120/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 121/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 122/300\n",
      "5052/5052 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3399\n",
      "Epoch 123/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3438\n",
      "Epoch 124/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3478\n",
      "Epoch 125/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 126/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3424\n",
      "Epoch 127/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3339\n",
      "Epoch 128/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3424\n",
      "Epoch 129/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3349\n",
      "Epoch 130/300\n",
      "5052/5052 [==============================] - 1s 135us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3383\n",
      "Epoch 131/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 132/300\n",
      "5052/5052 [==============================] - 1s 146us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 133/300\n",
      "5052/5052 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3399\n",
      "Epoch 134/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3339\n",
      "Epoch 135/300\n",
      "5052/5052 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34 - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 136/300\n",
      "5052/5052 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3470\n",
      "Epoch 137/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 138/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3357\n",
      "Epoch 139/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3252\n",
      "Epoch 140/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3333\n",
      "Epoch 141/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3393\n",
      "Epoch 142/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3304\n",
      "Epoch 143/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 144/300\n",
      "5052/5052 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 145/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 146/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3454\n",
      "Epoch 147/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 148/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3502\n",
      "Epoch 149/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 150/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34110s - loss: 0.2223 - mean_squared_error:  - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 151/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3272\n",
      "Epoch 152/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34180s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33\n",
      "Epoch 153/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3294\n",
      "Epoch 154/300\n",
      "5052/5052 [==============================] - 1s 143us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3488\n",
      "Epoch 155/300\n",
      "5052/5052 [==============================] - 1s 127us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3411\n",
      "Epoch 156/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3363\n",
      "Epoch 157/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3357\n",
      "Epoch 158/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3492\n",
      "Epoch 159/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3375\n",
      "Epoch 160/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3361\n",
      "Epoch 161/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3418\n",
      "Epoch 162/300\n",
      "5052/5052 [==============================] - 1s 181us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3377\n",
      "Epoch 163/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 164/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3448\n",
      "Epoch 165/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 166/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3314\n",
      "Epoch 167/300\n",
      "5052/5052 [==============================] - 1s 130us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 168/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3444\n",
      "Epoch 169/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3341\n",
      "Epoch 170/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3252\n",
      "Epoch 171/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3302\n",
      "Epoch 172/300\n",
      "5052/5052 [==============================] - 1s 133us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33650s - loss: 0.2222 - mean_squared_error: 0.2222 - acc\n",
      "Epoch 173/300\n",
      "5052/5052 [==============================] - 1s 142us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3438\n",
      "Epoch 174/300\n",
      "5052/5052 [==============================] - 1s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3321\n",
      "Epoch 175/300\n",
      "5052/5052 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 176/300\n",
      "5052/5052 [==============================] - 1s 156us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33930s - loss: 0.2223 - mean_squared\n",
      "Epoch 177/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3369\n",
      "Epoch 178/300\n",
      "5052/5052 [==============================] - 1s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3367\n",
      "Epoch 179/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3341\n",
      "Epoch 180/300\n",
      "5052/5052 [==============================] - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34 - 1s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3430\n",
      "Epoch 181/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3409\n",
      "Epoch 182/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3371\n",
      "Epoch 183/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3397\n",
      "Epoch 184/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3355\n",
      "Epoch 185/300\n",
      "5052/5052 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3482\n",
      "Epoch 186/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3345\n",
      "Epoch 187/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3345\n",
      "Epoch 188/300\n",
      "5052/5052 [==============================] - 1s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 189/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3411\n",
      "Epoch 190/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3215\n",
      "Epoch 191/300\n",
      "5052/5052 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3411\n",
      "Epoch 192/300\n",
      "5052/5052 [==============================] - 1s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3351\n",
      "Epoch 193/300\n",
      "5052/5052 [==============================] - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 194/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3367\n",
      "Epoch 195/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3373\n",
      "Epoch 196/300\n",
      "5052/5052 [==============================] - 1s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3414\n",
      "Epoch 197/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3343\n",
      "Epoch 198/300\n",
      "5052/5052 [==============================] - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33 - 1s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3432\n",
      "Epoch 200/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3409\n",
      "Epoch 201/300\n",
      "5052/5052 [==============================] - 1s 107us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3434\n",
      "Epoch 202/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3409\n",
      "Epoch 203/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3343\n",
      "Epoch 204/300\n",
      "5052/5052 [==============================] - 0s 93us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3395\n",
      "Epoch 205/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3403\n",
      "Epoch 206/300\n",
      "5052/5052 [==============================] - 0s 94us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 207/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 208/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 209/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3448\n",
      "Epoch 210/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33430s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: \n",
      "Epoch 211/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3345\n",
      "Epoch 212/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 213/300\n",
      "5052/5052 [==============================] - 0s 95us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3486\n",
      "Epoch 214/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3369\n",
      "Epoch 215/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3504\n",
      "Epoch 216/300\n",
      "5052/5052 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34280s - loss: 0.2220 - mean_squared_error\n",
      "Epoch 217/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 218/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 219/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 220/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3379\n",
      "Epoch 221/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3371\n",
      "Epoch 222/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3230\n",
      "Epoch 223/300\n",
      "5052/5052 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3426\n",
      "Epoch 224/300\n",
      "5052/5052 [==============================] - 0s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3401\n",
      "Epoch 225/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3333\n",
      "Epoch 226/300\n",
      "5052/5052 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 227/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3418\n",
      "Epoch 228/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3450\n",
      "Epoch 229/300\n",
      "5052/5052 [==============================] - 1s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3312\n",
      "Epoch 230/300\n",
      "5052/5052 [==============================] - 0s 91us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 231/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 232/300\n",
      "5052/5052 [==============================] - 0s 96us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3361\n",
      "Epoch 233/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3478\n",
      "Epoch 234/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3300\n",
      "Epoch 235/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3442\n",
      "Epoch 236/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3300\n",
      "Epoch 237/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33170s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.\n",
      "Epoch 238/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 239/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3327\n",
      "Epoch 240/300\n",
      "5052/5052 [==============================] - 1s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3468\n",
      "Epoch 241/300\n",
      "5052/5052 [==============================] - 1s 134us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3409\n",
      "Epoch 242/300\n",
      "5052/5052 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3405\n",
      "Epoch 243/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3329\n",
      "Epoch 244/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3428\n",
      "Epoch 245/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3430\n",
      "Epoch 246/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 247/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.32660s - loss: 0.2222 - mean_squared_error: \n",
      "Epoch 248/300\n",
      "5052/5052 [==============================] - 1s 106us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3389\n",
      "Epoch 249/300\n",
      "5052/5052 [==============================] - 1s 136us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3391\n",
      "Epoch 250/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3444\n",
      "Epoch 251/300\n",
      "5052/5052 [==============================] - 1s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3401\n",
      "Epoch 252/300\n",
      "5052/5052 [==============================] - 1s 145us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3321\n",
      "Epoch 253/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 254/300\n",
      "5052/5052 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33930s - loss: 0.2222 - mean_squared_error: 0.\n",
      "Epoch 255/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 256/300\n",
      "5052/5052 [==============================] - 1s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3278\n",
      "Epoch 257/300\n",
      "5052/5052 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3314\n",
      "Epoch 258/300\n",
      "5052/5052 [==============================] - 1s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3405\n",
      "Epoch 259/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3484\n",
      "Epoch 260/300\n",
      "5052/5052 [==============================] - 1s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3430\n",
      "Epoch 261/300\n",
      "5052/5052 [==============================] - 0s 92us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3504\n",
      "Epoch 262/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3296\n",
      "Epoch 263/300\n",
      "5052/5052 [==============================] - 0s 89us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3294\n",
      "Epoch 264/300\n",
      "5052/5052 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 265/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34280s - loss: 0.2224 - mean_squared_error: \n",
      "Epoch 266/300\n",
      "5052/5052 [==============================] - 1s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3470\n",
      "Epoch 267/300\n",
      "5052/5052 [==============================] - 1s 115us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3420\n",
      "Epoch 268/300\n",
      "5052/5052 [==============================] - 1s 102us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3434\n",
      "Epoch 269/300\n",
      "5052/5052 [==============================] - 1s 108us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3252\n",
      "Epoch 270/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 271/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3377\n",
      "Epoch 272/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34540s - loss: 0.2224 - mean_squared_error: 0.\n",
      "Epoch 273/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34180s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34\n",
      "Epoch 274/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34130s - loss: 0.2221 - mean_squared_error: 0.\n",
      "Epoch 275/300\n",
      "5052/5052 [==============================] - 1s 132us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3420\n",
      "Epoch 276/300\n",
      "5052/5052 [==============================] - 1s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3391\n",
      "Epoch 277/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 278/300\n",
      "5052/5052 [==============================] - 0s 98us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 279/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 280/300\n",
      "5052/5052 [==============================] - 0s 98us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 281/300\n",
      "5052/5052 [==============================] - 1s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 282/300\n",
      "5052/5052 [==============================] - 1s 109us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 283/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3379\n",
      "Epoch 284/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3331\n",
      "Epoch 285/300\n",
      "5052/5052 [==============================] - 1s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3288\n",
      "Epoch 286/300\n",
      "5052/5052 [==============================] - 1s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3304\n",
      "Epoch 287/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3355\n",
      "Epoch 288/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3387\n",
      "Epoch 289/300\n",
      "5052/5052 [==============================] - 1s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3422\n",
      "Epoch 290/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3349\n",
      "Epoch 291/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3389\n",
      "Epoch 292/300\n",
      "5052/5052 [==============================] - 1s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3274\n",
      "Epoch 293/300\n",
      "5052/5052 [==============================] - 1s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3403\n",
      "Epoch 294/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3379\n",
      "Epoch 295/300\n",
      "5052/5052 [==============================] - 1s 106us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3430\n",
      "Epoch 296/300\n",
      "5052/5052 [==============================] - 1s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3343\n",
      "Epoch 297/300\n",
      "5052/5052 [==============================] - 1s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3424\n",
      "Epoch 298/300\n",
      "5052/5052 [==============================] - 1s 121us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3397\n",
      "Epoch 299/300\n",
      "5052/5052 [==============================] - 1s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33810s - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.33\n",
      "Epoch 300/300\n",
      "5052/5052 [==============================] - 1s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33210s - loss: 0.2220 - mean_squared_error: 0.2220 -\n",
      "2526/2526 [==============================] - 0s 186us/step\n",
      "5052/5052 [==============================] - 0s 43us/step\n",
      "The Score is 0.341251\n",
      "current iteration fraction: 0.400000\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "(4041, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4041/4041 [==============================] - 1s 351us/step - loss: 0.2536 - mean_squared_error: 0.2536 - acc: 0.33041s - loss: 0.2648 - mean_squared_error: 0.2648 - a\n",
      "Epoch 2/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2361 - mean_squared_error: 0.2361 - acc: 0.3375\n",
      "Epoch 3/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2299 - mean_squared_error: 0.2299 - acc: 0.3388\n",
      "Epoch 4/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2288 - mean_squared_error: 0.2288 - acc: 0.3375\n",
      "Epoch 5/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.2283 - mean_squared_error: 0.2283 - acc: 0.3286\n",
      "Epoch 6/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2265 - mean_squared_error: 0.2265 - acc: 0.3175\n",
      "Epoch 7/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2256 - mean_squared_error: 0.2256 - acc: 0.3328\n",
      "Epoch 8/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2246 - mean_squared_error: 0.2246 - acc: 0.3301\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3469\n",
      "Epoch 10/300\n",
      "4041/4041 [==============================] - 0s 101us/step - loss: 0.2247 - mean_squared_error: 0.2247 - acc: 0.3267\n",
      "Epoch 11/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2247 - mean_squared_error: 0.2247 - acc: 0.3373\n",
      "Epoch 12/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3279\n",
      "Epoch 13/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3333\n",
      "Epoch 14/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3390\n",
      "Epoch 15/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3415\n",
      "Epoch 16/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3415\n",
      "Epoch 17/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3318\n",
      "Epoch 18/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3252\n",
      "Epoch 19/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3227\n",
      "Epoch 20/300\n",
      "4041/4041 [==============================] - 1s 142us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3336\n",
      "Epoch 21/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3276\n",
      "Epoch 22/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3361\n",
      "Epoch 23/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3368\n",
      "Epoch 24/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3318\n",
      "Epoch 25/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3331\n",
      "Epoch 26/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3469\n",
      "Epoch 27/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3366\n",
      "Epoch 28/300\n",
      "4041/4041 [==============================] - 1s 136us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3338\n",
      "Epoch 29/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3318\n",
      "Epoch 30/300\n",
      "4041/4041 [==============================] - 0s 97us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3361\n",
      "Epoch 31/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3398\n",
      "Epoch 32/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3351\n",
      "Epoch 33/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3378\n",
      "Epoch 34/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3383\n",
      "Epoch 35/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3415\n",
      "Epoch 36/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3336\n",
      "Epoch 37/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3442\n",
      "Epoch 38/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3286\n",
      "Epoch 39/300\n",
      "4041/4041 [==============================] - 0s 91us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3326\n",
      "Epoch 40/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3445\n",
      "Epoch 41/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3309\n",
      "Epoch 42/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3328\n",
      "Epoch 43/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3464\n",
      "Epoch 44/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.34000s - loss: 0.2222 - mean_squared_error: 0.\n",
      "Epoch 45/300\n",
      "4041/4041 [==============================] - 0s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3390\n",
      "Epoch 46/300\n",
      "4041/4041 [==============================] - 0s 96us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3353 0s - loss: 0.2233 - mean_squared_error: 0.2233 - acc\n",
      "Epoch 47/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3410\n",
      "Epoch 48/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3388\n",
      "Epoch 49/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3395\n",
      "Epoch 50/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3440\n",
      "Epoch 51/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3271\n",
      "Epoch 52/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3321\n",
      "Epoch 53/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3257\n",
      "Epoch 54/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3380\n",
      "Epoch 55/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3403\n",
      "Epoch 56/300\n",
      "4041/4041 [==============================] - 1s 141us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3343\n",
      "Epoch 57/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3422\n",
      "Epoch 58/300\n",
      "4041/4041 [==============================] - 1s 140us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3328\n",
      "Epoch 59/300\n",
      "4041/4041 [==============================] - 1s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3455\n",
      "Epoch 60/300\n",
      "4041/4041 [==============================] - 1s 140us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3405\n",
      "Epoch 61/300\n",
      "4041/4041 [==============================] - 1s 129us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3427\n",
      "Epoch 62/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3281\n",
      "Epoch 63/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3430\n",
      "Epoch 64/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3442\n",
      "Epoch 65/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3299\n",
      "Epoch 66/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3269\n",
      "Epoch 67/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3296\n",
      "Epoch 68/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3442\n",
      "Epoch 69/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3370\n",
      "Epoch 70/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3356\n",
      "Epoch 71/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33330s - loss: 0.2224 - mean_squared_error: 0.2224 - a\n",
      "Epoch 72/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3410\n",
      "Epoch 73/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3385\n",
      "Epoch 74/300\n",
      "4041/4041 [==============================] - 0s 109us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3417\n",
      "Epoch 75/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3427\n",
      "Epoch 76/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3361\n",
      "Epoch 77/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3343\n",
      "Epoch 78/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3425\n",
      "Epoch 79/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3383\n",
      "Epoch 80/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3427\n",
      "Epoch 81/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3390\n",
      "Epoch 82/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3356\n",
      "Epoch 83/300\n",
      "4041/4041 [==============================] - 0s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3432\n",
      "Epoch 84/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3410\n",
      "Epoch 85/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3259\n",
      "Epoch 86/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3385\n",
      "Epoch 87/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3445\n",
      "Epoch 88/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3264\n",
      "Epoch 89/300\n",
      "4041/4041 [==============================] - 0s 96us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3351\n",
      "Epoch 90/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3361\n",
      "Epoch 91/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3361\n",
      "Epoch 92/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3467\n",
      "Epoch 93/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3252\n",
      "Epoch 94/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3276\n",
      "Epoch 95/300\n",
      "4041/4041 [==============================] - 1s 134us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3323\n",
      "Epoch 96/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3393\n",
      "Epoch 97/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.33360s - loss: 0.2226 - mean_squared_error: 0.2226 - a\n",
      "Epoch 98/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 99/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3343\n",
      "Epoch 100/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3370\n",
      "Epoch 101/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3435\n",
      "Epoch 102/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3291\n",
      "Epoch 103/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3393\n",
      "Epoch 104/300\n",
      "4041/4041 [==============================] - 1s 132us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3474\n",
      "Epoch 105/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33630s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33\n",
      "Epoch 106/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3393\n",
      "Epoch 107/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3343\n",
      "Epoch 108/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 109/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3445\n",
      "Epoch 110/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3358\n",
      "Epoch 111/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3336\n",
      "Epoch 112/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3413\n",
      "Epoch 113/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3437\n",
      "Epoch 114/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3462\n",
      "Epoch 115/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 116/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3487\n",
      "Epoch 117/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3417\n",
      "Epoch 118/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3388\n",
      "Epoch 119/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 120/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3336\n",
      "Epoch 121/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3338\n",
      "Epoch 122/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3336\n",
      "Epoch 123/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3314\n",
      "Epoch 124/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3393\n",
      "Epoch 125/300\n",
      "4041/4041 [==============================] - 1s 152us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33310s - loss: 0.2222 - mean_squared_error: 0.2222 - acc\n",
      "Epoch 126/300\n",
      "4041/4041 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 127/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34130s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 128/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 129/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 130/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3323\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3351\n",
      "Epoch 132/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3346\n",
      "Epoch 133/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3375\n",
      "Epoch 134/300\n",
      "4041/4041 [==============================] - 0s 93us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 135/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 136/300\n",
      "4041/4041 [==============================] - 0s 87us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 137/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 138/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3346\n",
      "Epoch 139/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 140/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3455\n",
      "Epoch 141/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 142/300\n",
      "4041/4041 [==============================] - 0s 97us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 143/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3427\n",
      "Epoch 144/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3435\n",
      "Epoch 145/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 146/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3410\n",
      "Epoch 147/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3358\n",
      "Epoch 148/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3489\n",
      "Epoch 149/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3393\n",
      "Epoch 150/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 151/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 152/300\n",
      "4041/4041 [==============================] - 0s 88us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 153/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 154/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 155/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3435\n",
      "Epoch 156/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 157/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 158/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3462\n",
      "Epoch 159/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 160/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 161/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 162/300\n",
      "4041/4041 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 163/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 164/300\n",
      "4041/4041 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 165/300\n",
      "4041/4041 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 166/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 167/300\n",
      "4041/4041 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 168/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3435\n",
      "Epoch 169/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3435\n",
      "Epoch 170/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3435\n",
      "Epoch 171/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3430\n",
      "Epoch 172/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 173/300\n",
      "4041/4041 [==============================] - 0s 106us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3408\n",
      "Epoch 174/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3358\n",
      "Epoch 175/300\n",
      "4041/4041 [==============================] - 0s 99us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3368\n",
      "Epoch 176/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3497\n",
      "Epoch 177/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3410\n",
      "Epoch 178/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3417\n",
      "Epoch 179/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 180/300\n",
      "4041/4041 [==============================] - 0s 106us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3336\n",
      "Epoch 181/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 182/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 183/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3457\n",
      "Epoch 184/300\n",
      "4041/4041 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34 - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3447\n",
      "Epoch 185/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 186/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3445\n",
      "Epoch 187/300\n",
      "4041/4041 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 188/300\n",
      "4041/4041 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3445\n",
      "Epoch 189/300\n",
      "4041/4041 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33180s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.\n",
      "Epoch 190/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 191/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 192/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3385\n",
      "Epoch 193/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3519\n",
      "Epoch 194/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3378\n",
      "Epoch 195/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3333\n",
      "Epoch 196/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3393\n",
      "Epoch 197/300\n",
      "4041/4041 [==============================] - 0s 109us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3351\n",
      "Epoch 198/300\n",
      "4041/4041 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 199/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3373\n",
      "Epoch 200/300\n",
      "4041/4041 [==============================] - 0s 105us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3462\n",
      "Epoch 201/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 202/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3217\n",
      "Epoch 203/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3353\n",
      "Epoch 204/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3484\n",
      "Epoch 205/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34150s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.35 - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 -\n",
      "Epoch 206/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 207/300\n",
      "4041/4041 [==============================] - 0s 94us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375 0s - loss: 0.2223 - mean_squared_error: 0.2223\n",
      "Epoch 208/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 209/300\n",
      "4041/4041 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 210/300\n",
      "4041/4041 [==============================] - 0s 106us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 211/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 212/300\n",
      "4041/4041 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 213/300\n",
      "4041/4041 [==============================] - 0s 93us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 214/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 215/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 216/300\n",
      "4041/4041 [==============================] - 0s 98us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 217/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 218/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 219/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 220/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 221/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3482\n",
      "Epoch 222/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3408\n",
      "Epoch 223/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3405\n",
      "Epoch 224/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3455\n",
      "Epoch 225/300\n",
      "4041/4041 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 226/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3474\n",
      "Epoch 227/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3422\n",
      "Epoch 228/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34150s - loss: 0.2219 - mean_squared_error: 0.\n",
      "Epoch 229/300\n",
      "4041/4041 [==============================] - 0s 106us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3403\n",
      "Epoch 230/300\n",
      "4041/4041 [==============================] - 0s 101us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 231/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3390\n",
      "Epoch 232/300\n",
      "4041/4041 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 233/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 234/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 235/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3452\n",
      "Epoch 236/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3405\n",
      "Epoch 237/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 238/300\n",
      "4041/4041 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 239/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3380\n",
      "Epoch 240/300\n",
      "4041/4041 [==============================] - 0s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 241/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 242/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 243/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 244/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3472\n",
      "Epoch 245/300\n",
      "4041/4041 [==============================] - 0s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3403\n",
      "Epoch 246/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3445\n",
      "Epoch 247/300\n",
      "4041/4041 [==============================] - 0s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 248/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3410\n",
      "Epoch 249/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3420\n",
      "Epoch 250/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 251/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 252/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041/4041 [==============================] - 0s 96us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3425\n",
      "Epoch 254/300\n",
      "4041/4041 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 255/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 256/300\n",
      "4041/4041 [==============================] - 0s 109us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3420\n",
      "Epoch 257/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3457\n",
      "Epoch 258/300\n",
      "4041/4041 [==============================] - 0s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3430 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.\n",
      "Epoch 259/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 260/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3442\n",
      "Epoch 261/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3452\n",
      "Epoch 262/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 263/300\n",
      "4041/4041 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3403\n",
      "Epoch 264/300\n",
      "4041/4041 [==============================] - 0s 123us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3445\n",
      "Epoch 265/300\n",
      "4041/4041 [==============================] - 0s 114us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 266/300\n",
      "4041/4041 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3452\n",
      "Epoch 267/300\n",
      "4041/4041 [==============================] - 0s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 268/300\n",
      "4041/4041 [==============================] - 0s 93us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 269/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 270/300\n",
      "4041/4041 [==============================] - 0s 86us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3420\n",
      "Epoch 271/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3291\n",
      "Epoch 272/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3405\n",
      "Epoch 273/300\n",
      "4041/4041 [==============================] - 0s 100us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3281\n",
      "Epoch 274/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 275/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 276/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 277/300\n",
      "4041/4041 [==============================] - 0s 90us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3351\n",
      "Epoch 278/300\n",
      "4041/4041 [==============================] - 0s 116us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3254\n",
      "Epoch 279/300\n",
      "4041/4041 [==============================] - 0s 103us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3373\n",
      "Epoch 280/300\n",
      "4041/4041 [==============================] - ETA: 0s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33 - 0s 101us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3378\n",
      "Epoch 281/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3440\n",
      "Epoch 282/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3373\n",
      "Epoch 283/300\n",
      "4041/4041 [==============================] - 1s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3331\n",
      "Epoch 284/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3378\n",
      "Epoch 285/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3346\n",
      "Epoch 286/300\n",
      "4041/4041 [==============================] - 0s 110us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3363\n",
      "Epoch 287/300\n",
      "4041/4041 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3326\n",
      "Epoch 288/300\n",
      "4041/4041 [==============================] - 0s 95us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 289/300\n",
      "4041/4041 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3430\n",
      "Epoch 290/300\n",
      "4041/4041 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3343\n",
      "Epoch 291/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3425\n",
      "Epoch 292/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 293/300\n",
      "4041/4041 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3358\n",
      "Epoch 294/300\n",
      "4041/4041 [==============================] - 0s 113us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3410\n",
      "Epoch 295/300\n",
      "4041/4041 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 296/300\n",
      "4041/4041 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3447\n",
      "Epoch 297/300\n",
      "4041/4041 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 298/300\n",
      "4041/4041 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 299/300\n",
      "4041/4041 [==============================] - 0s 98us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3442\n",
      "Epoch 300/300\n",
      "4041/4041 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3455\n",
      "2526/2526 [==============================] - 0s 192us/step\n",
      "4041/4041 [==============================] - 0s 51us/step\n",
      "The Score is 0.332937\n",
      "current iteration fraction: 0.300000\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "(3031, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "3031/3031 [==============================] - 1s 448us/step - loss: 0.2503 - mean_squared_error: 0.2503 - acc: 0.3263\n",
      "Epoch 2/300\n",
      "3031/3031 [==============================] - 0s 135us/step - loss: 0.2408 - mean_squared_error: 0.2408 - acc: 0.32560s - loss: 0.2440 - mean_squared_error: 0.2440 - a\n",
      "Epoch 3/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2355 - mean_squared_error: 0.2355 - acc: 0.3319\n",
      "Epoch 4/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2311 - mean_squared_error: 0.2311 - acc: 0.3256\n",
      "Epoch 5/300\n",
      "3031/3031 [==============================] - 0s 84us/step - loss: 0.2271 - mean_squared_error: 0.2271 - acc: 0.3372\n",
      "Epoch 6/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2265 - mean_squared_error: 0.2265 - acc: 0.3418\n",
      "Epoch 7/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2254 - mean_squared_error: 0.2254 - acc: 0.3448\n",
      "Epoch 8/300\n",
      "3031/3031 [==============================] - 0s 89us/step - loss: 0.2254 - mean_squared_error: 0.2254 - acc: 0.3204\n",
      "Epoch 9/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2247 - mean_squared_error: 0.2247 - acc: 0.3411\n",
      "Epoch 10/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2247 - mean_squared_error: 0.2247 - acc: 0.33750s - loss: 0.2236 - mean_squared_error: 0.2236 -\n",
      "Epoch 11/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3256\n",
      "Epoch 12/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.2245 - mean_squared_error: 0.2245 - acc: 0.3332\n",
      "Epoch 13/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2246 - mean_squared_error: 0.2246 - acc: 0.3329\n",
      "Epoch 14/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3428\n",
      "Epoch 15/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3388\n",
      "Epoch 16/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3111\n",
      "Epoch 17/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3487\n",
      "Epoch 18/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3365\n",
      "Epoch 19/300\n",
      "3031/3031 [==============================] - 0s 104us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3481\n",
      "Epoch 20/300\n",
      "3031/3031 [==============================] - 0s 95us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3375\n",
      "Epoch 21/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3306\n",
      "Epoch 22/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3210\n",
      "Epoch 23/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3438\n",
      "Epoch 24/300\n",
      "3031/3031 [==============================] - 1s 166us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3382\n",
      "Epoch 25/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3448\n",
      "Epoch 26/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.34050s - loss: 0.2237 - mean_squared_error: 0.2237 - a\n",
      "Epoch 27/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3491\n",
      "Epoch 28/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3382\n",
      "Epoch 29/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3319\n",
      "Epoch 30/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3260\n",
      "Epoch 31/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3240\n",
      "Epoch 32/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3382\n",
      "Epoch 33/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3398\n",
      "Epoch 34/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3270\n",
      "Epoch 35/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3339\n",
      "Epoch 36/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3352\n",
      "Epoch 37/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3365\n",
      "Epoch 38/300\n",
      "3031/3031 [==============================] - 0s 148us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3339\n",
      "Epoch 39/300\n",
      "3031/3031 [==============================] - 0s 138us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3336\n",
      "Epoch 40/300\n",
      "3031/3031 [==============================] - 0s 146us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3237\n",
      "Epoch 41/300\n",
      "3031/3031 [==============================] - 0s 133us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3319\n",
      "Epoch 42/300\n",
      "3031/3031 [==============================] - 0s 109us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3342\n",
      "Epoch 43/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3309\n",
      "Epoch 44/300\n",
      "3031/3031 [==============================] - 0s 133us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3375\n",
      "Epoch 45/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3415\n",
      "Epoch 46/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3359\n",
      "Epoch 47/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3283\n",
      "Epoch 48/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3461\n",
      "Epoch 49/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3345\n",
      "Epoch 50/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3458\n",
      "Epoch 51/300\n",
      "3031/3031 [==============================] - 0s 101us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3336\n",
      "Epoch 52/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3454\n",
      "Epoch 53/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 54/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3263\n",
      "Epoch 55/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3289\n",
      "Epoch 56/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3408\n",
      "Epoch 57/300\n",
      "3031/3031 [==============================] - 0s 123us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3355\n",
      "Epoch 58/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3329\n",
      "Epoch 59/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3494\n",
      "Epoch 60/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.33880s - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.33\n",
      "Epoch 61/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3497\n",
      "Epoch 62/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3418\n",
      "Epoch 63/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3382\n",
      "Epoch 64/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3415\n",
      "Epoch 65/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3283\n",
      "Epoch 67/300\n",
      "3031/3031 [==============================] - 0s 83us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3319\n",
      "Epoch 68/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3246\n",
      "Epoch 69/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3319\n",
      "Epoch 70/300\n",
      "3031/3031 [==============================] - 0s 106us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3345\n",
      "Epoch 71/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3319\n",
      "Epoch 72/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3378\n",
      "Epoch 73/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3309\n",
      "Epoch 74/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3378\n",
      "Epoch 75/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3444\n",
      "Epoch 76/300\n",
      "3031/3031 [==============================] - ETA: 0s - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.33 - 0s 121us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3329\n",
      "Epoch 77/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3365\n",
      "Epoch 78/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3299\n",
      "Epoch 79/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3303\n",
      "Epoch 80/300\n",
      "3031/3031 [==============================] - 0s 86us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3339\n",
      "Epoch 81/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3435\n",
      "Epoch 82/300\n",
      "3031/3031 [==============================] - 0s 141us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3497\n",
      "Epoch 83/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3296\n",
      "Epoch 84/300\n",
      "3031/3031 [==============================] - 1s 165us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3385\n",
      "Epoch 85/300\n",
      "3031/3031 [==============================] - 1s 166us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34150s - loss: 0.2226 - mean_squared_error: 0.22\n",
      "Epoch 86/300\n",
      "3031/3031 [==============================] - 1s 241us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3342\n",
      "Epoch 87/300\n",
      "3031/3031 [==============================] - 1s 208us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3444\n",
      "Epoch 88/300\n",
      "3031/3031 [==============================] - 1s 187us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3415\n",
      "Epoch 89/300\n",
      "3031/3031 [==============================] - 1s 198us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3204\n",
      "Epoch 90/300\n",
      "3031/3031 [==============================] - 1s 198us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3312\n",
      "Epoch 91/300\n",
      "3031/3031 [==============================] - 0s 154us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3408\n",
      "Epoch 92/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3418\n",
      "Epoch 93/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3296\n",
      "Epoch 94/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3365\n",
      "Epoch 95/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3316\n",
      "Epoch 96/300\n",
      "3031/3031 [==============================] - 0s 142us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3326\n",
      "Epoch 97/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34510s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: \n",
      "Epoch 98/300\n",
      "3031/3031 [==============================] - 0s 139us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3329\n",
      "Epoch 99/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3504\n",
      "Epoch 100/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3253\n",
      "Epoch 101/300\n",
      "3031/3031 [==============================] - 0s 106us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3451\n",
      "Epoch 102/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3352\n",
      "Epoch 103/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3309\n",
      "Epoch 104/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3243\n",
      "Epoch 105/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.34110s - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.34\n",
      "Epoch 106/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3263\n",
      "Epoch 107/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3372\n",
      "Epoch 108/300\n",
      "3031/3031 [==============================] - 0s 101us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3458\n",
      "Epoch 109/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3260\n",
      "Epoch 110/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3312\n",
      "Epoch 111/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3458\n",
      "Epoch 112/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3375\n",
      "Epoch 113/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3349\n",
      "Epoch 114/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3405\n",
      "Epoch 115/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3349\n",
      "Epoch 116/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3319\n",
      "Epoch 117/300\n",
      "3031/3031 [==============================] - 0s 104us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3296\n",
      "Epoch 118/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3441\n",
      "Epoch 119/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3500\n",
      "Epoch 120/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3369\n",
      "Epoch 121/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3177\n",
      "Epoch 122/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3438\n",
      "Epoch 123/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3309\n",
      "Epoch 124/300\n",
      "3031/3031 [==============================] - 0s 108us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34480s - loss: 0.2223 - mean_squared_error: 0.2223 - acc\n",
      "Epoch 125/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3309\n",
      "Epoch 126/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3293\n",
      "Epoch 127/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3349\n",
      "Epoch 128/300\n",
      "3031/3031 [==============================] - 0s 93us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3468\n",
      "Epoch 129/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3418\n",
      "Epoch 130/300\n",
      "3031/3031 [==============================] - 0s 141us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3316\n",
      "Epoch 131/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3243\n",
      "Epoch 132/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34410s - loss: 0.2218 - mean_squared_error: 0.2218 - acc: 0.37 - ETA: 0s - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.35 - ETA: 0s - loss: 0.2220 - mean_squared_error: 0.2220 - acc:  - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 133/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3316\n",
      "Epoch 134/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3322\n",
      "Epoch 135/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3408\n",
      "Epoch 136/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3359\n",
      "Epoch 137/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 138/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3355\n",
      "Epoch 139/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3345\n",
      "Epoch 140/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3369\n",
      "Epoch 141/300\n",
      "3031/3031 [==============================] - 0s 146us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3464\n",
      "Epoch 142/300\n",
      "3031/3031 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3355\n",
      "Epoch 143/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3256\n",
      "Epoch 144/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3408\n",
      "Epoch 145/300\n",
      "3031/3031 [==============================] - 0s 109us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3435\n",
      "Epoch 146/300\n",
      "3031/3031 [==============================] - 0s 87us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3510\n",
      "Epoch 147/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3246\n",
      "Epoch 148/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3276\n",
      "Epoch 149/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3385\n",
      "Epoch 150/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3369\n",
      "Epoch 151/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3316\n",
      "Epoch 152/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3369\n",
      "Epoch 153/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 154/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3402\n",
      "Epoch 155/300\n",
      "3031/3031 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 156/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3336\n",
      "Epoch 157/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 158/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3312\n",
      "Epoch 159/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3372\n",
      "Epoch 160/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3464\n",
      "Epoch 161/300\n",
      "3031/3031 [==============================] - 0s 85us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3425\n",
      "Epoch 162/300\n",
      "3031/3031 [==============================] - 0s 109us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3339\n",
      "Epoch 163/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3230\n",
      "Epoch 164/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3345\n",
      "Epoch 165/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3326\n",
      "Epoch 166/300\n",
      "3031/3031 [==============================] - 0s 110us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3395\n",
      "Epoch 167/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3385\n",
      "Epoch 168/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3329\n",
      "Epoch 169/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3306\n",
      "Epoch 170/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3359\n",
      "Epoch 171/300\n",
      "3031/3031 [==============================] - 0s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3421\n",
      "Epoch 172/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3256\n",
      "Epoch 173/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 174/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3345\n",
      "Epoch 175/300\n",
      "3031/3031 [==============================] - 0s 107us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3266\n",
      "Epoch 176/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3303\n",
      "Epoch 177/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 178/300\n",
      "3031/3031 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 179/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3319\n",
      "Epoch 180/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3428\n",
      "Epoch 181/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34740s - loss: 0.2221 - mean_squared_error: 0.2221 - acc\n",
      "Epoch 182/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 183/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 184/300\n",
      "3031/3031 [==============================] - 0s 135us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3524\n",
      "Epoch 185/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3349\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3355\n",
      "Epoch 187/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3454\n",
      "Epoch 188/300\n",
      "3031/3031 [==============================] - 0s 111us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3326\n",
      "Epoch 189/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3388\n",
      "Epoch 190/300\n",
      "3031/3031 [==============================] - 0s 98us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3372\n",
      "Epoch 191/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 192/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3312\n",
      "Epoch 193/300\n",
      "3031/3031 [==============================] - 0s 98us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3392\n",
      "Epoch 194/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3441\n",
      "Epoch 195/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3520\n",
      "Epoch 196/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3362\n",
      "Epoch 197/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3425\n",
      "Epoch 198/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3289\n",
      "Epoch 199/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3471\n",
      "Epoch 200/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3273\n",
      "Epoch 201/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3345\n",
      "Epoch 202/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3365\n",
      "Epoch 203/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3375\n",
      "Epoch 204/300\n",
      "3031/3031 [==============================] - 0s 96us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3365\n",
      "Epoch 205/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3428\n",
      "Epoch 206/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3286\n",
      "Epoch 207/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3362\n",
      "Epoch 208/300\n",
      "3031/3031 [==============================] - 0s 97us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3385\n",
      "Epoch 209/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 210/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 211/300\n",
      "3031/3031 [==============================] - 0s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3276\n",
      "Epoch 212/300\n",
      "3031/3031 [==============================] - 0s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3382\n",
      "Epoch 213/300\n",
      "3031/3031 [==============================] - 0s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 214/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3385\n",
      "Epoch 215/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3345\n",
      "Epoch 216/300\n",
      "3031/3031 [==============================] - 0s 134us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3444\n",
      "Epoch 217/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3339\n",
      "Epoch 218/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3441\n",
      "Epoch 219/300\n",
      "3031/3031 [==============================] - 0s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3372\n",
      "Epoch 220/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 221/300\n",
      "3031/3031 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3471\n",
      "Epoch 222/300\n",
      "3031/3031 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34 - 0s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3435\n",
      "Epoch 223/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3484\n",
      "Epoch 224/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3332\n",
      "Epoch 225/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3319\n",
      "Epoch 226/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 227/300\n",
      "3031/3031 [==============================] - 0s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 228/300\n",
      "3031/3031 [==============================] - 0s 106us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3415\n",
      "Epoch 229/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3359\n",
      "Epoch 230/300\n",
      "3031/3031 [==============================] - 1s 181us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3349\n",
      "Epoch 231/300\n",
      "3031/3031 [==============================] - 0s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3342\n",
      "Epoch 232/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 233/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3365\n",
      "Epoch 234/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 235/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 236/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3388\n",
      "Epoch 237/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 238/300\n",
      "3031/3031 [==============================] - 0s 107us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3359\n",
      "Epoch 239/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3336\n",
      "Epoch 240/300\n",
      "3031/3031 [==============================] - 0s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 241/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3362\n",
      "Epoch 242/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 243/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 244/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3477\n",
      "Epoch 245/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3286\n",
      "Epoch 246/300\n",
      "3031/3031 [==============================] - 0s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 247/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 248/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 249/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3362\n",
      "Epoch 250/300\n",
      "3031/3031 [==============================] - 0s 109us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3395\n",
      "Epoch 251/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 252/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3464\n",
      "Epoch 253/300\n",
      "3031/3031 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3448\n",
      "Epoch 254/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3524\n",
      "Epoch 255/300\n",
      "3031/3031 [==============================] - 0s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3444\n",
      "Epoch 256/300\n",
      "3031/3031 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 257/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3451\n",
      "Epoch 258/300\n",
      "3031/3031 [==============================] - 0s 99us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3477\n",
      "Epoch 259/300\n",
      "3031/3031 [==============================] - 0s 91us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3458\n",
      "Epoch 260/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3359\n",
      "Epoch 261/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3372\n",
      "Epoch 262/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 263/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3303\n",
      "Epoch 264/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 265/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34210s - loss: 0.2222 - mean_squared_error: 0.2222 - a\n",
      "Epoch 266/300\n",
      "3031/3031 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3322\n",
      "Epoch 267/300\n",
      "3031/3031 [==============================] - 0s 120us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3583\n",
      "Epoch 268/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3329\n",
      "Epoch 269/300\n",
      "3031/3031 [==============================] - 0s 87us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3359\n",
      "Epoch 270/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3329\n",
      "Epoch 271/300\n",
      "3031/3031 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3454\n",
      "Epoch 272/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3428\n",
      "Epoch 273/300\n",
      "3031/3031 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3408\n",
      "Epoch 274/300\n",
      "3031/3031 [==============================] - 0s 112us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 275/300\n",
      "3031/3031 [==============================] - 0s 90us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3441\n",
      "Epoch 276/300\n",
      "3031/3031 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 277/300\n",
      "3031/3031 [==============================] - 0s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 278/300\n",
      "3031/3031 [==============================] - 0s 87us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3378\n",
      "Epoch 279/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3444\n",
      "Epoch 280/300\n",
      "3031/3031 [==============================] - 0s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3382\n",
      "Epoch 281/300\n",
      "3031/3031 [==============================] - 0s 149us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 282/300\n",
      "3031/3031 [==============================] - 0s 153us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3451\n",
      "Epoch 283/300\n",
      "3031/3031 [==============================] - 0s 155us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3451\n",
      "Epoch 284/300\n",
      "3031/3031 [==============================] - 0s 147us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3355\n",
      "Epoch 285/300\n",
      "3031/3031 [==============================] - 0s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 286/300\n",
      "3031/3031 [==============================] - 0s 117us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3441\n",
      "Epoch 287/300\n",
      "3031/3031 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 288/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3500\n",
      "Epoch 289/300\n",
      "3031/3031 [==============================] - 0s 92us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3316\n",
      "Epoch 290/300\n",
      "3031/3031 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 291/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34110s - loss: 0.2225 - mean_squared_error: 0.2225 - a\n",
      "Epoch 292/300\n",
      "3031/3031 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 293/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 294/300\n",
      "3031/3031 [==============================] - 0s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3428\n",
      "Epoch 295/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 296/300\n",
      "3031/3031 [==============================] - 0s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3431\n",
      "Epoch 297/300\n",
      "3031/3031 [==============================] - 0s 121us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 298/300\n",
      "3031/3031 [==============================] - 0s 116us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 299/300\n",
      "3031/3031 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 300/300\n",
      "3031/3031 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "2526/2526 [==============================] - 1s 201us/step\n",
      "3031/3031 [==============================] - 0s 59us/step\n",
      "The Score is 0.338480\n",
      "current iteration fraction: 0.200000\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "(2020, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2020/2020 [==============================] - 1s 618us/step - loss: 0.2549 - mean_squared_error: 0.2549 - acc: 0.3287\n",
      "Epoch 2/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2413 - mean_squared_error: 0.2413 - acc: 0.3252\n",
      "Epoch 3/300\n",
      "2020/2020 [==============================] - 0s 134us/step - loss: 0.2333 - mean_squared_error: 0.2333 - acc: 0.35300s - loss: 0.2359 - mean_squared_error: 0.2359 - acc: 0.\n",
      "Epoch 4/300\n",
      "2020/2020 [==============================] - 0s 145us/step - loss: 0.2359 - mean_squared_error: 0.2359 - acc: 0.3238\n",
      "Epoch 5/300\n",
      "2020/2020 [==============================] - 0s 150us/step - loss: 0.2298 - mean_squared_error: 0.2298 - acc: 0.3361\n",
      "Epoch 6/300\n",
      "2020/2020 [==============================] - 0s 133us/step - loss: 0.2286 - mean_squared_error: 0.2286 - acc: 0.3371\n",
      "Epoch 7/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2286 - mean_squared_error: 0.2286 - acc: 0.3277\n",
      "Epoch 8/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2278 - mean_squared_error: 0.2278 - acc: 0.3198\n",
      "Epoch 9/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2259 - mean_squared_error: 0.2259 - acc: 0.3347\n",
      "Epoch 10/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2253 - mean_squared_error: 0.2253 - acc: 0.3262\n",
      "Epoch 11/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2253 - mean_squared_error: 0.2253 - acc: 0.3366\n",
      "Epoch 12/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2245 - mean_squared_error: 0.2245 - acc: 0.3550\n",
      "Epoch 13/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2249 - mean_squared_error: 0.2249 - acc: 0.3356\n",
      "Epoch 14/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2248 - mean_squared_error: 0.2248 - acc: 0.3287\n",
      "Epoch 15/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3248\n",
      "Epoch 16/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2255 - mean_squared_error: 0.2255 - acc: 0.3218\n",
      "Epoch 17/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3356\n",
      "Epoch 18/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3317\n",
      "Epoch 19/300\n",
      "2020/2020 [==============================] - 0s 114us/step - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.3396\n",
      "Epoch 20/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3233\n",
      "Epoch 21/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3282\n",
      "Epoch 22/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3282\n",
      "Epoch 23/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3416\n",
      "Epoch 24/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3292\n",
      "Epoch 25/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3178\n",
      "Epoch 26/300\n",
      "2020/2020 [==============================] - 0s 113us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3287\n",
      "Epoch 27/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3347\n",
      "Epoch 28/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3356\n",
      "Epoch 29/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3470\n",
      "Epoch 30/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3292\n",
      "Epoch 31/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3540\n",
      "Epoch 32/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3272\n",
      "Epoch 33/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3347\n",
      "Epoch 34/300\n",
      "2020/2020 [==============================] - 0s 114us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3238\n",
      "Epoch 35/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3342\n",
      "Epoch 36/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3317\n",
      "Epoch 37/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3262\n",
      "Epoch 38/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3248\n",
      "Epoch 39/300\n",
      "2020/2020 [==============================] - 0s 157us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3401\n",
      "Epoch 40/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3277\n",
      "Epoch 41/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3277\n",
      "Epoch 42/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3396\n",
      "Epoch 43/300\n",
      "2020/2020 [==============================] - 0s 140us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3396\n",
      "Epoch 44/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3515\n",
      "Epoch 45/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3248\n",
      "Epoch 46/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3267\n",
      "Epoch 47/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3302\n",
      "Epoch 48/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3441\n",
      "Epoch 49/300\n",
      "2020/2020 [==============================] - 0s 109us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3252\n",
      "Epoch 50/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3332\n",
      "Epoch 51/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3455\n",
      "Epoch 52/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3401\n",
      "Epoch 53/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3168\n",
      "Epoch 54/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3441\n",
      "Epoch 55/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.30690s - loss: 0.2237 - mean_squared_error: 0.2237 - acc\n",
      "Epoch 56/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3421\n",
      "Epoch 57/300\n",
      "2020/2020 [==============================] - 0s 136us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3376\n",
      "Epoch 58/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3421\n",
      "Epoch 59/300\n",
      "2020/2020 [==============================] - 0s 132us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3327\n",
      "Epoch 60/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3287\n",
      "Epoch 61/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3327\n",
      "Epoch 62/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3554\n",
      "Epoch 63/300\n",
      "2020/2020 [==============================] - 0s 136us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3203\n",
      "Epoch 64/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3178\n",
      "Epoch 65/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3416\n",
      "Epoch 66/300\n",
      "2020/2020 [==============================] - 0s 133us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3297\n",
      "Epoch 67/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3327\n",
      "Epoch 68/300\n",
      "2020/2020 [==============================] - 0s 116us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3307\n",
      "Epoch 69/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3431\n",
      "Epoch 70/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3371\n",
      "Epoch 71/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3129\n",
      "Epoch 72/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3446\n",
      "Epoch 73/300\n",
      "2020/2020 [==============================] - 0s 132us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3183\n",
      "Epoch 74/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3208\n",
      "Epoch 75/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3327\n",
      "Epoch 76/300\n",
      "2020/2020 [==============================] - 0s 119us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3327\n",
      "Epoch 77/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3381\n",
      "Epoch 78/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3426\n",
      "Epoch 79/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3228\n",
      "Epoch 80/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3465\n",
      "Epoch 81/300\n",
      "2020/2020 [==============================] - 0s 149us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3465\n",
      "Epoch 82/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3238\n",
      "Epoch 83/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3238\n",
      "Epoch 84/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3347\n",
      "Epoch 85/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3267\n",
      "Epoch 86/300\n",
      "2020/2020 [==============================] - 0s 156us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.34310s - loss: 0.2234 - mean_squared_error: 0.2234 - acc\n",
      "Epoch 87/300\n",
      "2020/2020 [==============================] - 0s 183us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3149\n",
      "Epoch 88/300\n",
      "2020/2020 [==============================] - 0s 187us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3485\n",
      "Epoch 89/300\n",
      "2020/2020 [==============================] - 0s 176us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3238\n",
      "Epoch 90/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3292\n",
      "Epoch 91/300\n",
      "2020/2020 [==============================] - 0s 151us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3233\n",
      "Epoch 92/300\n",
      "2020/2020 [==============================] - 0s 175us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3391\n",
      "Epoch 93/300\n",
      "2020/2020 [==============================] - 0s 149us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3460\n",
      "Epoch 94/300\n",
      "2020/2020 [==============================] - 0s 142us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3312\n",
      "Epoch 95/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3322\n",
      "Epoch 96/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3277\n",
      "Epoch 97/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3347\n",
      "Epoch 98/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3267\n",
      "Epoch 99/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.33510s - loss: 0.2228 - mean_squared_error: 0.2228 - acc\n",
      "Epoch 100/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3460\n",
      "Epoch 101/300\n",
      "2020/2020 [==============================] - 0s 99us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3361\n",
      "Epoch 102/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3411\n",
      "Epoch 103/300\n",
      "2020/2020 [==============================] - 0s 132us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3342\n",
      "Epoch 104/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3203\n",
      "Epoch 105/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3297\n",
      "Epoch 106/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3371\n",
      "Epoch 107/300\n",
      "2020/2020 [==============================] - 0s 143us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3238\n",
      "Epoch 108/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3450\n",
      "Epoch 109/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3411\n",
      "Epoch 110/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3262\n",
      "Epoch 111/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3351\n",
      "Epoch 112/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3332\n",
      "Epoch 113/300\n",
      "2020/2020 [==============================] - 0s 145us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3455\n",
      "Epoch 114/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3267\n",
      "Epoch 115/300\n",
      "2020/2020 [==============================] - 0s 141us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3401\n",
      "Epoch 116/300\n",
      "2020/2020 [==============================] - 0s 151us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3376\n",
      "Epoch 117/300\n",
      "2020/2020 [==============================] - 0s 133us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3361\n",
      "Epoch 118/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3292\n",
      "Epoch 119/300\n",
      "2020/2020 [==============================] - 0s 164us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 120/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3267\n",
      "Epoch 121/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3347\n",
      "Epoch 122/300\n",
      "2020/2020 [==============================] - 0s 133us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3262\n",
      "Epoch 123/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3317\n",
      "Epoch 124/300\n",
      "2020/2020 [==============================] - 0s 149us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3262\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2020 [==============================] - 0s 141us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3446\n",
      "Epoch 126/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3267\n",
      "Epoch 127/300\n",
      "2020/2020 [==============================] - 0s 150us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3178\n",
      "Epoch 128/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3406\n",
      "Epoch 129/300\n",
      "2020/2020 [==============================] - 0s 155us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3277\n",
      "Epoch 130/300\n",
      "2020/2020 [==============================] - 0s 150us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3262\n",
      "Epoch 131/300\n",
      "2020/2020 [==============================] - 0s 165us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34500s - loss: 0.2222 - mean_squared_error: 0.2222 - a\n",
      "Epoch 132/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3302\n",
      "Epoch 133/300\n",
      "2020/2020 [==============================] - 0s 119us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3337\n",
      "Epoch 134/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3381\n",
      "Epoch 135/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3361\n",
      "Epoch 136/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3277\n",
      "Epoch 137/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3401\n",
      "Epoch 138/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3322\n",
      "Epoch 139/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34 - 0s 99us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3416\n",
      "Epoch 140/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3317\n",
      "Epoch 141/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 142/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 143/300\n",
      "2020/2020 [==============================] - 0s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3262\n",
      "Epoch 144/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3297\n",
      "Epoch 145/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3475\n",
      "Epoch 146/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3238\n",
      "Epoch 147/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3450\n",
      "Epoch 148/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3332\n",
      "Epoch 149/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3436\n",
      "Epoch 150/300\n",
      "2020/2020 [==============================] - 0s 97us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3292\n",
      "Epoch 151/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.32430s - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.\n",
      "Epoch 152/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3455\n",
      "Epoch 153/300\n",
      "2020/2020 [==============================] - 0s 147us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3282\n",
      "Epoch 154/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3342\n",
      "Epoch 155/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3327\n",
      "Epoch 156/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3421\n",
      "Epoch 157/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3441\n",
      "Epoch 158/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3307\n",
      "Epoch 159/300\n",
      "2020/2020 [==============================] - 0s 131us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3332\n",
      "Epoch 160/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3460\n",
      "Epoch 161/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3475\n",
      "Epoch 162/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3238\n",
      "Epoch 163/300\n",
      "2020/2020 [==============================] - 0s 111us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3421\n",
      "Epoch 164/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3252\n",
      "Epoch 165/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3416\n",
      "Epoch 166/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3361\n",
      "Epoch 167/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3307\n",
      "Epoch 168/300\n",
      "2020/2020 [==============================] - 0s 130us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3356\n",
      "Epoch 169/300\n",
      "2020/2020 [==============================] - 0s 114us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3342\n",
      "Epoch 170/300\n",
      "2020/2020 [==============================] - 0s 91us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3510\n",
      "Epoch 171/300\n",
      "2020/2020 [==============================] - 0s 113us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3292\n",
      "Epoch 172/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 173/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3455\n",
      "Epoch 174/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3426\n",
      "Epoch 175/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3366\n",
      "Epoch 176/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3351\n",
      "Epoch 177/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3114\n",
      "Epoch 178/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3277\n",
      "Epoch 179/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3312\n",
      "Epoch 180/300\n",
      "2020/2020 [==============================] - 0s 103us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3441\n",
      "Epoch 181/300\n",
      "2020/2020 [==============================] - 0s 148us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3356\n",
      "Epoch 182/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3327\n",
      "Epoch 183/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3089\n",
      "Epoch 184/300\n",
      "2020/2020 [==============================] - 0s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3515\n",
      "Epoch 185/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3446\n",
      "Epoch 186/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3307\n",
      "Epoch 187/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3277\n",
      "Epoch 188/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3198\n",
      "Epoch 189/300\n",
      "2020/2020 [==============================] - 0s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 190/300\n",
      "2020/2020 [==============================] - 0s 88us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3257\n",
      "Epoch 191/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3317\n",
      "Epoch 192/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3327\n",
      "Epoch 193/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3510\n",
      "Epoch 194/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3322\n",
      "Epoch 195/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 196/300\n",
      "2020/2020 [==============================] - 0s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3332\n",
      "Epoch 197/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3287\n",
      "Epoch 198/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.31530s - loss: 0.2224 - mean_squared_error: 0.2224 - acc\n",
      "Epoch 199/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3302\n",
      "Epoch 200/300\n",
      "2020/2020 [==============================] - 0s 101us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3243\n",
      "Epoch 201/300\n",
      "2020/2020 [==============================] - 0s 90us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 202/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3371\n",
      "Epoch 203/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3391\n",
      "Epoch 204/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3193\n",
      "Epoch 205/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34 - 0s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 206/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 207/300\n",
      "2020/2020 [==============================] - 0s 147us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3490\n",
      "Epoch 208/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3356\n",
      "Epoch 209/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3337\n",
      "Epoch 210/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3416\n",
      "Epoch 211/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3376\n",
      "Epoch 212/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3351\n",
      "Epoch 213/300\n",
      "2020/2020 [==============================] - 0s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3307\n",
      "Epoch 214/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3391\n",
      "Epoch 215/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 216/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 217/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3376\n",
      "Epoch 218/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3465\n",
      "Epoch 219/300\n",
      "2020/2020 [==============================] - 0s 119us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 220/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3351\n",
      "Epoch 221/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3342\n",
      "Epoch 222/300\n",
      "2020/2020 [==============================] - 0s 96us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 223/300\n",
      "2020/2020 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34 - 0s 98us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3426\n",
      "Epoch 224/300\n",
      "2020/2020 [==============================] - 0s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3396\n",
      "Epoch 225/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 226/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3421\n",
      "Epoch 227/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3327\n",
      "Epoch 228/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3282\n",
      "Epoch 229/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3465\n",
      "Epoch 230/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 231/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 232/300\n",
      "2020/2020 [==============================] - 0s 116us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3337\n",
      "Epoch 233/300\n",
      "2020/2020 [==============================] - 0s 93us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3426\n",
      "Epoch 234/300\n",
      "2020/2020 [==============================] - 0s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3287\n",
      "Epoch 235/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 236/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 237/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33220s - loss: 0.2223 - mean_squared_error: 0.2223 - acc\n",
      "Epoch 238/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3465\n",
      "Epoch 239/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34060s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: \n",
      "Epoch 240/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 241/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3337\n",
      "Epoch 242/300\n",
      "2020/2020 [==============================] - 0s 113us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3272\n",
      "Epoch 243/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3441\n",
      "Epoch 244/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3262\n",
      "Epoch 245/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3342\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 247/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3356\n",
      "Epoch 248/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3218\n",
      "Epoch 249/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.32380s - loss: 0.2224 - mean_squared_error: 0.2224 - acc\n",
      "Epoch 250/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3337\n",
      "Epoch 251/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3386\n",
      "Epoch 252/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3361\n",
      "Epoch 253/300\n",
      "2020/2020 [==============================] - 0s 117us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3317\n",
      "Epoch 254/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3317\n",
      "Epoch 255/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3386\n",
      "Epoch 256/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3312\n",
      "Epoch 257/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34160s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.\n",
      "Epoch 258/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 259/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3376\n",
      "Epoch 260/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3381\n",
      "Epoch 261/300\n",
      "2020/2020 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3188\n",
      "Epoch 262/300\n",
      "2020/2020 [==============================] - 0s 105us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3307\n",
      "Epoch 263/300\n",
      "2020/2020 [==============================] - 0s 86us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 264/300\n",
      "2020/2020 [==============================] - 0s 100us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3361\n",
      "Epoch 265/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3545\n",
      "Epoch 266/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 267/300\n",
      "2020/2020 [==============================] - 0s 135us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3332\n",
      "Epoch 268/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3366\n",
      "Epoch 269/300\n",
      "2020/2020 [==============================] - 0s 139us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3614\n",
      "Epoch 270/300\n",
      "2020/2020 [==============================] - 0s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 271/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3292\n",
      "Epoch 272/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3450\n",
      "Epoch 273/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3277\n",
      "Epoch 274/300\n",
      "2020/2020 [==============================] - 0s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 275/300\n",
      "2020/2020 [==============================] - 0s 104us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3559\n",
      "Epoch 276/300\n",
      "2020/2020 [==============================] - 0s 87us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 277/300\n",
      "2020/2020 [==============================] - 0s 110us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3371\n",
      "Epoch 278/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3297\n",
      "Epoch 279/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 280/300\n",
      "2020/2020 [==============================] - 0s 92us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3455\n",
      "Epoch 281/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3297\n",
      "Epoch 282/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 283/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3347\n",
      "Epoch 284/300\n",
      "2020/2020 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 285/300\n",
      "2020/2020 [==============================] - 0s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3455\n",
      "Epoch 286/300\n",
      "2020/2020 [==============================] - 0s 113us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 287/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3322\n",
      "Epoch 288/300\n",
      "2020/2020 [==============================] - 0s 102us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3322\n",
      "Epoch 289/300\n",
      "2020/2020 [==============================] - 0s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3337\n",
      "Epoch 290/300\n",
      "2020/2020 [==============================] - 0s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 291/300\n",
      "2020/2020 [==============================] - 0s 106us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 292/300\n",
      "2020/2020 [==============================] - 0s 89us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "Epoch 293/300\n",
      "2020/2020 [==============================] - 0s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3371\n",
      "Epoch 294/300\n",
      "2020/2020 [==============================] - 0s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "Epoch 295/300\n",
      "2020/2020 [==============================] - 0s 122us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3386\n",
      "Epoch 296/300\n",
      "2020/2020 [==============================] - 0s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3307\n",
      "Epoch 297/300\n",
      "2020/2020 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 298/300\n",
      "2020/2020 [==============================] - 0s 154us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3396\n",
      "Epoch 299/300\n",
      "2020/2020 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34210s - loss: 0.2220 - mean_squared_error: 0.2220 - acc: \n",
      "Epoch 300/300\n",
      "2020/2020 [==============================] - 0s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3416\n",
      "2526/2526 [==============================] - 1s 214us/step\n",
      "2020/2020 [==============================] - 0s 70us/step\n",
      "The Score is 0.348377\n",
      "current iteration fraction: 0.100000\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(1010, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,798\n",
      "Trainable params: 3,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1010/1010 [==============================] - 1s 1ms/step - loss: 0.2626 - mean_squared_error: 0.2626 - acc: 0.3307\n",
      "Epoch 2/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2444 - mean_squared_error: 0.2444 - acc: 0.3238\n",
      "Epoch 3/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2402 - mean_squared_error: 0.2402 - acc: 0.3376\n",
      "Epoch 4/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.2353 - mean_squared_error: 0.2353 - acc: 0.3713\n",
      "Epoch 5/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2320 - mean_squared_error: 0.2320 - acc: 0.3683\n",
      "Epoch 6/300\n",
      "1010/1010 [==============================] - 0s 163us/step - loss: 0.2339 - mean_squared_error: 0.2339 - acc: 0.34060s - loss: 0.2336 - mean_squared_error: 0.2336 - acc: 0.33\n",
      "Epoch 7/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2322 - mean_squared_error: 0.2322 - acc: 0.3366\n",
      "Epoch 8/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2311 - mean_squared_error: 0.2311 - acc: 0.3495\n",
      "Epoch 9/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2338 - mean_squared_error: 0.2338 - acc: 0.3238\n",
      "Epoch 10/300\n",
      "1010/1010 [==============================] - 0s 182us/step - loss: 0.2317 - mean_squared_error: 0.2317 - acc: 0.32770s - loss: 0.2318 - mean_squared_error: 0.2318 - acc: 0.\n",
      "Epoch 11/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2291 - mean_squared_error: 0.2291 - acc: 0.3446\n",
      "Epoch 12/300\n",
      "1010/1010 [==============================] - 0s 111us/step - loss: 0.2300 - mean_squared_error: 0.2300 - acc: 0.3297\n",
      "Epoch 13/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.2284 - mean_squared_error: 0.2284 - acc: 0.3307\n",
      "Epoch 14/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.2259 - mean_squared_error: 0.2259 - acc: 0.3525\n",
      "Epoch 15/300\n",
      "1010/1010 [==============================] - 0s 91us/step - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.3792\n",
      "Epoch 16/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2301 - mean_squared_error: 0.2301 - acc: 0.3208\n",
      "Epoch 17/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2266 - mean_squared_error: 0.2266 - acc: 0.3465\n",
      "Epoch 18/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2264 - mean_squared_error: 0.2264 - acc: 0.3624\n",
      "Epoch 19/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2269 - mean_squared_error: 0.2269 - acc: 0.3307\n",
      "Epoch 20/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2279 - mean_squared_error: 0.2279 - acc: 0.3050\n",
      "Epoch 21/300\n",
      "1010/1010 [==============================] - 0s 106us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3525\n",
      "Epoch 22/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3406\n",
      "Epoch 23/300\n",
      "1010/1010 [==============================] - 0s 89us/step - loss: 0.2252 - mean_squared_error: 0.2252 - acc: 0.3495\n",
      "Epoch 24/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2262 - mean_squared_error: 0.2262 - acc: 0.3317\n",
      "Epoch 25/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.2255 - mean_squared_error: 0.2255 - acc: 0.3356\n",
      "Epoch 26/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2246 - mean_squared_error: 0.2246 - acc: 0.3426\n",
      "Epoch 27/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2258 - mean_squared_error: 0.2258 - acc: 0.3139\n",
      "Epoch 28/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2247 - mean_squared_error: 0.2247 - acc: 0.33860s - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.\n",
      "Epoch 29/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3366\n",
      "Epoch 30/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2248 - mean_squared_error: 0.2248 - acc: 0.3505\n",
      "Epoch 31/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3416\n",
      "Epoch 32/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3495\n",
      "Epoch 33/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3515\n",
      "Epoch 34/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3455\n",
      "Epoch 35/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.2249 - mean_squared_error: 0.2249 - acc: 0.3267\n",
      "Epoch 36/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3307\n",
      "Epoch 37/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3317\n",
      "Epoch 38/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.35450s - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.35\n",
      "Epoch 39/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3574\n",
      "Epoch 40/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.33270s - loss: 0.2259 - mean_squared_error: 0.2259 - acc: 0.\n",
      "Epoch 41/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3356\n",
      "Epoch 42/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3238\n",
      "Epoch 43/300\n",
      "1010/1010 [==============================] - 0s 126us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3574\n",
      "Epoch 44/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3535\n",
      "Epoch 45/300\n",
      "1010/1010 [==============================] - 0s 198us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3554\n",
      "Epoch 46/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3386\n",
      "Epoch 47/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3495\n",
      "Epoch 48/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3436\n",
      "Epoch 49/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.33560s - loss: 0.2248 - mean_squared_error: 0.2248 - acc: 0.\n",
      "Epoch 50/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3406\n",
      "Epoch 51/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2237 - mean_squared_error: 0.2237 - acc: 0.3495\n",
      "Epoch 52/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.34650s - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.35\n",
      "Epoch 53/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3158\n",
      "Epoch 54/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3436\n",
      "Epoch 55/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3386\n",
      "Epoch 56/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3327\n",
      "Epoch 57/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3327\n",
      "Epoch 58/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3386\n",
      "Epoch 59/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.36630s - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.\n",
      "Epoch 60/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3535\n",
      "Epoch 61/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.3129\n",
      "Epoch 62/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3347\n",
      "Epoch 63/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3356\n",
      "Epoch 64/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3188\n",
      "Epoch 65/300\n",
      "1010/1010 [==============================] - 0s 121us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3703\n",
      "Epoch 66/300\n",
      "1010/1010 [==============================] - 0s 104us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3604\n",
      "Epoch 67/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3574\n",
      "Epoch 68/300\n",
      "1010/1010 [==============================] - 0s 97us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3297\n",
      "Epoch 69/300\n",
      "1010/1010 [==============================] - 0s 95us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3446\n",
      "Epoch 70/300\n",
      "1010/1010 [==============================] - 0s 151us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.35150s - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.\n",
      "Epoch 71/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3574\n",
      "Epoch 72/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3208\n",
      "Epoch 73/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3525\n",
      "Epoch 74/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3446\n",
      "Epoch 75/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.35350s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 76/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3356\n",
      "Epoch 77/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.35250s - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.\n",
      "Epoch 78/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3614\n",
      "Epoch 79/300\n",
      "1010/1010 [==============================] - 0s 92us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3356\n",
      "Epoch 80/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3119\n",
      "Epoch 81/300\n",
      "1010/1010 [==============================] - 0s 102us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3574\n",
      "Epoch 82/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3693\n",
      "Epoch 83/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3327\n",
      "Epoch 84/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3267\n",
      "Epoch 85/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3644\n",
      "Epoch 86/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3416\n",
      "Epoch 87/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.35050s - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.\n",
      "Epoch 88/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3307\n",
      "Epoch 89/300\n",
      "1010/1010 [==============================] - 0s 150us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3376\n",
      "Epoch 90/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3287\n",
      "Epoch 91/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3347\n",
      "Epoch 92/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3307\n",
      "Epoch 93/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3406\n",
      "Epoch 94/300\n",
      "1010/1010 [==============================] - 0s 105us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3376\n",
      "Epoch 95/300\n",
      "1010/1010 [==============================] - 0s 101us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3495\n",
      "Epoch 96/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3564\n",
      "Epoch 97/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3386\n",
      "Epoch 98/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.33270s - loss: 0.2241 - mean_squared_error: 0.2241 - acc: 0.\n",
      "Epoch 99/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3505\n",
      "Epoch 100/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3594\n",
      "Epoch 101/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3515\n",
      "Epoch 102/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3495\n",
      "Epoch 103/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.34 - 0s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3436\n",
      "Epoch 104/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3525\n",
      "Epoch 105/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.33560s - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.\n",
      "Epoch 106/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3257\n",
      "Epoch 107/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3515\n",
      "Epoch 108/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3574\n",
      "Epoch 109/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3307\n",
      "Epoch 110/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3663\n",
      "Epoch 111/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3277\n",
      "Epoch 112/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3475\n",
      "Epoch 113/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3356\n",
      "Epoch 114/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3218\n",
      "Epoch 115/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3347\n",
      "Epoch 116/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3455\n",
      "Epoch 117/300\n",
      "1010/1010 [==============================] - 0s 117us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3554\n",
      "Epoch 118/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3109\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3307\n",
      "Epoch 120/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3337\n",
      "Epoch 121/300\n",
      "1010/1010 [==============================] - 0s 150us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3446\n",
      "Epoch 122/300\n",
      "1010/1010 [==============================] - 0s 174us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3228\n",
      "Epoch 123/300\n",
      "1010/1010 [==============================] - 0s 176us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3337\n",
      "Epoch 124/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3238\n",
      "Epoch 125/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3535\n",
      "Epoch 126/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3693\n",
      "Epoch 127/300\n",
      "1010/1010 [==============================] - 0s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3465\n",
      "Epoch 128/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3465\n",
      "Epoch 129/300\n",
      "1010/1010 [==============================] - 0s 182us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3545\n",
      "Epoch 130/300\n",
      "1010/1010 [==============================] - 0s 165us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.31780s - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.31\n",
      "Epoch 131/300\n",
      "1010/1010 [==============================] - 0s 157us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3426\n",
      "Epoch 132/300\n",
      "1010/1010 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3465\n",
      "Epoch 133/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3535\n",
      "Epoch 134/300\n",
      "1010/1010 [==============================] - 0s 98us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3327\n",
      "Epoch 135/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3267\n",
      "Epoch 136/300\n",
      "1010/1010 [==============================] - 0s 168us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3317\n",
      "Epoch 137/300\n",
      "1010/1010 [==============================] - 0s 153us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3663\n",
      "Epoch 138/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3416\n",
      "Epoch 139/300\n",
      "1010/1010 [==============================] - 0s 158us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3337\n",
      "Epoch 140/300\n",
      "1010/1010 [==============================] - 0s 126us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3386\n",
      "Epoch 141/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3505\n",
      "Epoch 142/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3594\n",
      "Epoch 143/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.32180s - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.\n",
      "Epoch 144/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3554\n",
      "Epoch 145/300\n",
      "1010/1010 [==============================] - 0s 152us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3485\n",
      "Epoch 146/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3307\n",
      "Epoch 147/300\n",
      "1010/1010 [==============================] - 0s 163us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.34260s - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.\n",
      "Epoch 148/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3465\n",
      "Epoch 149/300\n",
      "1010/1010 [==============================] - 0s 151us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3545\n",
      "Epoch 150/300\n",
      "1010/1010 [==============================] - 0s 154us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3396\n",
      "Epoch 151/300\n",
      "1010/1010 [==============================] - 0s 122us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3446\n",
      "Epoch 152/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3465\n",
      "Epoch 153/300\n",
      "1010/1010 [==============================] - 0s 161us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3495\n",
      "Epoch 154/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3634\n",
      "Epoch 155/300\n",
      "1010/1010 [==============================] - 0s 149us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3267\n",
      "Epoch 156/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.33 - 0s 156us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3426\n",
      "Epoch 157/300\n",
      "1010/1010 [==============================] - 0s 148us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3594\n",
      "Epoch 158/300\n",
      "1010/1010 [==============================] - 0s 118us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3525\n",
      "Epoch 159/300\n",
      "1010/1010 [==============================] - 0s 115us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3554\n",
      "Epoch 160/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3307\n",
      "Epoch 161/300\n",
      "1010/1010 [==============================] - 0s 116us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3535\n",
      "Epoch 162/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3287\n",
      "Epoch 163/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 164/300\n",
      "1010/1010 [==============================] - 0s 168us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3465\n",
      "Epoch 165/300\n",
      "1010/1010 [==============================] - 0s 214us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3198\n",
      "Epoch 166/300\n",
      "1010/1010 [==============================] - 0s 190us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3455\n",
      "Epoch 167/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3287\n",
      "Epoch 168/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3257\n",
      "Epoch 169/300\n",
      "1010/1010 [==============================] - 0s 100us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3584\n",
      "Epoch 170/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3267\n",
      "Epoch 171/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3366\n",
      "Epoch 172/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3495\n",
      "Epoch 173/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3525\n",
      "Epoch 174/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3396\n",
      "Epoch 175/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 176/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34750s - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.\n",
      "Epoch 177/300\n",
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.35150s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.35\n",
      "Epoch 178/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3535\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 0s 146us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34650s - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.\n",
      "Epoch 180/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3446\n",
      "Epoch 181/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3218\n",
      "Epoch 182/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3554\n",
      "Epoch 183/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3436\n",
      "Epoch 184/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3515\n",
      "Epoch 185/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3416\n",
      "Epoch 186/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3564\n",
      "Epoch 187/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3495\n",
      "Epoch 188/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3327\n",
      "Epoch 189/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3495\n",
      "Epoch 190/300\n",
      "1010/1010 [==============================] - 0s 114us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3485\n",
      "Epoch 191/300\n",
      "1010/1010 [==============================] - 0s 93us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3673\n",
      "Epoch 192/300\n",
      "1010/1010 [==============================] - 0s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3465\n",
      "Epoch 193/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3505\n",
      "Epoch 194/300\n",
      "1010/1010 [==============================] - 0s 156us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3396\n",
      "Epoch 195/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3663\n",
      "Epoch 196/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.3653\n",
      "Epoch 197/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3317\n",
      "Epoch 198/300\n",
      "1010/1010 [==============================] - 0s 178us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3535\n",
      "Epoch 199/300\n",
      "1010/1010 [==============================] - 0s 153us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3515\n",
      "Epoch 200/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3089\n",
      "Epoch 201/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.3584\n",
      "Epoch 202/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3703\n",
      "Epoch 203/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3485\n",
      "Epoch 204/300\n",
      "1010/1010 [==============================] - 0s 117us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3663\n",
      "Epoch 205/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3564\n",
      "Epoch 206/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3515\n",
      "Epoch 207/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3564\n",
      "Epoch 208/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3663\n",
      "Epoch 209/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3248\n",
      "Epoch 210/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3376\n",
      "Epoch 211/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3307\n",
      "Epoch 212/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3277\n",
      "Epoch 213/300\n",
      "1010/1010 [==============================] - 0s 111us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3277\n",
      "Epoch 214/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3545\n",
      "Epoch 215/300\n",
      "1010/1010 [==============================] - 0s 96us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3416\n",
      "Epoch 216/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3564\n",
      "Epoch 217/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3376\n",
      "Epoch 218/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3218\n",
      "Epoch 219/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3277\n",
      "Epoch 220/300\n",
      "1010/1010 [==============================] - 0s 129us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3238\n",
      "Epoch 221/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3109\n",
      "Epoch 222/300\n",
      "1010/1010 [==============================] - 0s 117us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3376\n",
      "Epoch 223/300\n",
      "1010/1010 [==============================] - 0s 125us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3267\n",
      "Epoch 224/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3564\n",
      "Epoch 225/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3396\n",
      "Epoch 226/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3426\n",
      "Epoch 227/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 228/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3337\n",
      "Epoch 229/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33470s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 230/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3485\n",
      "Epoch 231/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3465\n",
      "Epoch 232/300\n",
      "1010/1010 [==============================] - 0s 128us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3386\n",
      "Epoch 233/300\n",
      "1010/1010 [==============================] - 0s 114us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3416\n",
      "Epoch 234/300\n",
      "1010/1010 [==============================] - 0s 108us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3535\n",
      "Epoch 235/300\n",
      "1010/1010 [==============================] - ETA: 0s - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.31 - 0s 144us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3178\n",
      "Epoch 236/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3327\n",
      "Epoch 237/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 238/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3406\n",
      "Epoch 239/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 240/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3475\n",
      "Epoch 241/300\n",
      "1010/1010 [==============================] - 0s 103us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3485\n",
      "Epoch 242/300\n",
      "1010/1010 [==============================] - 0s 110us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3465\n",
      "Epoch 243/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3277\n",
      "Epoch 244/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3614\n",
      "Epoch 245/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3277\n",
      "Epoch 246/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3277\n",
      "Epoch 247/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3545\n",
      "Epoch 248/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.3683\n",
      "Epoch 249/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3386\n",
      "Epoch 250/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3554\n",
      "Epoch 251/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 252/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3406\n",
      "Epoch 253/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.32570s - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.\n",
      "Epoch 254/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 255/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3356\n",
      "Epoch 256/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3366\n",
      "Epoch 257/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 258/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3416\n",
      "Epoch 259/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3347\n",
      "Epoch 260/300\n",
      "1010/1010 [==============================] - 0s 155us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3426\n",
      "Epoch 261/300\n",
      "1010/1010 [==============================] - 0s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.35640s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.35\n",
      "Epoch 262/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3604\n",
      "Epoch 263/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3495\n",
      "Epoch 264/300\n",
      "1010/1010 [==============================] - 0s 126us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3525\n",
      "Epoch 265/300\n",
      "1010/1010 [==============================] - 0s 106us/step - loss: 0.2219 - mean_squared_error: 0.2219 - acc: 0.3505\n",
      "Epoch 266/300\n",
      "1010/1010 [==============================] - 0s 94us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3426\n",
      "Epoch 267/300\n",
      "1010/1010 [==============================] - 0s 90us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3446\n",
      "Epoch 268/300\n",
      "1010/1010 [==============================] - 0s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3307\n",
      "Epoch 269/300\n",
      "1010/1010 [==============================] - 0s 144us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3297\n",
      "Epoch 270/300\n",
      "1010/1010 [==============================] - 0s 167us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3297\n",
      "Epoch 271/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3446\n",
      "Epoch 272/300\n",
      "1010/1010 [==============================] - 0s 147us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3297\n",
      "Epoch 273/300\n",
      "1010/1010 [==============================] - 0s 152us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3287\n",
      "Epoch 274/300\n",
      "1010/1010 [==============================] - 0s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3564\n",
      "Epoch 275/300\n",
      "1010/1010 [==============================] - 0s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3257\n",
      "Epoch 276/300\n",
      "1010/1010 [==============================] - 0s 121us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3356\n",
      "Epoch 277/300\n",
      "1010/1010 [==============================] - 0s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3604\n",
      "Epoch 278/300\n",
      "1010/1010 [==============================] - 0s 106us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3228\n",
      "Epoch 279/300\n",
      "1010/1010 [==============================] - 0s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3446\n",
      "Epoch 280/300\n",
      "1010/1010 [==============================] - 0s 134us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3624\n",
      "Epoch 281/300\n",
      "1010/1010 [==============================] - 0s 140us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.3475\n",
      "Epoch 282/300\n",
      "1010/1010 [==============================] - 0s 130us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3376\n",
      "Epoch 283/300\n",
      "1010/1010 [==============================] - 0s 133us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3495\n",
      "Epoch 284/300\n",
      "1010/1010 [==============================] - 0s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3426\n",
      "Epoch 285/300\n",
      "1010/1010 [==============================] - 0s 107us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3406\n",
      "Epoch 286/300\n",
      "1010/1010 [==============================] - 0s 123us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3396\n",
      "Epoch 287/300\n",
      "1010/1010 [==============================] - 0s 137us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3436\n",
      "Epoch 288/300\n",
      "1010/1010 [==============================] - 0s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3475\n",
      "Epoch 289/300\n",
      "1010/1010 [==============================] - 0s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3564\n",
      "Epoch 290/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3535\n",
      "Epoch 291/300\n",
      "1010/1010 [==============================] - 0s 121us/step - loss: 0.2220 - mean_squared_error: 0.2220 - acc: 0.35450s - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.\n",
      "Epoch 292/300\n",
      "1010/1010 [==============================] - 0s 119us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3406\n",
      "Epoch 293/300\n",
      "1010/1010 [==============================] - 0s 105us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3317\n",
      "Epoch 294/300\n",
      "1010/1010 [==============================] - 0s 126us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3297\n",
      "Epoch 295/300\n",
      "1010/1010 [==============================] - 0s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3574\n",
      "Epoch 296/300\n",
      "1010/1010 [==============================] - 0s 143us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3465\n",
      "Epoch 297/300\n",
      "1010/1010 [==============================] - 0s 132us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3564\n",
      "Epoch 298/300\n",
      "1010/1010 [==============================] - 0s 127us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3624\n",
      "Epoch 299/300\n",
      "1010/1010 [==============================] - 0s 118us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3495\n",
      "Epoch 300/300\n",
      "1010/1010 [==============================] - 0s 116us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526/2526 [==============================] - 1s 222us/step\n",
      "1010/1010 [==============================] - 0s 75us/step\n",
      "The Score is 0.322644\n",
      "[(8083, 0.3368962788430831, 300.32859992980957, 0.16918635368347168, 0.34492144004832276), (7072, 0.35193982585875266, 260.1097981929779, 0.45066261291503906, 0.3393665158371041), (6062, 0.33650039604799387, 226.84859824180603, 0.5275218486785889, 0.34774001981511204), (5052, 0.341250989825029, 192.58528184890747, 0.4776127338409424, 0.34263657957244653), (4041, 0.33293745060903346, 142.22978973388672, 0.49208545684814453, 0.34323187334293837), (3031, 0.3384798100470364, 113.60745596885681, 0.5160434246063232, 0.3421313097004212), (2020, 0.34837688051417814, 77.88481879234314, 0.5469837188720703, 0.3410891089108911), (1010, 0.3226444972406185, 43.00261664390564, 0.5664489269256592, 0.3455445546915035)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsRP.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, length)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetRP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00494937 0.01947932 0.02280607 0.02801419 0.04000684 0.06927274\n",
      " 0.07836177 0.16351802 0.57359169]\n"
     ]
    }
   ],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "length = len(X_inputs.columns)\n",
    "rp = GaussianRandomProjection(n_components = len(X_inputs.columns))\n",
    "rp.fit(X_inputs)\n",
    "X_inputs = rp.transform(X_inputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances/(sum(variances))))\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 55)                605       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,853\n",
      "Trainable params: 3,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 287us/step - loss: 0.2384 - mean_squared_error: 0.2384 - acc: 0.33221s - loss: 0.2410 - mean_squared_error: 0.2410\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.2295 - mean_squared_error: 0.2295 - acc: 0.32850s - loss: 0.2313 - mean_squared_error: 0.\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2262 - mean_squared_error: 0.2262 - acc: 0.3293\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2257 - mean_squared_error: 0.2257 - acc: 0.3301\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3422\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3365\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3309\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3255\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 188us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.33771s - loss: 0.2\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 183us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3385\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.34380s - loss: 0.2230 - mean_squared_error:  - ETA: 0s - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 194us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.33401s - loss: 0.2229 \n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3424\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3368\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3322\n",
      "2526/2526 [==============================] - 1s 255us/step\n",
      "8083/8083 [==============================] - 1s 84us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3400\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3458\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3387\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3290\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.32340s - loss: 0.2229 - mean_squared_error: 0.2229 - a\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3382\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3486\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3262\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3314\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3266\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3324\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3365\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 234us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3364\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 208us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3433\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3387\n",
      "2526/2526 [==============================] - 0s 94us/step\n",
      "8083/8083 [==============================] - 1s 102us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3380\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3429\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3361\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3398\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3429\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3317\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3363\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3473\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3324\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3312\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3338\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3400\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3340\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3316\n",
      "2526/2526 [==============================] - 0s 92us/step\n",
      "8083/8083 [==============================] - 1s 87us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33 - 1s 178us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3389\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3327\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3360\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3354\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.32770s - loss: 0.2223 - mean_squared_error: 0.22\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 226us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33811s\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 248us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34310s - loss: 0.2222 - mean_squared_e\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 217us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3324\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 3s 346us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.32932s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0. - ETA: 2s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0. - E\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33190s - loss: 0.2222 - mean_squared_error - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 122us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3426\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3360\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3387\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3403\n",
      "2526/2526 [==============================] - 0s 68us/step\n",
      "8083/8083 [==============================] - 1s 63us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34 - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3434\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3318\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3459\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34101s - loss: 0.2220 - mean_s - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3471\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3480\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 219us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3460\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3374\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34170s - loss: 0.2223 - mean_squared_error: 0.2223 - acc\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3407\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "2526/2526 [==============================] - 0s 104us/step\n",
      "8083/8083 [==============================] - 1s 92us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3374\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33240s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3421\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3408\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33771s - loss: 0.2\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3386\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3376\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3384\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3363\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3340\n",
      "2526/2526 [==============================] - 0s 75us/step\n",
      "8083/8083 [==============================] - 1s 81us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3434\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34321s - loss: 0.221\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33960s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34340s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3431\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3384\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3386\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "2526/2526 [==============================] - 0s 78us/step\n",
      "8083/8083 [==============================] - 1s 68us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 125us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3366\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3401\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34240s - loss: 0.2221 - mean_s\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33740s - loss: 0.2222 - mean_squared_error: \n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3434\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33470s - loss: 0.2221 - mean_squar\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3365\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3338\n",
      "2526/2526 [==============================] - 0s 96us/step\n",
      "8083/8083 [==============================] - 1s 134us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3337\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33940s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3330\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34292s - loss: 0.222\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3316\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3443\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34100s - loss: 0.2222 - mean_squared_error: 0.\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3321\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3412\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3390\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33970s - loss: 0.2223 - mean_squared\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "2526/2526 [==============================] - 0s 99us/step\n",
      "8083/8083 [==============================] - 1s 110us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3426\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3365\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3366\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33921s - loss: 0.2220 - mean\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3412\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3426\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3396\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3411\n",
      "2526/2526 [==============================] - 0s 93us/step\n",
      "8083/8083 [==============================] - 1s 96us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3376\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 227us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3395\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 253us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34470s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3382\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3348\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3316\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3432\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33140s - loss: 0.2223 - mean_squared_error: 0.2223 - acc\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3381\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3269\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 177us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3328\n",
      "2526/2526 [==============================] - 0s 109us/step\n",
      "8083/8083 [==============================] - 1s 101us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3358\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 179us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3415\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3395\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 2s 192us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.33950s - loss: 0.2220 - mean_squared_e\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3384\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34050s - loss: 0.2222 - mean_squared_error: 0.2222 -\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3351\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3366\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3386\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3423\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3370\n",
      "2526/2526 [==============================] - 0s 81us/step\n",
      "8083/8083 [==============================] - 1s 80us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3335\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3502\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33840s - loss: 0.2223 - mean_squared_error: 0.2223 - acc\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3324\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3413\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3365\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3334\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3369\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3327\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3373\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3398\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3416\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3390\n",
      "2526/2526 [==============================] - 0s 83us/step\n",
      "8083/8083 [==============================] - 1s 74us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3337\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3365\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3343\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3390\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3373\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33500s - loss: 0.2221 - mean_squared_error\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33610s - loss: 0.2221 - mean_squ\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3428\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3363\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3359\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3398\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3330\n",
      "2526/2526 [==============================] - 0s 74us/step\n",
      "8083/8083 [==============================] - 1s 83us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3387\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33890s - loss: 0.2220 - mean_squared\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34590s - loss: 0.2222 - mean_squared_error: 0.22\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 126us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3392\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3390\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3390\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s 124us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3429\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3356\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3415\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3396\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33420s - loss: 0.2222 - mean_squared_error: \n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3377\n",
      "2526/2526 [==============================] - 0s 94us/step\n",
      "8083/8083 [==============================] - 1s 84us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3369\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34000s - loss: 0.2221 - mean_squared_error: 0.2221 - a - ETA: 0s - loss: 0.2221 - mean_squared_error: 0.2221 - acc\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3369\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33921s - loss: 0.2223 - me\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3424\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34080s - loss: 0.2220 - mean_squ\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33450s - loss: 0.2223 - mean\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3318\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33730s - loss: 0.2222 - mean_squared_error: 0.2222\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3406\n",
      "2526/2526 [==============================] - 0s 79us/step\n",
      "8083/8083 [==============================] - 1s 87us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3385\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3422\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3369\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3350\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34100s - loss: 0.2220 - mean_squar\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3347\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3424\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3298\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3342\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3423\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3328\n",
      "2526/2526 [==============================] - 0s 72us/step\n",
      "8083/8083 [==============================] - 1s 73us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3428\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3342\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3424\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3476\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3410\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3375\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 134us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3410\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3345\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3375\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3441\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3345\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3384\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3377\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34481s - loss: 0.2222 - me\n",
      "2526/2526 [==============================] - 0s 77us/step\n",
      "8083/8083 [==============================] - 1s 82us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3354\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34440s - loss: 0.2222 - mean_squared_error: 0.\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3407\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3380\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3449\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3371\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 269us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3343\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 226us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3275\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3389\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 288us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3324\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3356\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3368\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 254us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34680s - loss: 0.2221 - me\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 203us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3365\n",
      "2526/2526 [==============================] - 0s 114us/step\n",
      "8083/8083 [==============================] - 1s 127us/step\n",
      "2526/2526 [==============================] - 0s 110us/step\n",
      "8083/8083 [==============================] - 0s 53us/step\n",
      "The Score is 0.351544\n",
      "current iteration fraction: 0.700000\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(7072, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 55)                605       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,853\n",
      "Trainable params: 3,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "7072/7072 [==============================] - 3s 439us/step - loss: 0.2419 - mean_squared_error: 0.2419 - acc: 0.3375\n",
      "Epoch 2/300\n",
      "7072/7072 [==============================] - 1s 87us/step - loss: 0.2309 - mean_squared_error: 0.2309 - acc: 0.3314\n",
      "Epoch 3/300\n",
      "7072/7072 [==============================] - 1s 86us/step - loss: 0.2259 - mean_squared_error: 0.2259 - acc: 0.3355\n",
      "Epoch 4/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.2252 - mean_squared_error: 0.2252 - acc: 0.3324\n",
      "Epoch 5/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.2243 - mean_squared_error: 0.2243 - acc: 0.3456\n",
      "Epoch 6/300\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3377\n",
      "Epoch 7/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3357\n",
      "Epoch 8/300\n",
      "7072/7072 [==============================] - 1s 93us/step - loss: 0.2235 - mean_squared_error: 0.2235 - acc: 0.3440\n",
      "Epoch 9/300\n",
      "7072/7072 [==============================] - 2s 248us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3333\n",
      "Epoch 10/300\n",
      "7072/7072 [==============================] - 1s 103us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3446\n",
      "Epoch 11/300\n",
      "7072/7072 [==============================] - 1s 84us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3439\n",
      "Epoch 12/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3254\n",
      "Epoch 13/300\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3333\n",
      "Epoch 14/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3488\n",
      "Epoch 15/300\n",
      "7072/7072 [==============================] - 1s 111us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3405\n",
      "Epoch 16/300\n",
      "7072/7072 [==============================] - 1s 163us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3377\n",
      "Epoch 17/300\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3453\n",
      "Epoch 18/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3409\n",
      "Epoch 19/300\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3387\n",
      "Epoch 20/300\n",
      "7072/7072 [==============================] - 1s 92us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3446\n",
      "Epoch 21/300\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3381\n",
      "Epoch 22/300\n",
      "7072/7072 [==============================] - 1s 118us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3365\n",
      "Epoch 23/300\n",
      "7072/7072 [==============================] - 1s 87us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3375\n",
      "Epoch 24/300\n",
      "7072/7072 [==============================] - 1s 86us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3409\n",
      "Epoch 25/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3374\n",
      "Epoch 26/300\n",
      "7072/7072 [==============================] - 1s 87us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3372\n",
      "Epoch 27/300\n",
      "7072/7072 [==============================] - 1s 87us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3409\n",
      "Epoch 28/300\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3286\n",
      "Epoch 29/300\n",
      "7072/7072 [==============================] - 1s 88us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3377\n",
      "Epoch 30/300\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3488\n",
      "Epoch 31/300\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3298\n",
      "Epoch 32/300\n",
      "7072/7072 [==============================] - 1s 133us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3368\n",
      "Epoch 33/300\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3402\n",
      "Epoch 34/300\n",
      "7072/7072 [==============================] - 1s 109us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3423\n",
      "Epoch 35/300\n",
      "7072/7072 [==============================] - 1s 124us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3501\n",
      "Epoch 36/300\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3395\n",
      "Epoch 37/300\n",
      "7072/7072 [==============================] - 1s 149us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3368\n",
      "Epoch 38/300\n",
      "7072/7072 [==============================] - 1s 151us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3452\n",
      "Epoch 39/300\n",
      "7072/7072 [==============================] - 1s 153us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3396\n",
      "Epoch 40/300\n",
      "7072/7072 [==============================] - 1s 164us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3435\n",
      "Epoch 41/300\n",
      "7072/7072 [==============================] - 1s 150us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3363\n",
      "Epoch 42/300\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3347\n",
      "Epoch 43/300\n",
      "4800/7072 [===================>..........] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3427 ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9b0be6ba4f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwriteDictToCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningCurveIterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_initialized'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsRPK_means.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, length + 1)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetRPK_Means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation Maximizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00130705 0.00143727 0.00568949 0.0095544  0.01154941 0.07254943\n",
      " 0.20547178 0.30989989 0.38254127]\n"
     ]
    }
   ],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "\n",
    "length = len(X_inputs.columns)\n",
    "rp = GaussianRandomProjection(n_components = len(X_inputs.columns))\n",
    "rp.fit(X_inputs)\n",
    "X_inputs = rp.transform(X_inputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances/(sum(variances))))\n",
    "\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X_inputs)\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 55)                605       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,853\n",
      "Trainable params: 3,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 3s 421us/step - loss: 0.2441 - mean_squared_error: 0.2441 - acc: 0.3387\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2300 - mean_squared_error: 0.2300 - acc: 0.3402\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2257 - mean_squared_error: 0.2257 - acc: 0.3468\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2253 - mean_squared_error: 0.2253 - acc: 0.3356\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.3428\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.2238 - mean_squared_error: 0.2238 - acc: 0.3449\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 195us/step - loss: 0.2240 - mean_squared_error: 0.2240 - acc: 0.33470s - loss: 0.2240 - mean_squared_error: 0.\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3441\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.33860s - loss: 0.2231 - mean_squared_error: 0.2231\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 232us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3386\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 305us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3434\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 282us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3521\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 276us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3351\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3436\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2230 - mean_squared_error: 0.2230 - acc: 0.3355\n",
      "2526/2526 [==============================] - 1s 371us/step\n",
      "8083/8083 [==============================] - 1s 77us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 221us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3437\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3395\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3390\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3389\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3462\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3469\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 218us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3374\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 240us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3395\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34631s - loss: 0.2223 - mean - ETA: 0s - loss: 0.2226 - mean_squared_error: 0.22\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3441\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3379\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3349\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3396\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3324\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3412\n",
      "2526/2526 [==============================] - 0s 173us/step\n",
      "8083/8083 [==============================] - 1s 84us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 236us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3428\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 237us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3432\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 230us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3365\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 213us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33171s - loss:\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.33611s - loss: 0.2222 - me\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3423\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3403\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3342\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 127us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3454\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3428\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 120us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3365\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3377\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3340\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3363\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "2526/2526 [==============================] - 0s 57us/step\n",
      "8083/8083 [==============================] - 1s 91us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3384\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.34131s - loss: 0.2225 \n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3387\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3427\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3422\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 138us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3433\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3391\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.34800s - loss: 0.2218 - mean_squar\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3405\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3345\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 100us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3510\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3429\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3413\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 99us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3400\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 119us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3488\n",
      "2526/2526 [==============================] - 0s 59us/step\n",
      "8083/8083 [==============================] - 1s 90us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 210us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.33821s - loss:\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3411\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 214us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3361\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3491\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3433\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3394\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3423\n",
      "Epoch 9/15\n",
      "4512/8083 [===============>..............] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-34f673b65b17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsRPEM.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, length+1 )\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetRPEM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Selection<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.49981036e-01 6.57274558e-01 6.57957245e-01 6.59464922e-01\n",
      " 6.68162784e-01 1.24580280e+00 1.24597206e+00 2.03655226e+00\n",
      " 1.32930749e+07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.57274558e-01 1.32930749e+07]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "\n",
    "X_inputs = X_inputs.values\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "X_inputs = SelectKBest(mutual_info_classif, k=2).fit_transform(X_inputs, X_outputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsFS.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 2)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetFS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.49981036e-01 6.57274558e-01 6.57957245e-01 6.59464922e-01\n",
      " 6.68162784e-01 1.24580280e+00 1.24597206e+00 2.03655226e+00\n",
      " 1.32930749e+07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.57274558e-01 1.32930749e+07]\n"
     ]
    }
   ],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "\n",
    "X_inputs = X_inputs.values\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "X_inputs = SelectKBest(mutual_info_classif, k=2).fit_transform(X_inputs, X_outputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "kmeanModel = KMeans(n_clusters=idealK).fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = kmeanModel.labels_\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 3s 343us/step - loss: 0.2399 - mean_squared_error: 0.2399 - acc: 0.3376\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 179us/step - loss: 0.2282 - mean_squared_error: 0.2282 - acc: 0.3412\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2260 - mean_squared_error: 0.2260 - acc: 0.3458\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 2s 188us/step - loss: 0.2245 - mean_squared_error: 0.2245 - acc: 0.3395\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.2242 - mean_squared_error: 0.2242 - acc: 0.3416\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 2s 215us/step - loss: 0.2244 - mean_squared_error: 0.2244 - acc: 0.3361\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3423\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.2234 - mean_squared_error: 0.2234 - acc: 0.3423\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 220us/step - loss: 0.2233 - mean_squared_error: 0.2233 - acc: 0.3363\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 212us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3389\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3390\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 195us/step - loss: 0.2231 - mean_squared_error: 0.2231 - acc: 0.3364\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.3256\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3354\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 2s 239us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3338\n",
      "2526/2526 [==============================] - 2s 944us/step\n",
      "8083/8083 [==============================] - 1s 140us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 208us/step - loss: 0.2229 - mean_squared_error: 0.2229 - acc: 0.3368\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 2s 304us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3417\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 0.2228 - mean_squared_error: 0.2228 - acc: 0.3286\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3358\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 2s 188us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3363\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 0.2227 - mean_squared_error: 0.2227 - acc: 0.3395\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 2s 206us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3389\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 2s 250us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3319\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 2s 216us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3410\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 2s 268us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3328\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 130us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3437\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 2s 211us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3364\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 2s 191us/step - loss: 0.2226 - mean_squared_error: 0.2226 - acc: 0.3361\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3389\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 177us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3464\n",
      "2526/2526 [==============================] - 0s 117us/step\n",
      "8083/8083 [==============================] - 1s 106us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 187us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3446\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3450\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3406\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3371\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3407\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.2225 - mean_squared_error: 0.2225 - acc: 0.3408\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3422\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3392\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3460\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33 - 1s 157us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.3355\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.33730s - loss: 0.2225 - mean_squared_error\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34431s - loss: 0\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.2224 - mean_squared_error: 0.2224 - acc: 0.34521s - loss:\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3387\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3420\n",
      "2526/2526 [==============================] - 0s 80us/step\n",
      "8083/8083 [==============================] - 1s 112us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3376\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3457\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3418\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3431\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3485\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3424\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3343\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 129us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3437\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3436\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 2s 202us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3449\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3431\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s 183us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3408\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 2s 190us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3417\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.3434\n",
      "2526/2526 [==============================] - 0s 99us/step\n",
      "8083/8083 [==============================] - 1s 103us/step\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 2s 194us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3453\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 182us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3418\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.33741s - loss:\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3450\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 173us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3460\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 0.2221 - mean_squared_error: 0.2221 - acc: 0.34890s - loss: 0.2220 - mean_squar\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.34551s - loss: 0.2220 - me\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.3412\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3448\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3432\n",
      "Epoch 11/15\n",
      "6208/8083 [======================>.......] - ETA: 0s - loss: 0.2222 - mean_squared_error: 0.2222 - acc: 0.3402"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-140c26d2a7fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1377\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;31m# TODO(mrry): Switch to raising an exception from the SWIG wrapper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsFSK_means.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 2 + 1)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetFSK_Means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation Maximizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.49981036e-01 6.57274558e-01 6.57957245e-01 6.59464922e-01\n",
      " 6.68162784e-01 1.24580280e+00 1.24597206e+00 2.03655226e+00\n",
      " 1.32930749e+07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.57274558e-01 1.32930749e+07]\n"
     ]
    }
   ],
   "source": [
    "X = importData('finalDataNursing.csv') #TODO: put the right csv name\n",
    "X_inputs = X.drop('app_status', axis=1)\n",
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "\n",
    "X_inputs = X_inputs.values\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "X_inputs = SelectKBest(mutual_info_classif, k=2).fit_transform(X_inputs, X_outputs)\n",
    "variances = []\n",
    "for i in range(0,len(X_inputs[0])):\n",
    "    variances.append(np.var(X_inputs[:,i]))\n",
    "print(np.sort(variances))\n",
    "\n",
    "\n",
    "# Add clustering\n",
    "idealK = 3 #TODO: put this number after running the cell above\n",
    "\n",
    "# getting the cluster for ideal K\n",
    "gaussianModel = GaussianMixture(n_components = idealK)\n",
    "gaussianModel.fit(X_inputs)\n",
    "# Find best two features for visualization\n",
    "y = gaussianModel.predict(X_inputs)\n",
    "\n",
    "y = np.reshape(y, (-1,1))\n",
    "X_inputs = np.hstack((X_inputs, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outputs = np.reshape(X['app_status'].values,(-1,1))\n",
    "finalData = np.hstack((X_inputs, X_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration fraction: 0.800000\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "(8083, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 55)                220       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 3,468\n",
      "Trainable params: 3,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ScopedTFStatus.__del__ of <tensorflow.python.framework.c_api_util.ScopedTFStatus object at 0x0000025A48C4F1D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 39, in __del__\n",
      "    c_api.TF_DeleteStatus(self.status)\n",
      "AttributeError: 'ScopedTFStatus' object has no attribute 'status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 3s 349us/step - loss: 0.2368 - mean_squared_error: 0.2368 - acc: 0.3391\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 0.2278 - mean_squared_error: 0.2278 - acc: 0.3407\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s 131us/step - loss: 0.2253 - mean_squared_error: 0.2253 - acc: 0.3356\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 0.2251 - mean_squared_error: 0.2251 - acc: 0.3344\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 0.2239 - mean_squared_error: 0.2239 - acc: 0.3350\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 0.2236 - mean_squared_error: 0.2236 - acc: 0.3291\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 0.2232 - mean_squared_error: 0.2232 - acc: 0.34160s - loss: 0.2233 - mean_squared_error: 0.2233 -\n",
      "Epoch 8/15\n",
      "7648/8083 [===========================>..] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.2223 - acc: 0.36"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c9567314f0d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"current iteration fraction: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetupDataNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainandTestNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestHyperParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutputData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2662344092e5>\u001b[0m in \u001b[0;36mtrainandTestNeuralNetwork\u001b[1;34m(data, bestHyperParameter, firstTime, inputNum)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through different data sizes and get curve\n",
    "fractions = [i*(1.0/10) for i in range(1, 9)]\n",
    "fractions = list(reversed(fractions))\n",
    "\n",
    "bestHyperParameter = None\n",
    "\n",
    "outputData = []\n",
    "\n",
    "firstTime = 'nnIterationsFSEM.csv'\n",
    "for i in fractions:\n",
    "    print(\"current iteration fraction: %f\" % (i))\n",
    "    data = setupDataNN(finalData, i)\n",
    "    testValues = trainandTestNeuralNetwork(data, bestHyperParameter, firstTime, 2 + 1)\n",
    "    X_data = data[0]\n",
    "    outputData.append((X_data.shape[0], testValues[0], testValues[1], testValues[2], testValues[3]))\n",
    "    firstTime = ''\n",
    "    \n",
    "makePlots(outputData, 'NeuralNetFSEM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
